{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes    = 9\n",
    "batch_size     = 16\n",
    "train_days     = 3\n",
    "epochs         = 500\n",
    "learning_rate  = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9145, 128, 1024, 1) (9145, 2) \n",
      " [b'arahman3', b'harika', b'hchen32', b'jlaivins', b'kjakkala', b'pjanakar', b'ppinyoan', b'pwang13', b'upattnai', b'wrang']\n"
     ]
    }
   ],
   "source": [
    "#Read data\n",
    "hf = h5py.File('/home/kjakkala/mmwave/data/source_data.h5', 'r')\n",
    "X_data = np.expand_dims(hf.get('X_data'), axis=-1).astype(np.float32)\n",
    "y_data = np.array(hf.get('y_data')).astype(np.int32)\n",
    "classes = list(hf.get('classes'))\n",
    "hf.close()\n",
    "print(X_data.shape, y_data.shape, \"\\n\", classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8740, 128, 1024, 1) (8740, 2)\n"
     ]
    }
   ],
   "source": [
    "#balence dataset to 95 samples per day for each person\n",
    "X_data_tmp = []\n",
    "y_data_tmp = []\n",
    "for day in range(10):\n",
    "  for idx in range(len(classes)):\n",
    "    X_data_tmp.extend(X_data[(y_data[:, 0] == idx) & (y_data[:, 1] == day)][:95])\n",
    "    y_data_tmp.extend(y_data[(y_data[:, 0] == idx) & (y_data[:, 1] == day)][:95])\n",
    "X_data = np.array(X_data_tmp)\n",
    "y_data = np.array(y_data_tmp)\n",
    "del X_data_tmp, y_data_tmp\n",
    "print(X_data.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8550, 128, 1024, 1) (8550, 2) \n",
      " [b'arahman3', b'hchen32', b'jlaivins', b'kjakkala', b'pjanakar', b'ppinyoan', b'pwang13', b'upattnai', b'wrang']\n"
     ]
    }
   ],
   "source": [
    "#remove harika's data\n",
    "X_data = np.delete(X_data, np.where(y_data[:, 0] == 1)[0], 0)\n",
    "y_data = np.delete(y_data, np.where(y_data[:, 0] == 1)[0], 0)\n",
    "\n",
    "#update labes to handle 9 classes instead of 10\n",
    "y_data[y_data[:, 0] >= 2, 0] -= 1\n",
    "del classes[1]\n",
    "print(X_data.shape, y_data.shape, \"\\n\", classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2308, 128, 1024, 1) (2308, 9) (257, 128, 1024, 1) (257, 9) (4788, 128, 1024, 1) (4788, 9) (1197, 128, 1024, 1) (1197, 9)\n"
     ]
    }
   ],
   "source": [
    "#split days of data to train and test\n",
    "X_src = X_data[y_data[:, 1] < train_days]\n",
    "y_src = y_data[y_data[:, 1] < train_days, 0]\n",
    "y_src = np.eye(len(classes))[y_src]\n",
    "X_train_src, X_test_src, y_train_src, y_test_src = train_test_split(X_src,\n",
    "                                                                    y_src,\n",
    "                                                                    stratify=y_src,\n",
    "                                                                    test_size=0.10,\n",
    "                                                                    random_state=42)\n",
    "\n",
    "X_trg  = X_data[y_data[:, 1] >= train_days]\n",
    "y_trg  = y_data[y_data[:, 1] >= train_days, 0]\n",
    "y_trg = np.eye(len(classes))[y_trg]\n",
    "X_train_trg, X_test_trg, y_train_trg, y_test_trg = train_test_split(X_trg,\n",
    "                                                                    y_trg,\n",
    "                                                                    stratify=y_trg,\n",
    "                                                                    test_size=0.20,\n",
    "                                                                    random_state=42)\n",
    "del X_src, y_src, X_trg, y_trg\n",
    "\n",
    "y_train_trg = y_train_trg.astype(np.int64)\n",
    "y_test_trg  = y_test_trg.astype(np.int64)\n",
    "y_train_src = y_train_src.astype(np.int64)\n",
    "y_test_src  = y_test_src.astype(np.int64)\n",
    "\n",
    "print(X_train_src.shape, y_train_src.shape,  X_test_src.shape, y_test_src.shape, X_train_trg.shape, y_train_trg.shape, X_test_trg.shape, y_test_trg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2308, 128, 1024, 1) (2308, 9) (257, 128, 1024, 1) (257, 9) (4788, 128, 1024, 1) (4788, 9) (1197, 128, 1024, 1) (1197, 9)\n"
     ]
    }
   ],
   "source": [
    "#standardise dataset\n",
    "src_mean = np.mean(X_train_src)\n",
    "X_train_src -= src_mean\n",
    "src_std  = np.std(X_train_src)\n",
    "X_train_src /= src_std\n",
    "\n",
    "X_test_src -= src_mean\n",
    "X_test_src /= src_std\n",
    "\n",
    "trg_mean = np.mean(X_train_trg)\n",
    "X_train_trg -= trg_mean\n",
    "trg_std  = np.std(X_train_trg)\n",
    "X_train_trg /= trg_std\n",
    "\n",
    "X_test_trg -= src_mean\n",
    "X_test_trg /= src_std\n",
    "\n",
    "print(X_train_src.shape, y_train_src.shape,  X_test_src.shape, y_test_src.shape, X_train_trg.shape, y_train_trg.shape, X_test_trg.shape, y_test_trg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get tf.data objects for each set\n",
    "src_train_set = tf.data.Dataset.from_tensor_slices((X_train_src, y_train_src))\n",
    "src_train_set = src_train_set.shuffle(X_train_src.shape[0])\n",
    "src_train_set = src_train_set.batch(batch_size, drop_remainder=True)\n",
    "src_train_set = src_train_set.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "trg_train_set = tf.data.Dataset.from_tensor_slices((X_train_trg, y_train_trg))\n",
    "trg_train_set = trg_train_set.shuffle(X_train_trg.shape[0])\n",
    "trg_train_set = trg_train_set.batch(batch_size, drop_remainder=True)\n",
    "trg_train_set = trg_train_set.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "trg_train_set = trg_train_set.repeat(-1)\n",
    "\n",
    "src_test_set = tf.data.Dataset.from_tensor_slices((X_test_src, y_test_src))\n",
    "src_test_set = src_test_set.batch(batch_size, drop_remainder=False)\n",
    "src_test_set = src_test_set.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "trg_test_set = tf.data.Dataset.from_tensor_slices((X_test_trg, y_test_trg))\n",
    "trg_test_set = trg_test_set.batch(batch_size, drop_remainder=False)\n",
    "trg_test_set = trg_test_set.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_WEIGHT_DECAY = 1e-4\n",
    "BATCH_NORM_DECAY = 0.9\n",
    "BATCH_NORM_EPSILON = 1e-5\n",
    "\n",
    "class IdentityBlock(tf.keras.Model):\n",
    "  def __init__(self, kernel_size, filters, stage, block):\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    super().__init__(name='stage-' + str(stage) + '_block-' + block)\n",
    "\n",
    "    filters1, filters2, filters3 = filters\n",
    "    bn_axis = -1\n",
    "\n",
    "    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1),\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '2a')\n",
    "    self.bn2a = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '2a')\n",
    "\n",
    "    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size,\n",
    "                                         padding='same',\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '2b')\n",
    "    self.bn2b = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '2b')\n",
    "\n",
    "    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1),\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '2c')\n",
    "    self.bn2c = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '2c')\n",
    "\n",
    "  def call(self, input_tensor, training=False):\n",
    "    x = self.conv2a(input_tensor)\n",
    "    x = self.bn2a(x, training=training)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = self.conv2b(x)\n",
    "    x = self.bn2b(x, training=training)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = self.conv2c(x)\n",
    "    x = self.bn2c(x, training=training)\n",
    "\n",
    "    x = tf.keras.layers.add([x, input_tensor])\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\"\"\"A block that has a conv layer at shortcut.\n",
    "\n",
    "Note that from stage 3,\n",
    "the second conv layer at main path is with strides=(2, 2)\n",
    "And the shortcut should have strides=(2, 2) as well\n",
    "\n",
    "Args:\n",
    "  kernel_size: the kernel size of middle conv layer at main path\n",
    "  filters: list of integers, the filters of 3 conv layer at main path\n",
    "  stage: integer, current stage label, used for generating layer names\n",
    "  block: 'a','b'..., current block label, used for generating layer names\n",
    "  strides: Strides for the second conv layer in the block.\n",
    "\n",
    "Returns:\n",
    "  A Keras model instance for the block.\n",
    "\"\"\"\n",
    "class ConvBlock(tf.keras.Model):\n",
    "  def __init__(self, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    super().__init__(name='stage-' + str(stage) + '_block-' + block)\n",
    "\n",
    "    filters1, filters2, filters3 = filters\n",
    "    bn_axis = -1\n",
    "\n",
    "    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1),\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '2a')\n",
    "    self.bn2a = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '2a')\n",
    "\n",
    "    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size,\n",
    "                                         strides=strides,\n",
    "                                         padding='same',\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '2b')\n",
    "    self.bn2b = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '2b')\n",
    "\n",
    "    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1),\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '2c')\n",
    "    self.bn2c = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '2c')\n",
    "\n",
    "    self.conv2s = tf.keras.layers.Conv2D(filters3, (1, 1),\n",
    "                                         strides=strides,\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '1')\n",
    "    self.bn2s = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '1')\n",
    "\n",
    "  def call(self, input_tensor, training=False):\n",
    "    x = self.conv2a(input_tensor)\n",
    "    x = self.bn2a(x, training=training)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = self.conv2b(x)\n",
    "    x = self.bn2b(x, training=training)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = self.conv2c(x)\n",
    "    x = self.bn2c(x, training=training)\n",
    "\n",
    "    shortcut = self.conv2s(input_tensor)\n",
    "    shortcut = self.bn2s(shortcut, training=training)\n",
    "\n",
    "    x = tf.keras.layers.add([x, shortcut])\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\"\"\"Instantiates the ResNet50 architecture.\n",
    "\n",
    "Args:\n",
    "  num_classes: `int` number of classes for image classification.\n",
    "\n",
    "Returns:\n",
    "    A Keras model instance.\n",
    "\"\"\"\n",
    "class ResNet50(tf.keras.Model):\n",
    "  def __init__(self, num_classes, num_features):\n",
    "    super().__init__(name='generator')\n",
    "    bn_axis = -1\n",
    "\n",
    "    #self.conv1_pad = tf.keras.layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')\n",
    "    self.conv1 = tf.keras.layers.Conv2D(32, (7, 7),\n",
    "                                        strides=(2, 2),\n",
    "                                        padding='valid',\n",
    "                                        use_bias=False,\n",
    "                                        kernel_initializer='he_normal',\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                        name='conv1')\n",
    "    self.bn1 = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                  momentum=BATCH_NORM_DECAY,\n",
    "                                                  epsilon=BATCH_NORM_EPSILON,\n",
    "                                                  name='bn_conv1')\n",
    "    self.relu1 = tf.keras.layers.Activation('relu', name='relu1')\n",
    "    self.max_pool1 = tf.keras.layers.MaxPooling2D((3, 3),\n",
    "                                                  strides=(2, 2),\n",
    "                                                  padding='same',\n",
    "                                                  name='max_pool1')\n",
    "\n",
    "    self.blocks = []\n",
    "    self.blocks.append(ConvBlock(3, [32, 32, 128], strides=(1, 1), stage=2, block='a'))\n",
    "    self.blocks.append(IdentityBlock(3, [32, 32, 128], stage=2, block='b'))\n",
    "\n",
    "    self.blocks.append(ConvBlock(3, [64, 64, 256], stage=3, block='a'))\n",
    "    self.blocks.append(IdentityBlock(3, [64, 64, 256], stage=3, block='b'))\n",
    "\n",
    "    self.blocks.append(ConvBlock(3, [64, 64, 256], stage=4, block='a'))\n",
    "    self.blocks.append(IdentityBlock(3, [64, 64, 256], stage=4, block='b'))\n",
    "\n",
    "    self.avg_pool = tf.keras.layers.GlobalAveragePooling2D(name='avg_pool')\n",
    "    self.fc1 = tf.keras.layers.Dense(num_features,\n",
    "                                     activation='relu',\n",
    "                                     kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                     kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                     bias_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                     name='fc1')\n",
    "    self.logits = tf.keras.layers.Dense(num_classes,\n",
    "                                        activation=None,\n",
    "                                        kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                        bias_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                        name='logits')\n",
    "\n",
    "  def call(self, img_input, training=False):\n",
    "    x = self.conv1(img_input)\n",
    "    x = self.bn1(x, training=training)\n",
    "    x = self.relu1(x)\n",
    "    x = self.max_pool1(x)\n",
    "\n",
    "    for block in self.blocks:\n",
    "      x = block(x)\n",
    "\n",
    "    x = self.avg_pool(x)\n",
    "    fc1 = self.fc1(x)\n",
    "    logits = self.logits(fc1)\n",
    "    return logits, fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super().__init__(name='discriminator')  \n",
    "    self.dense1 = tf.keras.layers.Dense(100, activation='relu')\n",
    "    self.logits = tf.keras.layers.Dense(1, activation=None)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = self.dense1(inputs)\n",
    "    x = self.logits(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cross_entropy_loss(labels, logits):\n",
    "  loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=logits)\n",
    "  return tf.reduce_mean(loss)\n",
    "\n",
    "def get_domain_confusion_loss(src_logits, trg_logits):\n",
    "  discriminator_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(src_logits),\n",
    "                                                               logits=src_logits) + \\\n",
    "                       tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(trg_logits),\n",
    "                                                               logits=trg_logits)\n",
    "  return 0.5 * tf.reduce_mean(discriminator_loss)\n",
    "\n",
    "def virtual_adversarial_images(images, logits, pert_norm_radius=3.5):  \n",
    "  with tf.GradientTape() as tape:\n",
    "    # Get normalised noise matrix\n",
    "    noise = tf.random.normal(shape=tf.shape(images))\n",
    "    noise = 1e-6 * tf.nn.l2_normalize(noise, axis=tf.range(1, len(noise.shape)))\n",
    "\n",
    "    # Add noise to image and get new logits\n",
    "    noise_logits, _ = generator(images + noise, \n",
    "                                tf.constant(False, dtype=tf.bool))\n",
    "\n",
    "    # Get loss from noisey logits\n",
    "    noise_loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=logits, logits=noise_logits)\n",
    "    noise_loss = tf.reduce_mean(noise_loss)\n",
    "\n",
    "  # Based on perturbed image loss, get direction of greatest error\n",
    "  adversarial_noise = tape.gradient(noise_loss, \n",
    "                                    [noise],\n",
    "                                    unconnected_gradients='zero')[0]\n",
    "\n",
    "  adversarial_noise = tf.nn.l2_normalize(adversarial_noise, \n",
    "                                         axis=tf.range(1, 4))\n",
    "\n",
    "  # return images with adversarial perturbation\n",
    "  return images + pert_norm_radius * adversarial_noise\n",
    "\n",
    "def mixup_preprocess(x, y, batch_size, alpha=1):\n",
    "    # random sample the lambda value from beta distribution.\n",
    "    weight     = np.random.beta(alpha, alpha, batch_size)\n",
    "    x_weight   = weight.reshape(batch_size, 1, 1, 1)\n",
    "    y_weight   = weight.reshape(batch_size, 1)\n",
    "    \n",
    "    # Perform the mixup.\n",
    "    indices = tf.random.shuffle(tf.range(batch_size))\n",
    "    mixup_images = (x * x_weight) + (tf.gather(x, indices) * (1 - x_weight))\n",
    "    mixup_labels = (y * y_weight) + (tf.gather(y, indices) * (1 - y_weight))    \n",
    "    \n",
    "    return mixup_images, tf.nn.softmax(mixup_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_total_loss         = tf.keras.metrics.Mean(name='train_total_loss')\n",
    "train_domain_loss        = tf.keras.metrics.Mean(name='train_domain_loss')\n",
    "train_src_vat_loss       = tf.keras.metrics.Mean(name='train_src_vat_loss')\n",
    "train_trg_vat_loss       = tf.keras.metrics.Mean(name='train_trg_vat_loss')\n",
    "train_src_mixup_loss     = tf.keras.metrics.Mean(name='train_src_mixup_loss')\n",
    "train_trg_mixup_loss     = tf.keras.metrics.Mean(name='train_trg_mixup_loss')\n",
    "train_cond_entropy_loss  = tf.keras.metrics.Mean(name='train_cond_entropy_loss')\n",
    "train_cross_entropy_loss = tf.keras.metrics.Mean(name='train_cross_entropy_loss')\n",
    "train_discriminator_loss = tf.keras.metrics.Mean(name='train_discriminator_loss')\n",
    "src_test_accuracy        = tf.keras.metrics.CategoricalAccuracy(name='src_test_accuracy')\n",
    "trg_test_accuracy        = tf.keras.metrics.CategoricalAccuracy(name='trg_test_accuracy')\n",
    "src_train_accuracy       = tf.keras.metrics.CategoricalAccuracy(name='src_train_accuracy')\n",
    "trg_train_accuracy       = tf.keras.metrics.CategoricalAccuracy(name='trg_train_accuracy')\n",
    "\n",
    "@tf.function\n",
    "def train_gen_step(src_images, src_labels, trg_images, trg_labels):  \n",
    "  with tf.GradientTape() as gen_tape:\n",
    "    #Logits\n",
    "    src_logits, src_enc = generator(src_images, training=True)\n",
    "    trg_logits, trg_enc = generator(trg_images, training=True) \n",
    "    \n",
    "    #VAT\n",
    "    src_adver_images    = virtual_adversarial_images(src_images, tf.nn.softmax(src_logits))\n",
    "    src_adver_logits, _ = generator(tf.stop_gradient(src_adver_images), training=True)\n",
    "    trg_adver_images    = virtual_adversarial_images(trg_images, tf.nn.softmax(trg_logits))\n",
    "    trg_adver_logits, _ = generator(tf.stop_gradient(trg_adver_images), training=True)\n",
    "    \n",
    "    #MixUp\n",
    "    src_mixup_images, src_mixup_labels = mixup_preprocess(src_images, src_logits, batch_size)\n",
    "    src_mixup_logits, _                = generator(tf.stop_gradient(src_mixup_images),\n",
    "                                                   training=True)\n",
    "    trg_mixup_images, trg_mixup_labels = mixup_preprocess(trg_images, trg_logits, batch_size)\n",
    "    trg_mixup_logits, _                = generator(tf.stop_gradient(trg_mixup_images),\n",
    "                                                   training=True)\n",
    "    \n",
    "    #Disc\n",
    "    src_disc_logits     = discriminator(src_enc)\n",
    "    trg_disc_logits     = discriminator(trg_enc)\n",
    "\n",
    "    cross_entropy_loss  = get_cross_entropy_loss(labels=src_labels, \n",
    "                                                 logits=src_logits)\n",
    "    cross_cond_loss     = get_cross_entropy_loss(labels=tf.nn.softmax(trg_logits), \n",
    "                                                 logits=trg_logits)\n",
    "    src_vat_loss        = get_cross_entropy_loss(labels=tf.nn.softmax(tf.stop_gradient(src_logits)),\n",
    "                                                 logits=src_adver_logits)\n",
    "    trg_vat_loss        = get_cross_entropy_loss(labels=tf.nn.softmax(tf.stop_gradient(trg_logits)),\n",
    "                                                 logits=trg_adver_logits)\n",
    "    src_mixup_loss      = get_cross_entropy_loss(labels=tf.stop_gradient(src_mixup_labels), \n",
    "                                                 logits=src_mixup_logits)\n",
    "    trg_mixup_loss      = get_cross_entropy_loss(labels=tf.stop_gradient(trg_mixup_labels), \n",
    "                                                 logits=trg_mixup_logits)\n",
    "    domain_loss         = get_domain_confusion_loss(src_logits=trg_disc_logits, \n",
    "                                                    trg_logits=src_disc_logits)\n",
    "\n",
    "    total_loss = cross_entropy_loss + \\\n",
    "                 1e-2 * domain_loss + \\\n",
    "                 1e-2 * cross_cond_loss + \\\n",
    "                 1    * src_mixup_loss +\\\n",
    "                 1e-2 * trg_mixup_loss +\\\n",
    "                 1e-2 * trg_vat_loss + \\\n",
    "                 1    * src_vat_loss\n",
    "    \n",
    "  gen_gradients = gen_tape.gradient(total_loss, generator.trainable_variables)\n",
    "  gen_optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n",
    "\n",
    "  src_train_accuracy(src_labels, src_logits)\n",
    "  trg_train_accuracy(trg_labels, trg_logits)\n",
    "  train_cross_entropy_loss(cross_entropy_loss)\n",
    "  train_cond_entropy_loss(cross_cond_loss)\n",
    "  train_src_mixup_loss(src_mixup_loss)\n",
    "  train_trg_mixup_loss(trg_mixup_loss)\n",
    "  train_src_vat_loss(src_vat_loss)\n",
    "  train_trg_vat_loss(trg_vat_loss)\n",
    "  train_domain_loss(domain_loss)\n",
    "  train_total_loss(total_loss)\n",
    "  \n",
    "@tf.function\n",
    "def train_disc_step(src_images, trg_images):  \n",
    "  with tf.GradientTape() as disc_tape:\n",
    "    _, src_enc          = generator(src_images, training=True)\n",
    "    _, trg_enc          = generator(trg_images, training=True)  \n",
    "    src_disc_logits     = discriminator(src_enc)\n",
    "    trg_disc_logits     = discriminator(trg_enc)    \n",
    "    domain_conf_loss    = get_domain_confusion_loss(src_logits=src_disc_logits, \n",
    "                                                    trg_logits=trg_disc_logits)\n",
    "  \n",
    "  disc_gradients = disc_tape.gradient(domain_conf_loss, \n",
    "                                      discriminator.trainable_variables)\n",
    "  disc_optimizer.apply_gradients(zip(disc_gradients, discriminator.trainable_variables))\n",
    "  train_discriminator_loss(domain_conf_loss)\n",
    "\n",
    "@tf.function\n",
    "def test_source_step(source_images, source_labels):\n",
    "  source_logits, _ = generator(source_images, training=False)\n",
    "  src_test_accuracy(source_labels, source_logits)\n",
    "    \n",
    "@tf.function\n",
    "def test_target_step(target_images, target_labels):\n",
    "  target_logits, _ = generator(target_images, training=False)\n",
    "  trg_test_accuracy(target_labels, target_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0818 15:21:55.870690 140631618668288 deprecation.py:323] From /home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, TotalL: 6.6616, CrossE: 2.1994, CondE: 2.1947, disc: 0.6943, domain: 0.6948, Src VAT: 2.1946, Trg VAT: 2.1947, Src MixUp: 2.1947, Trg MixUp: 2.1947, Src Train Acc: 11.02, Trg Train Acc: 11.15, Src Test Acc: 11.28, Trg Test Acc: 10.61\n",
      "Epoch: 002, TotalL: 6.6046, CrossE: 2.1676, CondE: 2.1813, disc: 0.6940, domain: 0.6943, Src VAT: 2.1813, Trg VAT: 2.1813, Src MixUp: 2.1833, Trg MixUp: 2.1832, Src Train Acc: 13.24, Trg Train Acc: 15.41, Src Test Acc: 14.01, Trg Test Acc: 17.54\n",
      "Epoch: 003, TotalL: 5.9233, CrossE: 1.8876, CondE: 1.9625, disc: 0.6942, domain: 0.7063, Src VAT: 1.9566, Trg VAT: 1.9625, Src MixUp: 2.0127, Trg MixUp: 2.0083, Src Train Acc: 22.05, Trg Train Acc: 24.18, Src Test Acc: 31.52, Trg Test Acc: 29.57\n",
      "Epoch: 004, TotalL: 5.5498, CrossE: 1.7521, CondE: 1.8369, disc: 0.6929, domain: 0.7126, Src VAT: 1.8288, Trg VAT: 1.8369, Src MixUp: 1.9060, Trg MixUp: 1.9028, Src Train Acc: 29.99, Trg Train Acc: 29.34, Src Test Acc: 34.63, Trg Test Acc: 31.08\n",
      "Epoch: 005, TotalL: 5.1699, CrossE: 1.6133, CondE: 1.7139, disc: 0.6931, domain: 0.7183, Src VAT: 1.7046, Trg VAT: 1.7139, Src MixUp: 1.7926, Trg MixUp: 1.7893, Src Train Acc: 37.15, Trg Train Acc: 33.64, Src Test Acc: 42.41, Trg Test Acc: 38.85\n",
      "Epoch: 006, TotalL: 4.7050, CrossE: 1.4318, CondE: 1.5658, disc: 0.6971, domain: 0.7260, Src VAT: 1.5423, Trg VAT: 1.5658, Src MixUp: 1.6756, Trg MixUp: 1.6731, Src Train Acc: 45.23, Trg Train Acc: 39.41, Src Test Acc: 48.25, Trg Test Acc: 44.53\n",
      "Epoch: 007, TotalL: 4.3430, CrossE: 1.3007, CondE: 1.4448, disc: 0.6946, domain: 0.7290, Src VAT: 1.4154, Trg VAT: 1.4448, Src MixUp: 1.5749, Trg MixUp: 1.5807, Src Train Acc: 50.56, Trg Train Acc: 44.53, Src Test Acc: 54.47, Trg Test Acc: 47.37\n",
      "Epoch: 008, TotalL: 4.1406, CrossE: 1.2175, CondE: 1.3760, disc: 0.6964, domain: 0.7309, Src VAT: 1.3404, Trg VAT: 1.3760, Src MixUp: 1.5324, Trg MixUp: 1.5330, Src Train Acc: 53.21, Trg Train Acc: 46.61, Src Test Acc: 56.81, Trg Test Acc: 48.71\n",
      "Epoch: 009, TotalL: 3.9598, CrossE: 1.1571, CondE: 1.3165, disc: 0.6951, domain: 0.7376, Src VAT: 1.2797, Trg VAT: 1.3165, Src MixUp: 1.4744, Trg MixUp: 1.4847, Src Train Acc: 56.16, Trg Train Acc: 49.18, Src Test Acc: 59.14, Trg Test Acc: 50.88\n",
      "Epoch: 010, TotalL: 3.8322, CrossE: 1.0992, CondE: 1.2723, disc: 0.6922, domain: 0.7416, Src VAT: 1.2344, Trg VAT: 1.2723, Src MixUp: 1.4511, Trg MixUp: 1.4612, Src Train Acc: 59.51, Trg Train Acc: 52.08, Src Test Acc: 62.26, Trg Test Acc: 54.22\n",
      "Epoch: 011, TotalL: 3.6612, CrossE: 1.0399, CondE: 1.2241, disc: 0.6907, domain: 0.7484, Src VAT: 1.1778, Trg VAT: 1.2241, Src MixUp: 1.3973, Trg MixUp: 1.4171, Src Train Acc: 61.68, Trg Train Acc: 53.52, Src Test Acc: 66.15, Trg Test Acc: 58.23\n",
      "Epoch: 012, TotalL: 3.5498, CrossE: 0.9902, CondE: 1.1873, disc: 0.6890, domain: 0.7478, Src VAT: 1.1406, Trg VAT: 1.1873, Src MixUp: 1.3739, Trg MixUp: 1.3954, Src Train Acc: 63.93, Trg Train Acc: 56.29, Src Test Acc: 58.75, Trg Test Acc: 52.63\n",
      "Epoch: 013, TotalL: 3.4392, CrossE: 0.9567, CondE: 1.1489, disc: 0.6876, domain: 0.7509, Src VAT: 1.0989, Trg VAT: 1.1489, Src MixUp: 1.3396, Trg MixUp: 1.3472, Src Train Acc: 66.19, Trg Train Acc: 57.29, Src Test Acc: 68.48, Trg Test Acc: 62.74\n",
      "Epoch: 014, TotalL: 3.3406, CrossE: 0.9188, CondE: 1.1159, disc: 0.6892, domain: 0.7496, Src VAT: 1.0669, Trg VAT: 1.1159, Src MixUp: 1.3119, Trg MixUp: 1.3188, Src Train Acc: 67.14, Trg Train Acc: 59.46, Src Test Acc: 71.21, Trg Test Acc: 62.32\n",
      "Epoch: 015, TotalL: 3.2272, CrossE: 0.8736, CondE: 1.0792, disc: 0.6887, domain: 0.7530, Src VAT: 1.0296, Trg VAT: 1.0792, Src MixUp: 1.2818, Trg MixUp: 1.3017, Src Train Acc: 69.40, Trg Train Acc: 60.81, Src Test Acc: 70.43, Trg Test Acc: 64.33\n",
      "Epoch: 016, TotalL: 3.1138, CrossE: 0.8394, CondE: 1.0435, disc: 0.6846, domain: 0.7550, Src VAT: 0.9863, Trg VAT: 1.0435, Src MixUp: 1.2470, Trg MixUp: 1.2667, Src Train Acc: 70.75, Trg Train Acc: 62.24, Src Test Acc: 72.37, Trg Test Acc: 65.25\n",
      "Epoch: 017, TotalL: 3.0250, CrossE: 0.8012, CondE: 1.0127, disc: 0.6882, domain: 0.7564, Src VAT: 0.9536, Trg VAT: 1.0127, Src MixUp: 1.2299, Trg MixUp: 1.2584, Src Train Acc: 72.57, Trg Train Acc: 62.98, Src Test Acc: 75.10, Trg Test Acc: 66.50\n",
      "Epoch: 018, TotalL: 2.9154, CrossE: 0.7595, CondE: 0.9751, disc: 0.6873, domain: 0.7589, Src VAT: 0.9178, Trg VAT: 0.9751, Src MixUp: 1.1991, Trg MixUp: 1.1964, Src Train Acc: 73.48, Trg Train Acc: 65.15, Src Test Acc: 76.26, Trg Test Acc: 67.08\n",
      "Epoch: 019, TotalL: 2.8460, CrossE: 0.7346, CondE: 0.9489, disc: 0.6876, domain: 0.7583, Src VAT: 0.8933, Trg VAT: 0.9489, Src MixUp: 1.1796, Trg MixUp: 1.1918, Src Train Acc: 74.87, Trg Train Acc: 66.19, Src Test Acc: 76.65, Trg Test Acc: 69.01\n",
      "Epoch: 020, TotalL: 2.6853, CrossE: 0.6730, CondE: 0.8989, disc: 0.6847, domain: 0.7605, Src VAT: 0.8410, Trg VAT: 0.8989, Src MixUp: 1.1343, Trg MixUp: 1.1485, Src Train Acc: 76.91, Trg Train Acc: 69.18, Src Test Acc: 77.43, Trg Test Acc: 70.26\n",
      "Epoch: 021, TotalL: 2.6533, CrossE: 0.6694, CondE: 0.8818, disc: 0.6856, domain: 0.7627, Src VAT: 0.8217, Trg VAT: 0.8818, Src MixUp: 1.1257, Trg MixUp: 1.1328, Src Train Acc: 76.69, Trg Train Acc: 68.40, Src Test Acc: 75.49, Trg Test Acc: 68.25\n",
      "Epoch: 022, TotalL: 2.5712, CrossE: 0.6332, CondE: 0.8585, disc: 0.6818, domain: 0.7673, Src VAT: 0.7970, Trg VAT: 0.8585, Src MixUp: 1.1051, Trg MixUp: 1.1069, Src Train Acc: 78.04, Trg Train Acc: 69.75, Src Test Acc: 77.43, Trg Test Acc: 70.68\n",
      "Epoch: 023, TotalL: 2.4046, CrossE: 0.5721, CondE: 0.8012, disc: 0.6793, domain: 0.7766, Src VAT: 0.7384, Trg VAT: 0.8012, Src MixUp: 1.0596, Trg MixUp: 1.0659, Src Train Acc: 80.73, Trg Train Acc: 72.14, Src Test Acc: 75.10, Trg Test Acc: 69.34\n",
      "Epoch: 024, TotalL: 2.3549, CrossE: 0.5606, CondE: 0.7816, disc: 0.6815, domain: 0.7740, Src VAT: 0.7179, Trg VAT: 0.7816, Src MixUp: 1.0424, Trg MixUp: 1.0581, Src Train Acc: 81.16, Trg Train Acc: 72.44, Src Test Acc: 78.60, Trg Test Acc: 73.18\n",
      "Epoch: 025, TotalL: 2.2379, CrossE: 0.5213, CondE: 0.7451, disc: 0.6785, domain: 0.7763, Src VAT: 0.6813, Trg VAT: 0.7451, Src MixUp: 1.0025, Trg MixUp: 1.0186, Src Train Acc: 81.55, Trg Train Acc: 74.74, Src Test Acc: 78.99, Trg Test Acc: 74.52\n",
      "Epoch: 026, TotalL: 2.1648, CrossE: 0.4960, CondE: 0.7229, disc: 0.6775, domain: 0.7815, Src VAT: 0.6540, Trg VAT: 0.7229, Src MixUp: 0.9826, Trg MixUp: 0.9970, Src Train Acc: 83.12, Trg Train Acc: 74.78, Src Test Acc: 77.04, Trg Test Acc: 69.84\n",
      "Epoch: 027, TotalL: 2.1135, CrossE: 0.4849, CondE: 0.7010, disc: 0.6747, domain: 0.7880, Src VAT: 0.6365, Trg VAT: 0.7010, Src MixUp: 0.9605, Trg MixUp: 0.9783, Src Train Acc: 83.85, Trg Train Acc: 76.69, Src Test Acc: 81.71, Trg Test Acc: 76.11\n",
      "Epoch: 028, TotalL: 2.0111, CrossE: 0.4396, CondE: 0.6647, disc: 0.6684, domain: 0.7981, Src VAT: 0.5956, Trg VAT: 0.6647, Src MixUp: 0.9452, Trg MixUp: 0.9377, Src Train Acc: 85.24, Trg Train Acc: 77.08, Src Test Acc: 70.43, Trg Test Acc: 66.08\n",
      "Epoch: 029, TotalL: 1.9096, CrossE: 0.4048, CondE: 0.6279, disc: 0.6695, domain: 0.8066, Src VAT: 0.5607, Trg VAT: 0.6279, Src MixUp: 0.9146, Trg MixUp: 0.9016, Src Train Acc: 86.41, Trg Train Acc: 77.69, Src Test Acc: 82.10, Trg Test Acc: 77.69\n",
      "Epoch: 030, TotalL: 1.8782, CrossE: 0.3936, CondE: 0.6240, disc: 0.6628, domain: 0.8102, Src VAT: 0.5511, Trg VAT: 0.6240, Src MixUp: 0.9039, Trg MixUp: 0.9048, Src Train Acc: 87.37, Trg Train Acc: 78.86, Src Test Acc: 75.49, Trg Test Acc: 70.43\n",
      "Epoch: 031, TotalL: 1.7498, CrossE: 0.3600, CondE: 0.5785, disc: 0.6642, domain: 0.8245, Src VAT: 0.5071, Trg VAT: 0.5785, Src MixUp: 0.8541, Trg MixUp: 0.8771, Src Train Acc: 88.50, Trg Train Acc: 79.08, Src Test Acc: 85.60, Trg Test Acc: 80.45\n",
      "Epoch: 032, TotalL: 1.7511, CrossE: 0.3587, CondE: 0.5798, disc: 0.6602, domain: 0.8256, Src VAT: 0.4990, Trg VAT: 0.5798, Src MixUp: 0.8646, Trg MixUp: 0.8796, Src Train Acc: 88.15, Trg Train Acc: 79.90, Src Test Acc: 92.22, Trg Test Acc: 83.71\n",
      "Epoch: 033, TotalL: 1.7223, CrossE: 0.3435, CondE: 0.5743, disc: 0.6646, domain: 0.8301, Src VAT: 0.4927, Trg VAT: 0.5743, Src MixUp: 0.8575, Trg MixUp: 0.8742, Src Train Acc: 89.19, Trg Train Acc: 80.38, Src Test Acc: 83.66, Trg Test Acc: 77.19\n",
      "Epoch: 034, TotalL: 1.6519, CrossE: 0.3241, CondE: 0.5455, disc: 0.6555, domain: 0.8351, Src VAT: 0.4665, Trg VAT: 0.5455, Src MixUp: 0.8337, Trg MixUp: 0.8355, Src Train Acc: 89.50, Trg Train Acc: 80.34, Src Test Acc: 79.38, Trg Test Acc: 72.60\n",
      "Epoch: 035, TotalL: 1.6453, CrossE: 0.3209, CondE: 0.5418, disc: 0.6563, domain: 0.8363, Src VAT: 0.4665, Trg VAT: 0.5418, Src MixUp: 0.8304, Trg MixUp: 0.8308, Src Train Acc: 89.93, Trg Train Acc: 80.60, Src Test Acc: 87.16, Trg Test Acc: 81.70\n",
      "Epoch: 036, TotalL: 1.5532, CrossE: 0.2920, CondE: 0.5242, disc: 0.6515, domain: 0.8545, Src VAT: 0.4386, Trg VAT: 0.5242, Src MixUp: 0.7952, Trg MixUp: 0.8412, Src Train Acc: 91.32, Trg Train Acc: 82.07, Src Test Acc: 92.22, Trg Test Acc: 84.04\n",
      "Epoch: 037, TotalL: 1.4876, CrossE: 0.2849, CondE: 0.5099, disc: 0.6553, domain: 0.8664, Src VAT: 0.4122, Trg VAT: 0.5099, Src MixUp: 0.7635, Trg MixUp: 0.8084, Src Train Acc: 91.02, Trg Train Acc: 82.34, Src Test Acc: 82.88, Trg Test Acc: 74.02\n",
      "Epoch: 038, TotalL: 1.5306, CrossE: 0.2860, CondE: 0.5027, disc: 0.6510, domain: 0.8580, Src VAT: 0.4175, Trg VAT: 0.5027, Src MixUp: 0.8005, Trg MixUp: 0.7948, Src Train Acc: 90.97, Trg Train Acc: 82.64, Src Test Acc: 92.61, Trg Test Acc: 86.38\n",
      "Epoch: 039, TotalL: 1.4339, CrossE: 0.2593, CondE: 0.4859, disc: 0.6448, domain: 0.8713, Src VAT: 0.3905, Trg VAT: 0.4859, Src MixUp: 0.7580, Trg MixUp: 0.7756, Src Train Acc: 92.58, Trg Train Acc: 83.94, Src Test Acc: 90.27, Trg Test Acc: 82.79\n",
      "Epoch: 040, TotalL: 1.4306, CrossE: 0.2567, CondE: 0.4760, disc: 0.6468, domain: 0.8712, Src VAT: 0.3868, Trg VAT: 0.4760, Src MixUp: 0.7611, Trg MixUp: 0.7812, Src Train Acc: 92.06, Trg Train Acc: 83.12, Src Test Acc: 93.00, Trg Test Acc: 86.55\n",
      "Epoch: 041, TotalL: 1.3668, CrossE: 0.2267, CondE: 0.4572, disc: 0.6440, domain: 0.8761, Src VAT: 0.3666, Trg VAT: 0.4572, Src MixUp: 0.7478, Trg MixUp: 0.7788, Src Train Acc: 93.19, Trg Train Acc: 83.98, Src Test Acc: 85.60, Trg Test Acc: 81.12\n",
      "Epoch: 042, TotalL: 1.4088, CrossE: 0.2476, CondE: 0.4733, disc: 0.6459, domain: 0.8729, Src VAT: 0.3776, Trg VAT: 0.4733, Src MixUp: 0.7576, Trg MixUp: 0.7837, Src Train Acc: 91.97, Trg Train Acc: 83.81, Src Test Acc: 94.94, Trg Test Acc: 87.22\n",
      "Epoch: 043, TotalL: 1.3517, CrossE: 0.2368, CondE: 0.4600, disc: 0.6453, domain: 0.8824, Src VAT: 0.3561, Trg VAT: 0.4600, Src MixUp: 0.7331, Trg MixUp: 0.7686, Src Train Acc: 92.88, Trg Train Acc: 85.03, Src Test Acc: 91.05, Trg Test Acc: 85.55\n",
      "Epoch: 044, TotalL: 1.3046, CrossE: 0.2145, CondE: 0.4374, disc: 0.6441, domain: 0.8894, Src VAT: 0.3408, Trg VAT: 0.4374, Src MixUp: 0.7241, Trg MixUp: 0.7580, Src Train Acc: 93.10, Trg Train Acc: 85.81, Src Test Acc: 88.72, Trg Test Acc: 82.54\n",
      "Epoch: 045, TotalL: 1.3293, CrossE: 0.2325, CondE: 0.4387, disc: 0.6481, domain: 0.8738, Src VAT: 0.3532, Trg VAT: 0.4387, Src MixUp: 0.7188, Trg MixUp: 0.7359, Src Train Acc: 93.10, Trg Train Acc: 84.20, Src Test Acc: 93.39, Trg Test Acc: 85.71\n",
      "Epoch: 046, TotalL: 1.2338, CrossE: 0.1905, CondE: 0.4217, disc: 0.6385, domain: 0.8898, Src VAT: 0.3191, Trg VAT: 0.4217, Src MixUp: 0.6997, Trg MixUp: 0.7186, Src Train Acc: 94.53, Trg Train Acc: 86.15, Src Test Acc: 88.72, Trg Test Acc: 84.38\n",
      "Epoch: 047, TotalL: 1.2719, CrossE: 0.1978, CondE: 0.4358, disc: 0.6397, domain: 0.8965, Src VAT: 0.3255, Trg VAT: 0.4358, Src MixUp: 0.7235, Trg MixUp: 0.7495, Src Train Acc: 94.97, Trg Train Acc: 85.24, Src Test Acc: 91.44, Trg Test Acc: 85.63\n",
      "Epoch: 048, TotalL: 1.2311, CrossE: 0.2048, CondE: 0.4111, disc: 0.6491, domain: 0.8986, Src VAT: 0.3160, Trg VAT: 0.4111, Src MixUp: 0.6859, Trg MixUp: 0.7200, Src Train Acc: 93.36, Trg Train Acc: 84.33, Src Test Acc: 94.16, Trg Test Acc: 87.39\n",
      "Epoch: 049, TotalL: 1.1652, CrossE: 0.1797, CondE: 0.3943, disc: 0.6360, domain: 0.8996, Src VAT: 0.2960, Trg VAT: 0.3943, Src MixUp: 0.6654, Trg MixUp: 0.7197, Src Train Acc: 94.70, Trg Train Acc: 85.55, Src Test Acc: 93.39, Trg Test Acc: 87.13\n",
      "Epoch: 050, TotalL: 1.1436, CrossE: 0.1721, CondE: 0.3831, disc: 0.6408, domain: 0.9192, Src VAT: 0.2849, Trg VAT: 0.3831, Src MixUp: 0.6627, Trg MixUp: 0.7058, Src Train Acc: 95.01, Trg Train Acc: 87.15, Src Test Acc: 92.61, Trg Test Acc: 87.80\n",
      "Epoch: 051, TotalL: 1.1811, CrossE: 0.1805, CondE: 0.3965, disc: 0.6281, domain: 0.9284, Src VAT: 0.2959, Trg VAT: 0.3965, Src MixUp: 0.6806, Trg MixUp: 0.6881, Src Train Acc: 94.70, Trg Train Acc: 86.72, Src Test Acc: 93.39, Trg Test Acc: 87.39\n",
      "Epoch: 052, TotalL: 1.1127, CrossE: 0.1696, CondE: 0.3708, disc: 0.6362, domain: 0.9314, Src VAT: 0.2753, Trg VAT: 0.3708, Src MixUp: 0.6441, Trg MixUp: 0.6894, Src Train Acc: 95.10, Trg Train Acc: 87.02, Src Test Acc: 91.83, Trg Test Acc: 85.71\n",
      "Epoch: 053, TotalL: 1.1635, CrossE: 0.1752, CondE: 0.3907, disc: 0.6329, domain: 0.9140, Src VAT: 0.2858, Trg VAT: 0.3907, Src MixUp: 0.6785, Trg MixUp: 0.6920, Src Train Acc: 94.75, Trg Train Acc: 85.85, Src Test Acc: 96.89, Trg Test Acc: 89.81\n",
      "Epoch: 054, TotalL: 1.0643, CrossE: 0.1470, CondE: 0.3689, disc: 0.6353, domain: 0.9331, Src VAT: 0.2572, Trg VAT: 0.3689, Src MixUp: 0.6365, Trg MixUp: 0.6790, Src Train Acc: 95.70, Trg Train Acc: 87.41, Src Test Acc: 96.11, Trg Test Acc: 89.64\n",
      "Epoch: 055, TotalL: 1.0751, CrossE: 0.1635, CondE: 0.3631, disc: 0.6354, domain: 0.9483, Src VAT: 0.2629, Trg VAT: 0.3631, Src MixUp: 0.6253, Trg MixUp: 0.6579, Src Train Acc: 95.49, Trg Train Acc: 87.24, Src Test Acc: 95.72, Trg Test Acc: 89.81\n",
      "Epoch: 056, TotalL: 1.0426, CrossE: 0.1599, CondE: 0.3511, disc: 0.6256, domain: 0.9551, Src VAT: 0.2495, Trg VAT: 0.3511, Src MixUp: 0.6100, Trg MixUp: 0.6594, Src Train Acc: 95.31, Trg Train Acc: 86.46, Src Test Acc: 93.00, Trg Test Acc: 88.64\n",
      "Epoch: 057, TotalL: 1.0457, CrossE: 0.1453, CondE: 0.3539, disc: 0.6259, domain: 0.9521, Src VAT: 0.2462, Trg VAT: 0.3539, Src MixUp: 0.6311, Trg MixUp: 0.6547, Src Train Acc: 95.62, Trg Train Acc: 87.72, Src Test Acc: 95.72, Trg Test Acc: 88.30\n",
      "Epoch: 058, TotalL: 1.0043, CrossE: 0.1395, CondE: 0.3508, disc: 0.6247, domain: 0.9585, Src VAT: 0.2355, Trg VAT: 0.3508, Src MixUp: 0.6061, Trg MixUp: 0.6573, Src Train Acc: 96.05, Trg Train Acc: 87.59, Src Test Acc: 90.27, Trg Test Acc: 83.79\n",
      "Epoch: 059, TotalL: 1.0210, CrossE: 0.1419, CondE: 0.3540, disc: 0.6296, domain: 0.9460, Src VAT: 0.2429, Trg VAT: 0.3540, Src MixUp: 0.6129, Trg MixUp: 0.6740, Src Train Acc: 95.83, Trg Train Acc: 87.46, Src Test Acc: 92.22, Trg Test Acc: 87.55\n",
      "Epoch: 060, TotalL: 1.0234, CrossE: 0.1462, CondE: 0.3395, disc: 0.6334, domain: 0.9560, Src VAT: 0.2409, Trg VAT: 0.3395, Src MixUp: 0.6136, Trg MixUp: 0.6314, Src Train Acc: 95.57, Trg Train Acc: 86.41, Src Test Acc: 96.89, Trg Test Acc: 88.97\n",
      "Epoch: 061, TotalL: 1.0368, CrossE: 0.1527, CondE: 0.3430, disc: 0.6335, domain: 0.9423, Src VAT: 0.2383, Trg VAT: 0.3430, Src MixUp: 0.6230, Trg MixUp: 0.6579, Src Train Acc: 94.97, Trg Train Acc: 87.37, Src Test Acc: 95.72, Trg Test Acc: 89.72\n",
      "Epoch: 062, TotalL: 0.9952, CrossE: 0.1293, CondE: 0.3232, disc: 0.6260, domain: 0.9649, Src VAT: 0.2282, Trg VAT: 0.3232, Src MixUp: 0.6152, Trg MixUp: 0.6342, Src Train Acc: 96.40, Trg Train Acc: 88.76, Src Test Acc: 92.61, Trg Test Acc: 83.71\n",
      "Epoch: 063, TotalL: 0.9821, CrossE: 0.1266, CondE: 0.3269, disc: 0.6266, domain: 0.9606, Src VAT: 0.2315, Trg VAT: 0.3269, Src MixUp: 0.6015, Trg MixUp: 0.6402, Src Train Acc: 96.40, Trg Train Acc: 87.20, Src Test Acc: 98.05, Trg Test Acc: 90.14\n",
      "Epoch: 064, TotalL: 0.9417, CrossE: 0.1151, CondE: 0.3180, disc: 0.6183, domain: 0.9695, Src VAT: 0.2094, Trg VAT: 0.3180, Src MixUp: 0.5948, Trg MixUp: 0.6357, Src Train Acc: 96.79, Trg Train Acc: 88.28, Src Test Acc: 97.28, Trg Test Acc: 91.06\n",
      "Epoch: 065, TotalL: 0.9351, CrossE: 0.1222, CondE: 0.3138, disc: 0.6343, domain: 0.9677, Src VAT: 0.2134, Trg VAT: 0.3138, Src MixUp: 0.5773, Trg MixUp: 0.6269, Src Train Acc: 96.88, Trg Train Acc: 87.89, Src Test Acc: 92.22, Trg Test Acc: 88.81\n",
      "Epoch: 066, TotalL: 0.9276, CrossE: 0.1198, CondE: 0.3106, disc: 0.6303, domain: 0.9563, Src VAT: 0.2052, Trg VAT: 0.3106, Src MixUp: 0.5806, Trg MixUp: 0.6216, Src Train Acc: 96.57, Trg Train Acc: 88.50, Src Test Acc: 94.16, Trg Test Acc: 87.89\n",
      "Epoch: 067, TotalL: 0.8632, CrossE: 0.0989, CondE: 0.2891, disc: 0.6254, domain: 0.9757, Src VAT: 0.1900, Trg VAT: 0.2891, Src MixUp: 0.5527, Trg MixUp: 0.6045, Src Train Acc: 97.70, Trg Train Acc: 88.24, Src Test Acc: 94.94, Trg Test Acc: 89.22\n",
      "Epoch: 068, TotalL: 0.8944, CrossE: 0.1136, CondE: 0.2966, disc: 0.6284, domain: 0.9581, Src VAT: 0.1977, Trg VAT: 0.2966, Src MixUp: 0.5616, Trg MixUp: 0.6081, Src Train Acc: 96.57, Trg Train Acc: 87.89, Src Test Acc: 93.39, Trg Test Acc: 88.64\n",
      "Epoch: 069, TotalL: 0.8673, CrossE: 0.1123, CondE: 0.2880, disc: 0.6275, domain: 0.9790, Src VAT: 0.1951, Trg VAT: 0.2880, Src MixUp: 0.5382, Trg MixUp: 0.6111, Src Train Acc: 96.74, Trg Train Acc: 88.32, Src Test Acc: 96.50, Trg Test Acc: 89.31\n",
      "Epoch: 070, TotalL: 0.9127, CrossE: 0.1163, CondE: 0.2992, disc: 0.6321, domain: 0.9493, Src VAT: 0.2016, Trg VAT: 0.2992, Src MixUp: 0.5732, Trg MixUp: 0.6083, Src Train Acc: 96.48, Trg Train Acc: 88.89, Src Test Acc: 96.50, Trg Test Acc: 89.64\n",
      "Epoch: 071, TotalL: 0.8920, CrossE: 0.1034, CondE: 0.2929, disc: 0.6258, domain: 0.9685, Src VAT: 0.1913, Trg VAT: 0.2929, Src MixUp: 0.5755, Trg MixUp: 0.6130, Src Train Acc: 97.09, Trg Train Acc: 88.45, Src Test Acc: 96.50, Trg Test Acc: 90.98\n",
      "Epoch: 072, TotalL: 0.8545, CrossE: 0.0978, CondE: 0.2942, disc: 0.6170, domain: 0.9815, Src VAT: 0.1857, Trg VAT: 0.2942, Src MixUp: 0.5493, Trg MixUp: 0.5983, Src Train Acc: 97.44, Trg Train Acc: 88.54, Src Test Acc: 95.72, Trg Test Acc: 91.48\n",
      "Epoch: 073, TotalL: 0.8320, CrossE: 0.0901, CondE: 0.2654, disc: 0.6205, domain: 0.9828, Src VAT: 0.1755, Trg VAT: 0.2654, Src MixUp: 0.5454, Trg MixUp: 0.5893, Src Train Acc: 97.61, Trg Train Acc: 89.45, Src Test Acc: 97.67, Trg Test Acc: 88.81\n",
      "Epoch: 074, TotalL: 0.8380, CrossE: 0.0960, CondE: 0.2853, disc: 0.6172, domain: 0.9867, Src VAT: 0.1827, Trg VAT: 0.2853, Src MixUp: 0.5378, Trg MixUp: 0.5836, Src Train Acc: 97.48, Trg Train Acc: 88.19, Src Test Acc: 98.44, Trg Test Acc: 91.73\n",
      "Epoch: 075, TotalL: 0.8794, CrossE: 0.1035, CondE: 0.2898, disc: 0.6294, domain: 0.9633, Src VAT: 0.1897, Trg VAT: 0.2898, Src MixUp: 0.5647, Trg MixUp: 0.6099, Src Train Acc: 97.09, Trg Train Acc: 88.45, Src Test Acc: 98.05, Trg Test Acc: 92.65\n",
      "Epoch: 076, TotalL: 0.8095, CrossE: 0.0839, CondE: 0.2610, disc: 0.6268, domain: 0.9763, Src VAT: 0.1693, Trg VAT: 0.2610, Src MixUp: 0.5355, Trg MixUp: 0.5779, Src Train Acc: 97.53, Trg Train Acc: 89.41, Src Test Acc: 96.89, Trg Test Acc: 87.80\n",
      "Epoch: 077, TotalL: 0.7842, CrossE: 0.0833, CondE: 0.2716, disc: 0.6306, domain: 0.9728, Src VAT: 0.1626, Trg VAT: 0.2716, Src MixUp: 0.5174, Trg MixUp: 0.5750, Src Train Acc: 97.70, Trg Train Acc: 89.76, Src Test Acc: 91.83, Trg Test Acc: 86.97\n",
      "Epoch: 078, TotalL: 0.8220, CrossE: 0.0924, CondE: 0.2625, disc: 0.6234, domain: 0.9832, Src VAT: 0.1732, Trg VAT: 0.2625, Src MixUp: 0.5358, Trg MixUp: 0.5616, Src Train Acc: 97.14, Trg Train Acc: 88.76, Src Test Acc: 96.11, Trg Test Acc: 87.47\n",
      "Epoch: 079, TotalL: 0.8146, CrossE: 0.0956, CondE: 0.2703, disc: 0.6354, domain: 0.9799, Src VAT: 0.1708, Trg VAT: 0.2703, Src MixUp: 0.5273, Trg MixUp: 0.5806, Src Train Acc: 97.05, Trg Train Acc: 89.41, Src Test Acc: 98.05, Trg Test Acc: 92.90\n",
      "Epoch: 080, TotalL: 0.8032, CrossE: 0.0833, CondE: 0.2742, disc: 0.6255, domain: 0.9834, Src VAT: 0.1624, Trg VAT: 0.2742, Src MixUp: 0.5364, Trg MixUp: 0.5850, Src Train Acc: 97.87, Trg Train Acc: 89.15, Src Test Acc: 94.94, Trg Test Acc: 89.81\n",
      "Epoch: 081, TotalL: 0.7878, CrossE: 0.0880, CondE: 0.2645, disc: 0.6260, domain: 0.9701, Src VAT: 0.1604, Trg VAT: 0.2645, Src MixUp: 0.5187, Trg MixUp: 0.5637, Src Train Acc: 97.66, Trg Train Acc: 89.06, Src Test Acc: 97.67, Trg Test Acc: 89.64\n",
      "Epoch: 082, TotalL: 0.7885, CrossE: 0.0845, CondE: 0.2519, disc: 0.6207, domain: 0.9734, Src VAT: 0.1618, Trg VAT: 0.2519, Src MixUp: 0.5217, Trg MixUp: 0.5669, Src Train Acc: 97.61, Trg Train Acc: 89.84, Src Test Acc: 96.50, Trg Test Acc: 89.97\n",
      "Epoch: 083, TotalL: 0.7415, CrossE: 0.0683, CondE: 0.2543, disc: 0.6185, domain: 0.9833, Src VAT: 0.1450, Trg VAT: 0.2543, Src MixUp: 0.5077, Trg MixUp: 0.5618, Src Train Acc: 98.18, Trg Train Acc: 89.84, Src Test Acc: 97.67, Trg Test Acc: 90.39\n",
      "Epoch: 084, TotalL: 0.7441, CrossE: 0.0746, CondE: 0.2554, disc: 0.6128, domain: 0.9958, Src VAT: 0.1464, Trg VAT: 0.2554, Src MixUp: 0.5022, Trg MixUp: 0.5830, Src Train Acc: 98.00, Trg Train Acc: 90.10, Src Test Acc: 94.94, Trg Test Acc: 90.14\n",
      "Epoch: 085, TotalL: 0.7557, CrossE: 0.0822, CondE: 0.2602, disc: 0.6224, domain: 0.9753, Src VAT: 0.1510, Trg VAT: 0.2602, Src MixUp: 0.5019, Trg MixUp: 0.5602, Src Train Acc: 97.61, Trg Train Acc: 88.98, Src Test Acc: 97.28, Trg Test Acc: 91.73\n",
      "Epoch: 086, TotalL: 0.7447, CrossE: 0.0691, CondE: 0.2376, disc: 0.6259, domain: 0.9761, Src VAT: 0.1465, Trg VAT: 0.2376, Src MixUp: 0.5093, Trg MixUp: 0.5258, Src Train Acc: 98.09, Trg Train Acc: 89.37, Src Test Acc: 96.50, Trg Test Acc: 90.89\n",
      "Epoch: 087, TotalL: 0.7408, CrossE: 0.0763, CondE: 0.2379, disc: 0.6276, domain: 0.9821, Src VAT: 0.1451, Trg VAT: 0.2379, Src MixUp: 0.4994, Trg MixUp: 0.5441, Src Train Acc: 98.22, Trg Train Acc: 90.06, Src Test Acc: 97.28, Trg Test Acc: 90.64\n",
      "Epoch: 088, TotalL: 0.7533, CrossE: 0.0763, CondE: 0.2389, disc: 0.6193, domain: 0.9731, Src VAT: 0.1427, Trg VAT: 0.2389, Src MixUp: 0.5143, Trg MixUp: 0.5545, Src Train Acc: 97.79, Trg Train Acc: 90.93, Src Test Acc: 98.83, Trg Test Acc: 92.40\n",
      "Epoch: 089, TotalL: 0.7090, CrossE: 0.0679, CondE: 0.2368, disc: 0.6174, domain: 1.0010, Src VAT: 0.1351, Trg VAT: 0.2368, Src MixUp: 0.4858, Trg MixUp: 0.5469, Src Train Acc: 98.22, Trg Train Acc: 90.32, Src Test Acc: 98.44, Trg Test Acc: 91.14\n",
      "Epoch: 090, TotalL: 0.7172, CrossE: 0.0698, CondE: 0.2406, disc: 0.6225, domain: 0.9940, Src VAT: 0.1337, Trg VAT: 0.2406, Src MixUp: 0.4936, Trg MixUp: 0.5363, Src Train Acc: 98.09, Trg Train Acc: 89.63, Src Test Acc: 91.83, Trg Test Acc: 82.87\n",
      "Epoch: 091, TotalL: 0.7186, CrossE: 0.0795, CondE: 0.2388, disc: 0.6190, domain: 0.9884, Src VAT: 0.1382, Trg VAT: 0.2388, Src MixUp: 0.4807, Trg MixUp: 0.5607, Src Train Acc: 97.74, Trg Train Acc: 89.97, Src Test Acc: 94.94, Trg Test Acc: 90.23\n",
      "Epoch: 092, TotalL: 0.7262, CrossE: 0.0722, CondE: 0.2397, disc: 0.6146, domain: 0.9921, Src VAT: 0.1390, Trg VAT: 0.2397, Src MixUp: 0.4948, Trg MixUp: 0.5480, Src Train Acc: 98.09, Trg Train Acc: 89.54, Src Test Acc: 98.44, Trg Test Acc: 93.15\n",
      "Epoch: 093, TotalL: 0.7120, CrossE: 0.0647, CondE: 0.2415, disc: 0.6265, domain: 0.9776, Src VAT: 0.1330, Trg VAT: 0.2415, Src MixUp: 0.4942, Trg MixUp: 0.5469, Src Train Acc: 98.13, Trg Train Acc: 89.93, Src Test Acc: 95.72, Trg Test Acc: 89.72\n",
      "Epoch: 094, TotalL: 0.6926, CrossE: 0.0576, CondE: 0.2244, disc: 0.6271, domain: 0.9878, Src VAT: 0.1255, Trg VAT: 0.2244, Src MixUp: 0.4899, Trg MixUp: 0.5272, Src Train Acc: 98.57, Trg Train Acc: 91.19, Src Test Acc: 98.05, Trg Test Acc: 91.73\n",
      "Epoch: 095, TotalL: 0.6818, CrossE: 0.0562, CondE: 0.2425, disc: 0.6259, domain: 0.9818, Src VAT: 0.1216, Trg VAT: 0.2425, Src MixUp: 0.4838, Trg MixUp: 0.5495, Src Train Acc: 98.57, Trg Train Acc: 90.49, Src Test Acc: 98.44, Trg Test Acc: 92.56\n",
      "Epoch: 096, TotalL: 0.7392, CrossE: 0.0728, CondE: 0.2418, disc: 0.6213, domain: 0.9572, Src VAT: 0.1397, Trg VAT: 0.2418, Src MixUp: 0.5068, Trg MixUp: 0.5533, Src Train Acc: 97.92, Trg Train Acc: 90.32, Src Test Acc: 98.44, Trg Test Acc: 94.07\n",
      "Epoch: 097, TotalL: 0.7513, CrossE: 0.0702, CondE: 0.2434, disc: 0.6310, domain: 0.9328, Src VAT: 0.1398, Trg VAT: 0.2434, Src MixUp: 0.5218, Trg MixUp: 0.5352, Src Train Acc: 98.05, Trg Train Acc: 90.02, Src Test Acc: 98.44, Trg Test Acc: 94.74\n",
      "Epoch: 098, TotalL: 0.7322, CrossE: 0.0728, CondE: 0.2486, disc: 0.6218, domain: 0.9825, Src VAT: 0.1383, Trg VAT: 0.2486, Src MixUp: 0.5010, Trg MixUp: 0.5402, Src Train Acc: 97.79, Trg Train Acc: 90.06, Src Test Acc: 98.05, Trg Test Acc: 92.90\n",
      "Epoch: 099, TotalL: 0.6952, CrossE: 0.0603, CondE: 0.2370, disc: 0.6275, domain: 0.9770, Src VAT: 0.1242, Trg VAT: 0.2370, Src MixUp: 0.4908, Trg MixUp: 0.5401, Src Train Acc: 98.61, Trg Train Acc: 89.93, Src Test Acc: 94.94, Trg Test Acc: 89.14\n",
      "Epoch: 100, TotalL: 0.6436, CrossE: 0.0507, CondE: 0.2101, disc: 0.6115, domain: 0.9918, Src VAT: 0.1178, Trg VAT: 0.2101, Src MixUp: 0.4558, Trg MixUp: 0.5145, Src Train Acc: 98.91, Trg Train Acc: 91.15, Src Test Acc: 97.28, Trg Test Acc: 91.65\n",
      "Epoch: 101, TotalL: 0.6903, CrossE: 0.0646, CondE: 0.2302, disc: 0.6207, domain: 0.9814, Src VAT: 0.1243, Trg VAT: 0.2302, Src MixUp: 0.4816, Trg MixUp: 0.5361, Src Train Acc: 98.65, Trg Train Acc: 90.10, Src Test Acc: 97.28, Trg Test Acc: 90.64\n",
      "Epoch: 102, TotalL: 0.6291, CrossE: 0.0527, CondE: 0.2131, disc: 0.6162, domain: 0.9733, Src VAT: 0.1092, Trg VAT: 0.2131, Src MixUp: 0.4478, Trg MixUp: 0.5318, Src Train Acc: 98.48, Trg Train Acc: 90.71, Src Test Acc: 97.67, Trg Test Acc: 91.98\n",
      "Epoch: 103, TotalL: 0.6757, CrossE: 0.0622, CondE: 0.2255, disc: 0.6234, domain: 0.9811, Src VAT: 0.1216, Trg VAT: 0.2255, Src MixUp: 0.4722, Trg MixUp: 0.5254, Src Train Acc: 98.22, Trg Train Acc: 90.58, Src Test Acc: 96.89, Trg Test Acc: 90.56\n",
      "Epoch: 104, TotalL: 0.6778, CrossE: 0.0599, CondE: 0.2224, disc: 0.6158, domain: 0.9995, Src VAT: 0.1194, Trg VAT: 0.2224, Src MixUp: 0.4788, Trg MixUp: 0.5246, Src Train Acc: 98.48, Trg Train Acc: 90.89, Src Test Acc: 96.11, Trg Test Acc: 88.89\n",
      "Epoch: 105, TotalL: 0.6951, CrossE: 0.0677, CondE: 0.2280, disc: 0.6148, domain: 0.9536, Src VAT: 0.1225, Trg VAT: 0.2280, Src MixUp: 0.4854, Trg MixUp: 0.5459, Src Train Acc: 98.05, Trg Train Acc: 90.41, Src Test Acc: 99.22, Trg Test Acc: 94.57\n",
      "Epoch: 106, TotalL: 0.6686, CrossE: 0.0572, CondE: 0.2217, disc: 0.6135, domain: 0.9988, Src VAT: 0.1202, Trg VAT: 0.2217, Src MixUp: 0.4716, Trg MixUp: 0.5124, Src Train Acc: 98.65, Trg Train Acc: 90.45, Src Test Acc: 98.44, Trg Test Acc: 93.90\n",
      "Epoch: 107, TotalL: 0.6576, CrossE: 0.0551, CondE: 0.2241, disc: 0.6183, domain: 1.0000, Src VAT: 0.1182, Trg VAT: 0.2241, Src MixUp: 0.4645, Trg MixUp: 0.5252, Src Train Acc: 98.48, Trg Train Acc: 90.23, Src Test Acc: 89.49, Trg Test Acc: 82.04\n",
      "Epoch: 108, TotalL: 0.6341, CrossE: 0.0494, CondE: 0.2135, disc: 0.6126, domain: 0.9788, Src VAT: 0.1059, Trg VAT: 0.2135, Src MixUp: 0.4596, Trg MixUp: 0.5174, Src Train Acc: 98.70, Trg Train Acc: 91.93, Src Test Acc: 95.33, Trg Test Acc: 90.89\n",
      "Epoch: 109, TotalL: 0.6749, CrossE: 0.0624, CondE: 0.2203, disc: 0.6158, domain: 0.9964, Src VAT: 0.1154, Trg VAT: 0.2203, Src MixUp: 0.4774, Trg MixUp: 0.5212, Src Train Acc: 98.13, Trg Train Acc: 90.93, Src Test Acc: 97.28, Trg Test Acc: 92.65\n",
      "Epoch: 110, TotalL: 0.6440, CrossE: 0.0489, CondE: 0.2132, disc: 0.6217, domain: 0.9769, Src VAT: 0.1080, Trg VAT: 0.2132, Src MixUp: 0.4679, Trg MixUp: 0.5068, Src Train Acc: 98.70, Trg Train Acc: 92.14, Src Test Acc: 98.83, Trg Test Acc: 91.48\n",
      "Epoch: 111, TotalL: 0.6298, CrossE: 0.0486, CondE: 0.2066, disc: 0.6234, domain: 0.9962, Src VAT: 0.1026, Trg VAT: 0.2066, Src MixUp: 0.4595, Trg MixUp: 0.5045, Src Train Acc: 98.65, Trg Train Acc: 91.06, Src Test Acc: 98.44, Trg Test Acc: 92.31\n",
      "Epoch: 112, TotalL: 0.6309, CrossE: 0.0555, CondE: 0.2077, disc: 0.6141, domain: 0.9921, Src VAT: 0.1111, Trg VAT: 0.2077, Src MixUp: 0.4452, Trg MixUp: 0.5001, Src Train Acc: 98.39, Trg Train Acc: 91.62, Src Test Acc: 97.67, Trg Test Acc: 90.89\n",
      "Epoch: 113, TotalL: 0.6181, CrossE: 0.0486, CondE: 0.2030, disc: 0.6172, domain: 0.9795, Src VAT: 0.1019, Trg VAT: 0.2030, Src MixUp: 0.4486, Trg MixUp: 0.5103, Src Train Acc: 98.78, Trg Train Acc: 90.62, Src Test Acc: 96.89, Trg Test Acc: 89.56\n",
      "Epoch: 114, TotalL: 0.6049, CrossE: 0.0470, CondE: 0.1955, disc: 0.6126, domain: 0.9788, Src VAT: 0.0998, Trg VAT: 0.1955, Src MixUp: 0.4395, Trg MixUp: 0.4939, Src Train Acc: 98.83, Trg Train Acc: 90.89, Src Test Acc: 97.67, Trg Test Acc: 91.98\n",
      "Epoch: 115, TotalL: 0.6088, CrossE: 0.0518, CondE: 0.2006, disc: 0.6124, domain: 0.9795, Src VAT: 0.1036, Trg VAT: 0.2006, Src MixUp: 0.4348, Trg MixUp: 0.4804, Src Train Acc: 98.57, Trg Train Acc: 91.58, Src Test Acc: 96.50, Trg Test Acc: 91.31\n",
      "Epoch: 116, TotalL: 0.6469, CrossE: 0.0695, CondE: 0.2089, disc: 0.6088, domain: 0.9872, Src VAT: 0.1143, Trg VAT: 0.2089, Src MixUp: 0.4439, Trg MixUp: 0.5112, Src Train Acc: 97.96, Trg Train Acc: 91.49, Src Test Acc: 96.11, Trg Test Acc: 92.23\n",
      "Epoch: 117, TotalL: 0.5902, CrossE: 0.0474, CondE: 0.1985, disc: 0.6122, domain: 0.9938, Src VAT: 0.0958, Trg VAT: 0.1985, Src MixUp: 0.4281, Trg MixUp: 0.5056, Src Train Acc: 98.61, Trg Train Acc: 92.10, Src Test Acc: 95.72, Trg Test Acc: 93.15\n",
      "Epoch: 118, TotalL: 0.6031, CrossE: 0.0485, CondE: 0.2014, disc: 0.6108, domain: 1.0022, Src VAT: 0.1018, Trg VAT: 0.2014, Src MixUp: 0.4336, Trg MixUp: 0.5193, Src Train Acc: 98.96, Trg Train Acc: 91.93, Src Test Acc: 95.33, Trg Test Acc: 85.88\n",
      "Epoch: 119, TotalL: 0.5876, CrossE: 0.0354, CondE: 0.2014, disc: 0.6036, domain: 1.0093, Src VAT: 0.0890, Trg VAT: 0.2014, Src MixUp: 0.4441, Trg MixUp: 0.4930, Src Train Acc: 99.18, Trg Train Acc: 91.84, Src Test Acc: 98.05, Trg Test Acc: 95.49\n",
      "Epoch: 120, TotalL: 0.6064, CrossE: 0.0423, CondE: 0.1987, disc: 0.6032, domain: 1.0121, Src VAT: 0.0955, Trg VAT: 0.1987, Src MixUp: 0.4496, Trg MixUp: 0.4983, Src Train Acc: 99.05, Trg Train Acc: 92.06, Src Test Acc: 97.67, Trg Test Acc: 92.48\n",
      "Epoch: 121, TotalL: 0.6020, CrossE: 0.0512, CondE: 0.1959, disc: 0.6118, domain: 1.0165, Src VAT: 0.1000, Trg VAT: 0.1959, Src MixUp: 0.4317, Trg MixUp: 0.5008, Src Train Acc: 98.39, Trg Train Acc: 91.10, Src Test Acc: 97.28, Trg Test Acc: 89.06\n",
      "Epoch: 122, TotalL: 0.5525, CrossE: 0.0320, CondE: 0.1801, disc: 0.6046, domain: 1.0214, Src VAT: 0.0818, Trg VAT: 0.1801, Src MixUp: 0.4202, Trg MixUp: 0.4806, Src Train Acc: 99.48, Trg Train Acc: 92.93, Src Test Acc: 97.67, Trg Test Acc: 95.32\n",
      "Epoch: 123, TotalL: 0.5765, CrossE: 0.0410, CondE: 0.1885, disc: 0.6078, domain: 1.0167, Src VAT: 0.0924, Trg VAT: 0.1885, Src MixUp: 0.4243, Trg MixUp: 0.4908, Src Train Acc: 99.05, Trg Train Acc: 91.45, Src Test Acc: 99.22, Trg Test Acc: 93.73\n",
      "Epoch: 124, TotalL: 0.5885, CrossE: 0.0488, CondE: 0.1912, disc: 0.6117, domain: 1.0273, Src VAT: 0.0971, Trg VAT: 0.1912, Src MixUp: 0.4237, Trg MixUp: 0.4815, Src Train Acc: 98.52, Trg Train Acc: 90.67, Src Test Acc: 99.22, Trg Test Acc: 93.98\n",
      "Epoch: 125, TotalL: 0.5538, CrossE: 0.0397, CondE: 0.1784, disc: 0.6032, domain: 1.0085, Src VAT: 0.0862, Trg VAT: 0.1784, Src MixUp: 0.4095, Trg MixUp: 0.4683, Src Train Acc: 98.91, Trg Train Acc: 92.84, Src Test Acc: 98.83, Trg Test Acc: 95.57\n",
      "Epoch: 126, TotalL: 0.6063, CrossE: 0.0484, CondE: 0.1983, disc: 0.6076, domain: 1.0028, Src VAT: 0.0977, Trg VAT: 0.1983, Src MixUp: 0.4412, Trg MixUp: 0.5095, Src Train Acc: 98.78, Trg Train Acc: 91.84, Src Test Acc: 98.44, Trg Test Acc: 95.15\n",
      "Epoch: 127, TotalL: 0.5921, CrossE: 0.0499, CondE: 0.1886, disc: 0.6047, domain: 1.0085, Src VAT: 0.0928, Trg VAT: 0.1886, Src MixUp: 0.4307, Trg MixUp: 0.4848, Src Train Acc: 98.70, Trg Train Acc: 91.80, Src Test Acc: 97.28, Trg Test Acc: 91.98\n",
      "Epoch: 128, TotalL: 0.5615, CrossE: 0.0433, CondE: 0.1907, disc: 0.6063, domain: 1.0232, Src VAT: 0.0879, Trg VAT: 0.1907, Src MixUp: 0.4113, Trg MixUp: 0.4976, Src Train Acc: 98.78, Trg Train Acc: 91.88, Src Test Acc: 96.89, Trg Test Acc: 90.48\n",
      "Epoch: 129, TotalL: 0.6117, CrossE: 0.0425, CondE: 0.2069, disc: 0.6099, domain: 0.9960, Src VAT: 0.0994, Trg VAT: 0.2069, Src MixUp: 0.4507, Trg MixUp: 0.5044, Src Train Acc: 98.91, Trg Train Acc: 91.54, Src Test Acc: 98.44, Trg Test Acc: 94.90\n",
      "Epoch: 130, TotalL: 0.5878, CrossE: 0.0464, CondE: 0.1892, disc: 0.6048, domain: 1.0080, Src VAT: 0.0890, Trg VAT: 0.1892, Src MixUp: 0.4337, Trg MixUp: 0.4902, Src Train Acc: 99.05, Trg Train Acc: 92.40, Src Test Acc: 98.05, Trg Test Acc: 91.65\n",
      "Epoch: 131, TotalL: 0.5802, CrossE: 0.0433, CondE: 0.1924, disc: 0.6044, domain: 1.0141, Src VAT: 0.0910, Trg VAT: 0.1924, Src MixUp: 0.4269, Trg MixUp: 0.5004, Src Train Acc: 98.87, Trg Train Acc: 92.62, Src Test Acc: 98.44, Trg Test Acc: 93.48\n",
      "Epoch: 132, TotalL: 0.5378, CrossE: 0.0318, CondE: 0.1918, disc: 0.5898, domain: 1.0184, Src VAT: 0.0805, Trg VAT: 0.1918, Src MixUp: 0.4067, Trg MixUp: 0.4740, Src Train Acc: 99.13, Trg Train Acc: 92.84, Src Test Acc: 99.22, Trg Test Acc: 95.24\n",
      "Epoch: 133, TotalL: 0.5982, CrossE: 0.0523, CondE: 0.1960, disc: 0.6033, domain: 1.0047, Src VAT: 0.0948, Trg VAT: 0.1960, Src MixUp: 0.4323, Trg MixUp: 0.4837, Src Train Acc: 98.70, Trg Train Acc: 90.93, Src Test Acc: 98.05, Trg Test Acc: 93.40\n",
      "Epoch: 134, TotalL: 0.5679, CrossE: 0.0422, CondE: 0.1922, disc: 0.6096, domain: 1.0288, Src VAT: 0.0916, Trg VAT: 0.1922, Src MixUp: 0.4152, Trg MixUp: 0.4789, Src Train Acc: 98.91, Trg Train Acc: 92.06, Src Test Acc: 98.44, Trg Test Acc: 94.49\n",
      "Epoch: 135, TotalL: 0.5733, CrossE: 0.0384, CondE: 0.1940, disc: 0.6034, domain: 0.9956, Src VAT: 0.0842, Trg VAT: 0.1940, Src MixUp: 0.4321, Trg MixUp: 0.4854, Src Train Acc: 98.91, Trg Train Acc: 92.14, Src Test Acc: 98.83, Trg Test Acc: 94.24\n",
      "Epoch: 136, TotalL: 0.5678, CrossE: 0.0402, CondE: 0.1968, disc: 0.6002, domain: 1.0122, Src VAT: 0.0854, Trg VAT: 0.1968, Src MixUp: 0.4232, Trg MixUp: 0.4947, Src Train Acc: 98.91, Trg Train Acc: 92.32, Src Test Acc: 99.61, Trg Test Acc: 96.99\n",
      "Epoch: 137, TotalL: 0.5372, CrossE: 0.0322, CondE: 0.1825, disc: 0.5989, domain: 1.0215, Src VAT: 0.0779, Trg VAT: 0.1825, Src MixUp: 0.4083, Trg MixUp: 0.4896, Src Train Acc: 99.09, Trg Train Acc: 92.71, Src Test Acc: 97.67, Trg Test Acc: 93.40\n",
      "Epoch: 138, TotalL: 0.5468, CrossE: 0.0298, CondE: 0.1809, disc: 0.5982, domain: 1.0152, Src VAT: 0.0765, Trg VAT: 0.1809, Src MixUp: 0.4220, Trg MixUp: 0.4735, Src Train Acc: 99.48, Trg Train Acc: 92.93, Src Test Acc: 98.83, Trg Test Acc: 95.49\n",
      "Epoch: 139, TotalL: 0.5317, CrossE: 0.0278, CondE: 0.1770, disc: 0.5997, domain: 1.0230, Src VAT: 0.0762, Trg VAT: 0.1770, Src MixUp: 0.4094, Trg MixUp: 0.4539, Src Train Acc: 99.39, Trg Train Acc: 93.32, Src Test Acc: 98.44, Trg Test Acc: 91.98\n",
      "Epoch: 140, TotalL: 0.5765, CrossE: 0.0373, CondE: 0.1846, disc: 0.6034, domain: 1.0099, Src VAT: 0.0907, Trg VAT: 0.1846, Src MixUp: 0.4300, Trg MixUp: 0.4731, Src Train Acc: 99.31, Trg Train Acc: 92.40, Src Test Acc: 99.22, Trg Test Acc: 96.07\n",
      "Epoch: 141, TotalL: 0.5504, CrossE: 0.0351, CondE: 0.1776, disc: 0.5996, domain: 1.0109, Src VAT: 0.0817, Trg VAT: 0.1776, Src MixUp: 0.4153, Trg MixUp: 0.4640, Src Train Acc: 99.35, Trg Train Acc: 92.80, Src Test Acc: 96.50, Trg Test Acc: 89.31\n",
      "Epoch: 142, TotalL: 0.5451, CrossE: 0.0340, CondE: 0.1780, disc: 0.5964, domain: 1.0064, Src VAT: 0.0816, Trg VAT: 0.1780, Src MixUp: 0.4111, Trg MixUp: 0.4789, Src Train Acc: 99.13, Trg Train Acc: 92.58, Src Test Acc: 98.83, Trg Test Acc: 94.15\n",
      "Epoch: 143, TotalL: 0.5469, CrossE: 0.0348, CondE: 0.1897, disc: 0.6132, domain: 1.0063, Src VAT: 0.0811, Trg VAT: 0.1897, Src MixUp: 0.4125, Trg MixUp: 0.4746, Src Train Acc: 99.22, Trg Train Acc: 92.06, Src Test Acc: 98.44, Trg Test Acc: 95.74\n",
      "Epoch: 144, TotalL: 0.5238, CrossE: 0.0387, CondE: 0.1793, disc: 0.6048, domain: 1.0238, Src VAT: 0.0776, Trg VAT: 0.1793, Src MixUp: 0.3888, Trg MixUp: 0.4877, Src Train Acc: 99.00, Trg Train Acc: 92.06, Src Test Acc: 98.83, Trg Test Acc: 95.91\n",
      "Epoch: 145, TotalL: 0.5252, CrossE: 0.0347, CondE: 0.1697, disc: 0.6029, domain: 1.0130, Src VAT: 0.0763, Trg VAT: 0.1697, Src MixUp: 0.3962, Trg MixUp: 0.4541, Src Train Acc: 99.00, Trg Train Acc: 93.23, Src Test Acc: 92.61, Trg Test Acc: 89.39\n",
      "Epoch: 146, TotalL: 0.5302, CrossE: 0.0368, CondE: 0.1807, disc: 0.6021, domain: 1.0221, Src VAT: 0.0736, Trg VAT: 0.1807, Src MixUp: 0.4010, Trg MixUp: 0.4930, Src Train Acc: 99.22, Trg Train Acc: 92.27, Src Test Acc: 97.28, Trg Test Acc: 93.32\n",
      "Epoch: 147, TotalL: 0.5342, CrossE: 0.0294, CondE: 0.1790, disc: 0.6043, domain: 1.0051, Src VAT: 0.0800, Trg VAT: 0.1790, Src MixUp: 0.4065, Trg MixUp: 0.4558, Src Train Acc: 99.44, Trg Train Acc: 92.80, Src Test Acc: 97.67, Trg Test Acc: 91.98\n",
      "Epoch: 148, TotalL: 0.5275, CrossE: 0.0352, CondE: 0.1840, disc: 0.6066, domain: 1.0285, Src VAT: 0.0789, Trg VAT: 0.1840, Src MixUp: 0.3945, Trg MixUp: 0.4831, Src Train Acc: 98.91, Trg Train Acc: 92.36, Src Test Acc: 99.22, Trg Test Acc: 95.66\n",
      "Epoch: 149, TotalL: 0.4655, CrossE: 0.0217, CondE: 0.1583, disc: 0.5985, domain: 1.0410, Src VAT: 0.0614, Trg VAT: 0.1583, Src MixUp: 0.3645, Trg MixUp: 0.4335, Src Train Acc: 99.61, Trg Train Acc: 93.10, Src Test Acc: 98.05, Trg Test Acc: 91.31\n",
      "Epoch: 150, TotalL: 0.5933, CrossE: 0.0650, CondE: 0.1864, disc: 0.6132, domain: 0.9966, Src VAT: 0.0938, Trg VAT: 0.1864, Src MixUp: 0.4162, Trg MixUp: 0.4666, Src Train Acc: 98.09, Trg Train Acc: 91.58, Src Test Acc: 98.44, Trg Test Acc: 94.49\n",
      "Epoch: 151, TotalL: 0.5260, CrossE: 0.0339, CondE: 0.1754, disc: 0.6030, domain: 1.0095, Src VAT: 0.0766, Trg VAT: 0.1754, Src MixUp: 0.3974, Trg MixUp: 0.4493, Src Train Acc: 98.96, Trg Train Acc: 93.23, Src Test Acc: 97.67, Trg Test Acc: 93.07\n",
      "Epoch: 152, TotalL: 0.6266, CrossE: 0.0537, CondE: 0.1996, disc: 0.6224, domain: 1.0015, Src VAT: 0.1026, Trg VAT: 0.1996, Src MixUp: 0.4516, Trg MixUp: 0.4772, Src Train Acc: 98.61, Trg Train Acc: 91.10, Src Test Acc: 98.83, Trg Test Acc: 94.57\n",
      "Epoch: 153, TotalL: 0.5055, CrossE: 0.0325, CondE: 0.1701, disc: 0.5984, domain: 1.0017, Src VAT: 0.0762, Trg VAT: 0.1701, Src MixUp: 0.3790, Trg MixUp: 0.4389, Src Train Acc: 99.05, Trg Train Acc: 93.01, Src Test Acc: 97.28, Trg Test Acc: 94.57\n",
      "Epoch: 154, TotalL: 0.5204, CrossE: 0.0298, CondE: 0.1586, disc: 0.6072, domain: 1.0212, Src VAT: 0.0689, Trg VAT: 0.1586, Src MixUp: 0.4039, Trg MixUp: 0.4407, Src Train Acc: 99.31, Trg Train Acc: 93.84, Src Test Acc: 98.05, Trg Test Acc: 94.90\n",
      "Epoch: 155, TotalL: 0.4945, CrossE: 0.0281, CondE: 0.1576, disc: 0.6036, domain: 1.0191, Src VAT: 0.0673, Trg VAT: 0.1576, Src MixUp: 0.3814, Trg MixUp: 0.4385, Src Train Acc: 99.26, Trg Train Acc: 93.45, Src Test Acc: 98.05, Trg Test Acc: 91.73\n",
      "Epoch: 156, TotalL: 0.5173, CrossE: 0.0276, CondE: 0.1791, disc: 0.6063, domain: 1.0119, Src VAT: 0.0734, Trg VAT: 0.1791, Src MixUp: 0.3980, Trg MixUp: 0.4512, Src Train Acc: 99.44, Trg Train Acc: 91.97, Src Test Acc: 96.11, Trg Test Acc: 92.15\n",
      "Epoch: 157, TotalL: 0.5165, CrossE: 0.0317, CondE: 0.1687, disc: 0.6023, domain: 1.0271, Src VAT: 0.0746, Trg VAT: 0.1687, Src MixUp: 0.3922, Trg MixUp: 0.4424, Src Train Acc: 99.18, Trg Train Acc: 93.06, Src Test Acc: 97.67, Trg Test Acc: 91.56\n",
      "Epoch: 158, TotalL: 0.5252, CrossE: 0.0265, CondE: 0.1760, disc: 0.6056, domain: 1.0166, Src VAT: 0.0724, Trg VAT: 0.1760, Src MixUp: 0.4081, Trg MixUp: 0.4517, Src Train Acc: 99.39, Trg Train Acc: 92.66, Src Test Acc: 97.67, Trg Test Acc: 93.32\n",
      "Epoch: 159, TotalL: 0.4991, CrossE: 0.0270, CondE: 0.1597, disc: 0.6056, domain: 1.0087, Src VAT: 0.0666, Trg VAT: 0.1597, Src MixUp: 0.3879, Trg MixUp: 0.4297, Src Train Acc: 99.44, Trg Train Acc: 93.36, Src Test Acc: 93.00, Trg Test Acc: 88.97\n",
      "Epoch: 160, TotalL: 0.5181, CrossE: 0.0430, CondE: 0.1659, disc: 0.6082, domain: 1.0001, Src VAT: 0.0761, Trg VAT: 0.1659, Src MixUp: 0.3811, Trg MixUp: 0.4561, Src Train Acc: 99.00, Trg Train Acc: 93.23, Src Test Acc: 97.67, Trg Test Acc: 93.90\n",
      "Epoch: 161, TotalL: 0.5295, CrossE: 0.0310, CondE: 0.1677, disc: 0.5999, domain: 1.0086, Src VAT: 0.0682, Trg VAT: 0.1677, Src MixUp: 0.4124, Trg MixUp: 0.4455, Src Train Acc: 99.26, Trg Train Acc: 93.32, Src Test Acc: 98.44, Trg Test Acc: 95.07\n",
      "Epoch: 162, TotalL: 0.4919, CrossE: 0.0266, CondE: 0.1578, disc: 0.6011, domain: 1.0076, Src VAT: 0.0675, Trg VAT: 0.1578, Src MixUp: 0.3803, Trg MixUp: 0.4263, Src Train Acc: 99.26, Trg Train Acc: 93.36, Src Test Acc: 98.44, Trg Test Acc: 91.81\n",
      "Epoch: 163, TotalL: 0.4934, CrossE: 0.0260, CondE: 0.1632, disc: 0.6009, domain: 0.9888, Src VAT: 0.0625, Trg VAT: 0.1632, Src MixUp: 0.3872, Trg MixUp: 0.4501, Src Train Acc: 99.13, Trg Train Acc: 94.27, Src Test Acc: 96.89, Trg Test Acc: 91.90\n",
      "Epoch: 164, TotalL: 0.5001, CrossE: 0.0234, CondE: 0.1665, disc: 0.5995, domain: 1.0032, Src VAT: 0.0661, Trg VAT: 0.1665, Src MixUp: 0.3927, Trg MixUp: 0.4633, Src Train Acc: 99.39, Trg Train Acc: 93.40, Src Test Acc: 99.22, Trg Test Acc: 93.98\n",
      "Epoch: 165, TotalL: 0.4793, CrossE: 0.0270, CondE: 0.1615, disc: 0.6152, domain: 1.0137, Src VAT: 0.0679, Trg VAT: 0.1615, Src MixUp: 0.3666, Trg MixUp: 0.4358, Src Train Acc: 99.39, Trg Train Acc: 93.19, Src Test Acc: 95.72, Trg Test Acc: 91.98\n",
      "Epoch: 166, TotalL: 0.4727, CrossE: 0.0228, CondE: 0.1579, disc: 0.5963, domain: 1.0106, Src VAT: 0.0589, Trg VAT: 0.1579, Src MixUp: 0.3734, Trg MixUp: 0.4293, Src Train Acc: 99.52, Trg Train Acc: 93.45, Src Test Acc: 95.72, Trg Test Acc: 91.23\n",
      "Epoch: 167, TotalL: 0.4731, CrossE: 0.0204, CondE: 0.1468, disc: 0.5996, domain: 1.0255, Src VAT: 0.0610, Trg VAT: 0.1468, Src MixUp: 0.3744, Trg MixUp: 0.4244, Src Train Acc: 99.70, Trg Train Acc: 94.18, Src Test Acc: 99.61, Trg Test Acc: 94.24\n",
      "Epoch: 168, TotalL: 0.4977, CrossE: 0.0279, CondE: 0.1595, disc: 0.6141, domain: 1.0174, Src VAT: 0.0672, Trg VAT: 0.1595, Src MixUp: 0.3850, Trg MixUp: 0.4220, Src Train Acc: 99.35, Trg Train Acc: 93.32, Src Test Acc: 91.44, Trg Test Acc: 88.72\n",
      "Epoch: 169, TotalL: 0.5037, CrossE: 0.0250, CondE: 0.1598, disc: 0.6136, domain: 0.9749, Src VAT: 0.0682, Trg VAT: 0.1598, Src MixUp: 0.3931, Trg MixUp: 0.4329, Src Train Acc: 99.52, Trg Train Acc: 93.40, Src Test Acc: 96.89, Trg Test Acc: 94.57\n",
      "Epoch: 170, TotalL: 0.5057, CrossE: 0.0318, CondE: 0.1654, disc: 0.6193, domain: 0.9944, Src VAT: 0.0676, Trg VAT: 0.1654, Src MixUp: 0.3887, Trg MixUp: 0.4393, Src Train Acc: 99.09, Trg Train Acc: 92.88, Src Test Acc: 98.83, Trg Test Acc: 91.56\n",
      "Epoch: 171, TotalL: 0.5254, CrossE: 0.0353, CondE: 0.1804, disc: 0.6143, domain: 0.9975, Src VAT: 0.0771, Trg VAT: 0.1804, Src MixUp: 0.3949, Trg MixUp: 0.4482, Src Train Acc: 99.05, Trg Train Acc: 92.49, Src Test Acc: 97.28, Trg Test Acc: 93.40\n",
      "Epoch: 172, TotalL: 0.4540, CrossE: 0.0209, CondE: 0.1493, disc: 0.5927, domain: 1.0220, Src VAT: 0.0554, Trg VAT: 0.1493, Src MixUp: 0.3602, Trg MixUp: 0.4337, Src Train Acc: 99.61, Trg Train Acc: 94.01, Src Test Acc: 98.44, Trg Test Acc: 96.99\n",
      "Epoch: 173, TotalL: 0.4576, CrossE: 0.0215, CondE: 0.1567, disc: 0.6060, domain: 1.0277, Src VAT: 0.0567, Trg VAT: 0.1567, Src MixUp: 0.3617, Trg MixUp: 0.4374, Src Train Acc: 99.61, Trg Train Acc: 94.36, Src Test Acc: 99.61, Trg Test Acc: 96.07\n",
      "Epoch: 174, TotalL: 0.4614, CrossE: 0.0276, CondE: 0.1505, disc: 0.6184, domain: 1.0079, Src VAT: 0.0574, Trg VAT: 0.1505, Src MixUp: 0.3591, Trg MixUp: 0.4264, Src Train Acc: 99.26, Trg Train Acc: 93.92, Src Test Acc: 98.83, Trg Test Acc: 96.41\n",
      "Epoch: 175, TotalL: 0.4692, CrossE: 0.0240, CondE: 0.1453, disc: 0.6024, domain: 0.9961, Src VAT: 0.0588, Trg VAT: 0.1453, Src MixUp: 0.3694, Trg MixUp: 0.4093, Src Train Acc: 99.61, Trg Train Acc: 93.84, Src Test Acc: 99.61, Trg Test Acc: 94.07\n",
      "Epoch: 176, TotalL: 0.4504, CrossE: 0.0238, CondE: 0.1377, disc: 0.5942, domain: 1.0191, Src VAT: 0.0514, Trg VAT: 0.1377, Src MixUp: 0.3583, Trg MixUp: 0.4019, Src Train Acc: 99.48, Trg Train Acc: 93.88, Src Test Acc: 98.44, Trg Test Acc: 96.07\n",
      "Epoch: 177, TotalL: 0.4776, CrossE: 0.0250, CondE: 0.1511, disc: 0.6051, domain: 1.0010, Src VAT: 0.0591, Trg VAT: 0.1511, Src MixUp: 0.3761, Trg MixUp: 0.4328, Src Train Acc: 99.35, Trg Train Acc: 93.62, Src Test Acc: 98.83, Trg Test Acc: 95.49\n",
      "Epoch: 178, TotalL: 0.4823, CrossE: 0.0261, CondE: 0.1527, disc: 0.6049, domain: 1.0087, Src VAT: 0.0613, Trg VAT: 0.1527, Src MixUp: 0.3775, Trg MixUp: 0.4278, Src Train Acc: 99.35, Trg Train Acc: 93.36, Src Test Acc: 99.61, Trg Test Acc: 95.15\n",
      "Epoch: 179, TotalL: 0.4664, CrossE: 0.0249, CondE: 0.1513, disc: 0.6046, domain: 1.0006, Src VAT: 0.0610, Trg VAT: 0.1513, Src MixUp: 0.3630, Trg MixUp: 0.4471, Src Train Acc: 99.48, Trg Train Acc: 93.71, Src Test Acc: 94.55, Trg Test Acc: 90.81\n",
      "Epoch: 180, TotalL: 0.4999, CrossE: 0.0355, CondE: 0.1599, disc: 0.6119, domain: 1.0124, Src VAT: 0.0693, Trg VAT: 0.1599, Src MixUp: 0.3776, Trg MixUp: 0.4150, Src Train Acc: 99.00, Trg Train Acc: 92.19, Src Test Acc: 98.05, Trg Test Acc: 94.07\n",
      "Epoch: 181, TotalL: 0.4640, CrossE: 0.0320, CondE: 0.1571, disc: 0.6090, domain: 1.0018, Src VAT: 0.0580, Trg VAT: 0.1571, Src MixUp: 0.3566, Trg MixUp: 0.4226, Src Train Acc: 99.09, Trg Train Acc: 94.05, Src Test Acc: 98.05, Trg Test Acc: 93.82\n",
      "Epoch: 182, TotalL: 0.4903, CrossE: 0.0359, CondE: 0.1614, disc: 0.6095, domain: 1.0149, Src VAT: 0.0691, Trg VAT: 0.1614, Src MixUp: 0.3677, Trg MixUp: 0.4295, Src Train Acc: 99.09, Trg Train Acc: 92.80, Src Test Acc: 97.28, Trg Test Acc: 91.56\n",
      "Epoch: 183, TotalL: 0.4624, CrossE: 0.0212, CondE: 0.1426, disc: 0.6024, domain: 1.0026, Src VAT: 0.0546, Trg VAT: 0.1426, Src MixUp: 0.3694, Trg MixUp: 0.4316, Src Train Acc: 99.70, Trg Train Acc: 94.49, Src Test Acc: 98.44, Trg Test Acc: 92.31\n",
      "Epoch: 184, TotalL: 0.4933, CrossE: 0.0299, CondE: 0.1674, disc: 0.5940, domain: 1.0050, Src VAT: 0.0647, Trg VAT: 0.1674, Src MixUp: 0.3808, Trg MixUp: 0.4420, Src Train Acc: 99.26, Trg Train Acc: 93.14, Src Test Acc: 99.22, Trg Test Acc: 92.82\n",
      "Epoch: 185, TotalL: 0.4285, CrossE: 0.0218, CondE: 0.1465, disc: 0.5937, domain: 1.0395, Src VAT: 0.0488, Trg VAT: 0.1465, Src MixUp: 0.3406, Trg MixUp: 0.3927, Src Train Acc: 99.52, Trg Train Acc: 93.71, Src Test Acc: 98.83, Trg Test Acc: 96.24\n",
      "Epoch: 186, TotalL: 0.4558, CrossE: 0.0233, CondE: 0.1546, disc: 0.6035, domain: 1.0102, Src VAT: 0.0534, Trg VAT: 0.1546, Src MixUp: 0.3615, Trg MixUp: 0.4460, Src Train Acc: 99.35, Trg Train Acc: 93.97, Src Test Acc: 97.67, Trg Test Acc: 93.57\n",
      "Epoch: 187, TotalL: 0.5041, CrossE: 0.0354, CondE: 0.1632, disc: 0.6023, domain: 1.0202, Src VAT: 0.0684, Trg VAT: 0.1632, Src MixUp: 0.3824, Trg MixUp: 0.4433, Src Train Acc: 98.74, Trg Train Acc: 92.88, Src Test Acc: 96.89, Trg Test Acc: 88.55\n",
      "Epoch: 188, TotalL: 0.4610, CrossE: 0.0242, CondE: 0.1568, disc: 0.5982, domain: 1.0240, Src VAT: 0.0582, Trg VAT: 0.1568, Src MixUp: 0.3607, Trg MixUp: 0.4541, Src Train Acc: 99.31, Trg Train Acc: 93.84, Src Test Acc: 98.05, Trg Test Acc: 93.07\n",
      "Epoch: 189, TotalL: 0.4076, CrossE: 0.0166, CondE: 0.1381, disc: 0.5861, domain: 1.0621, Src VAT: 0.0459, Trg VAT: 0.1381, Src MixUp: 0.3279, Trg MixUp: 0.3908, Src Train Acc: 99.65, Trg Train Acc: 94.70, Src Test Acc: 95.33, Trg Test Acc: 93.07\n",
      "Epoch: 190, TotalL: 0.4278, CrossE: 0.0244, CondE: 0.1414, disc: 0.6014, domain: 1.0471, Src VAT: 0.0509, Trg VAT: 0.1414, Src MixUp: 0.3349, Trg MixUp: 0.4278, Src Train Acc: 99.26, Trg Train Acc: 94.40, Src Test Acc: 97.28, Trg Test Acc: 93.07\n",
      "Epoch: 191, TotalL: 0.4394, CrossE: 0.0171, CondE: 0.1469, disc: 0.5918, domain: 1.0021, Src VAT: 0.0503, Trg VAT: 0.1469, Src MixUp: 0.3547, Trg MixUp: 0.4436, Src Train Acc: 99.61, Trg Train Acc: 94.49, Src Test Acc: 98.44, Trg Test Acc: 93.23\n",
      "Epoch: 192, TotalL: 0.4503, CrossE: 0.0197, CondE: 0.1495, disc: 0.5943, domain: 1.0297, Src VAT: 0.0566, Trg VAT: 0.1495, Src MixUp: 0.3565, Trg MixUp: 0.4251, Src Train Acc: 99.74, Trg Train Acc: 93.66, Src Test Acc: 99.22, Trg Test Acc: 93.15\n",
      "Epoch: 193, TotalL: 0.4337, CrossE: 0.0185, CondE: 0.1432, disc: 0.6003, domain: 1.0250, Src VAT: 0.0519, Trg VAT: 0.1432, Src MixUp: 0.3463, Trg MixUp: 0.3920, Src Train Acc: 99.57, Trg Train Acc: 94.36, Src Test Acc: 97.28, Trg Test Acc: 94.74\n",
      "Epoch: 194, TotalL: 0.4487, CrossE: 0.0211, CondE: 0.1471, disc: 0.6042, domain: 1.0212, Src VAT: 0.0567, Trg VAT: 0.1471, Src MixUp: 0.3537, Trg MixUp: 0.4165, Src Train Acc: 99.65, Trg Train Acc: 93.19, Src Test Acc: 97.28, Trg Test Acc: 94.07\n",
      "Epoch: 195, TotalL: 0.4315, CrossE: 0.0191, CondE: 0.1414, disc: 0.6039, domain: 1.0146, Src VAT: 0.0519, Trg VAT: 0.1414, Src MixUp: 0.3433, Trg MixUp: 0.4199, Src Train Acc: 99.61, Trg Train Acc: 93.79, Src Test Acc: 98.05, Trg Test Acc: 94.65\n",
      "Epoch: 196, TotalL: 0.4451, CrossE: 0.0220, CondE: 0.1535, disc: 0.5988, domain: 1.0066, Src VAT: 0.0548, Trg VAT: 0.1535, Src MixUp: 0.3510, Trg MixUp: 0.4238, Src Train Acc: 99.44, Trg Train Acc: 94.27, Src Test Acc: 98.05, Trg Test Acc: 92.31\n",
      "Epoch: 197, TotalL: 0.4654, CrossE: 0.0204, CondE: 0.1626, disc: 0.6048, domain: 1.0208, Src VAT: 0.0562, Trg VAT: 0.1626, Src MixUp: 0.3711, Trg MixUp: 0.4263, Src Train Acc: 99.52, Trg Train Acc: 93.14, Src Test Acc: 98.05, Trg Test Acc: 94.24\n",
      "Epoch: 198, TotalL: 0.4528, CrossE: 0.0226, CondE: 0.1620, disc: 0.6014, domain: 1.0469, Src VAT: 0.0545, Trg VAT: 0.1620, Src MixUp: 0.3577, Trg MixUp: 0.4353, Src Train Acc: 99.22, Trg Train Acc: 92.88, Src Test Acc: 97.67, Trg Test Acc: 92.73\n",
      "Epoch: 199, TotalL: 0.4388, CrossE: 0.0206, CondE: 0.1535, disc: 0.5970, domain: 1.0509, Src VAT: 0.0534, Trg VAT: 0.1535, Src MixUp: 0.3467, Trg MixUp: 0.4432, Src Train Acc: 99.65, Trg Train Acc: 92.97, Src Test Acc: 97.67, Trg Test Acc: 95.32\n",
      "Epoch: 200, TotalL: 0.4195, CrossE: 0.0215, CondE: 0.1374, disc: 0.5980, domain: 1.0308, Src VAT: 0.0522, Trg VAT: 0.1374, Src MixUp: 0.3287, Trg MixUp: 0.4095, Src Train Acc: 99.39, Trg Train Acc: 94.36, Src Test Acc: 96.11, Trg Test Acc: 93.65\n",
      "Epoch: 201, TotalL: 0.4516, CrossE: 0.0236, CondE: 0.1421, disc: 0.6011, domain: 1.0134, Src VAT: 0.0558, Trg VAT: 0.1421, Src MixUp: 0.3552, Trg MixUp: 0.4097, Src Train Acc: 99.57, Trg Train Acc: 93.19, Src Test Acc: 94.55, Trg Test Acc: 89.31\n",
      "Epoch: 202, TotalL: 0.4829, CrossE: 0.0247, CondE: 0.1494, disc: 0.6085, domain: 1.0147, Src VAT: 0.0618, Trg VAT: 0.1494, Src MixUp: 0.3791, Trg MixUp: 0.4144, Src Train Acc: 99.35, Trg Train Acc: 94.01, Src Test Acc: 99.61, Trg Test Acc: 96.49\n",
      "Epoch: 203, TotalL: 0.4447, CrossE: 0.0222, CondE: 0.1400, disc: 0.5850, domain: 1.0316, Src VAT: 0.0489, Trg VAT: 0.1400, Src MixUp: 0.3564, Trg MixUp: 0.4083, Src Train Acc: 99.44, Trg Train Acc: 95.10, Src Test Acc: 100.00, Trg Test Acc: 96.66\n",
      "Epoch: 204, TotalL: 0.4149, CrossE: 0.0201, CondE: 0.1385, disc: 0.5934, domain: 1.0599, Src VAT: 0.0480, Trg VAT: 0.1385, Src MixUp: 0.3295, Trg MixUp: 0.4038, Src Train Acc: 99.48, Trg Train Acc: 95.05, Src Test Acc: 98.83, Trg Test Acc: 90.64\n",
      "Epoch: 205, TotalL: 0.4559, CrossE: 0.0195, CondE: 0.1490, disc: 0.5905, domain: 1.0476, Src VAT: 0.0556, Trg VAT: 0.1490, Src MixUp: 0.3634, Trg MixUp: 0.3999, Src Train Acc: 99.57, Trg Train Acc: 93.71, Src Test Acc: 97.67, Trg Test Acc: 92.23\n",
      "Epoch: 206, TotalL: 0.4544, CrossE: 0.0196, CondE: 0.1416, disc: 0.5892, domain: 1.0502, Src VAT: 0.0543, Trg VAT: 0.1416, Src MixUp: 0.3632, Trg MixUp: 0.4116, Src Train Acc: 99.70, Trg Train Acc: 94.36, Src Test Acc: 99.22, Trg Test Acc: 95.82\n",
      "Epoch: 207, TotalL: 0.4164, CrossE: 0.0162, CondE: 0.1424, disc: 0.5861, domain: 1.0583, Src VAT: 0.0492, Trg VAT: 0.1424, Src MixUp: 0.3334, Trg MixUp: 0.4140, Src Train Acc: 99.61, Trg Train Acc: 94.05, Src Test Acc: 98.05, Trg Test Acc: 93.90\n",
      "Epoch: 208, TotalL: 0.4601, CrossE: 0.0246, CondE: 0.1546, disc: 0.6022, domain: 1.0441, Src VAT: 0.0604, Trg VAT: 0.1546, Src MixUp: 0.3573, Trg MixUp: 0.4213, Src Train Acc: 99.35, Trg Train Acc: 93.66, Src Test Acc: 98.83, Trg Test Acc: 95.07\n",
      "Epoch: 209, TotalL: 0.4596, CrossE: 0.0309, CondE: 0.1467, disc: 0.5934, domain: 1.0341, Src VAT: 0.0573, Trg VAT: 0.1467, Src MixUp: 0.3540, Trg MixUp: 0.4073, Src Train Acc: 99.09, Trg Train Acc: 93.10, Src Test Acc: 98.44, Trg Test Acc: 91.98\n",
      "Epoch: 210, TotalL: 0.4405, CrossE: 0.0169, CondE: 0.1485, disc: 0.5880, domain: 1.0446, Src VAT: 0.0499, Trg VAT: 0.1485, Src MixUp: 0.3560, Trg MixUp: 0.4264, Src Train Acc: 99.65, Trg Train Acc: 93.97, Src Test Acc: 98.83, Trg Test Acc: 95.99\n"
     ]
    }
   ],
   "source": [
    "train_template = 'Epoch: {:03d}, TotalL: {:.4f}, CrossE: {:.4f}, CondE: {:.4f}, disc: {:.4f}, domain: {:.4f}, Src VAT: {:.4f}, Trg VAT: {:.4f}, Src MixUp: {:.4f}, Trg MixUp: {:.4f}, Src Train Acc: {:.2f}, Trg Train Acc: {:.2f}, '\n",
    "test_template  = 'Src Test Acc: {:.2f}, Trg Test Acc: {:.2f}'\n",
    "\n",
    "generator      = ResNet50(num_classes, 256)\n",
    "discriminator  = Discriminator()\n",
    "disc_optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate, beta_1 = 0.5)\n",
    "gen_optimizer  = tf.keras.optimizers.Adam(learning_rate = learning_rate, beta_1 = 0.5)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  for source_data, target_data in zip(src_train_set, trg_train_set):\n",
    "    train_gen_step(source_data[0], source_data[1], target_data[0], target_data[1])    \n",
    "    train_disc_step(source_data[0], target_data[0])\n",
    "\n",
    "  print(train_template.format(epoch+1,\n",
    "                              train_total_loss.result(),\n",
    "                              train_cross_entropy_loss.result(),\n",
    "                              train_cond_entropy_loss.result(),\n",
    "                              train_discriminator_loss.result(),\n",
    "                              train_domain_loss.result(),\n",
    "                              train_src_vat_loss.result(),\n",
    "                              train_trg_vat_loss.result(),\n",
    "                              train_src_mixup_loss.result(),\n",
    "                              train_trg_mixup_loss.result(),\n",
    "                              src_train_accuracy.result()*100,\n",
    "                              trg_train_accuracy.result()*100), end=\"\")\n",
    "\n",
    "  train_total_loss.reset_states()\n",
    "  train_cross_entropy_loss.reset_states()\n",
    "  train_cond_entropy_loss.reset_states()\n",
    "  src_train_accuracy.reset_states()\n",
    "  trg_train_accuracy.reset_states()\n",
    "  train_discriminator_loss.reset_states()\n",
    "  train_domain_loss.reset_states()\n",
    "  train_src_vat_loss.reset_states()\n",
    "  train_trg_vat_loss.reset_states()\n",
    "  train_src_mixup_loss.reset_states()\n",
    "  train_trg_mixup_loss.reset_states()\n",
    "\n",
    "  for target_data in trg_test_set:\n",
    "    test_target_step(target_data[0], target_data[1])\n",
    "\n",
    "  for source_data in src_test_set:\n",
    "    test_source_step(source_data[0], source_data[1])\n",
    "    \n",
    "  print(test_template.format(src_test_accuracy.result()*100,\n",
    "                             trg_test_accuracy.result()*100))\n",
    "\n",
    "  src_test_accuracy.reset_states()\n",
    "  trg_test_accuracy.reset_states()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
