{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/kjakkala/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kjakkala/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kjakkala/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kjakkala/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kjakkala/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kjakkala/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2\"\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes    = 9\n",
    "batch_size     = 16\n",
    "train_days     = 3\n",
    "epochs         = 500\n",
    "learning_rate  = 0.0001\n",
    "num_gpus       = 2\n",
    "\n",
    "global_batch_size = batch_size*num_gpus\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9127, 128, 1024, 1) (9127, 2) \n",
      " [b'arahman3', b'harika', b'hchen32', b'jlaivins', b'kjakkala', b'pjanakar', b'ppinyoan', b'pwang13', b'upattnai', b'wrang']\n"
     ]
    }
   ],
   "source": [
    "#Read data\n",
    "hf = h5py.File('/home/kjakkala/mmwave/data/source_data.h5', 'r')\n",
    "X_data = np.expand_dims(hf.get('X_data'), axis=-1).astype(np.float32)\n",
    "y_data = np.array(hf.get('y_data')).astype(np.int32)\n",
    "classes = list(hf.get('classes'))\n",
    "hf.close()\n",
    "print(X_data.shape, y_data.shape, \"\\n\", classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8737, 128, 1024, 1) (8737, 2)\n"
     ]
    }
   ],
   "source": [
    "#balence dataset to 95 samples per day for each person\n",
    "X_data_tmp = []\n",
    "y_data_tmp = []\n",
    "for day in range(10):\n",
    "  for idx in range(len(classes)):\n",
    "    X_data_tmp.extend(X_data[(y_data[:, 0] == idx) & (y_data[:, 1] == day)][:95])\n",
    "    y_data_tmp.extend(y_data[(y_data[:, 0] == idx) & (y_data[:, 1] == day)][:95])\n",
    "X_data = np.array(X_data_tmp)\n",
    "y_data = np.array(y_data_tmp)\n",
    "del X_data_tmp, y_data_tmp\n",
    "print(X_data.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8547, 128, 1024, 1) (8547, 2) \n",
      " [b'arahman3', b'hchen32', b'jlaivins', b'kjakkala', b'pjanakar', b'ppinyoan', b'pwang13', b'upattnai', b'wrang']\n"
     ]
    }
   ],
   "source": [
    "#remove harika's data\n",
    "X_data = np.delete(X_data, np.where(y_data[:, 0] == 1)[0], 0)\n",
    "y_data = np.delete(y_data, np.where(y_data[:, 0] == 1)[0], 0)\n",
    "\n",
    "#update labes to handle 9 classes instead of 10\n",
    "y_data[y_data[:, 0] >= 2, 0] -= 1\n",
    "del classes[1]\n",
    "print(X_data.shape, y_data.shape, \"\\n\", classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2308, 128, 1024, 1) (2308, 9) (257, 128, 1024, 1) (257, 9) (4785, 128, 1024, 1) (4785, 9) (1197, 128, 1024, 1) (1197, 9)\n"
     ]
    }
   ],
   "source": [
    "#split days of data to train and test\n",
    "X_src = X_data[y_data[:, 1] < train_days]\n",
    "y_src = y_data[y_data[:, 1] < train_days, 0]\n",
    "y_src = np.eye(len(classes))[y_src]\n",
    "X_train_src, X_test_src, y_train_src, y_test_src = train_test_split(X_src,\n",
    "                                                                    y_src,\n",
    "                                                                    stratify=y_src,\n",
    "                                                                    test_size=0.10,\n",
    "                                                                    random_state=42)\n",
    "\n",
    "X_trg  = X_data[y_data[:, 1] >= train_days]\n",
    "y_trg  = y_data[y_data[:, 1] >= train_days, 0]\n",
    "y_trg = np.eye(len(classes))[y_trg]\n",
    "X_train_trg, X_test_trg, y_train_trg, y_test_trg = train_test_split(X_trg,\n",
    "                                                                    y_trg,\n",
    "                                                                    stratify=y_trg,\n",
    "                                                                    test_size=0.20,\n",
    "                                                                    random_state=42)\n",
    "del X_src, y_src, X_trg, y_trg\n",
    "\n",
    "y_train_trg = y_train_trg.astype(np.int64)\n",
    "y_test_trg  = y_test_trg.astype(np.int64)\n",
    "y_train_src = y_train_src.astype(np.int64)\n",
    "y_test_src  = y_test_src.astype(np.int64)\n",
    "\n",
    "print(X_train_src.shape, y_train_src.shape,  X_test_src.shape, y_test_src.shape, X_train_trg.shape, y_train_trg.shape, X_test_trg.shape, y_test_trg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2308, 128, 1024, 1) (2308, 9) (257, 128, 1024, 1) (257, 9) (4785, 128, 1024, 1) (4785, 9) (1197, 128, 1024, 1) (1197, 9)\n"
     ]
    }
   ],
   "source": [
    "#standardise dataset\n",
    "src_mean = np.mean(X_train_src)\n",
    "X_train_src -= src_mean\n",
    "src_std  = np.std(X_train_src)\n",
    "X_train_src /= src_std\n",
    "\n",
    "X_test_src -= src_mean\n",
    "X_test_src /= src_std\n",
    "\n",
    "trg_mean = np.mean(X_train_trg)\n",
    "X_train_trg -= trg_mean\n",
    "trg_std  = np.std(X_train_trg)\n",
    "X_train_trg /= trg_std\n",
    "\n",
    "X_test_trg -= src_mean\n",
    "X_test_trg /= src_std\n",
    "\n",
    "print(X_train_src.shape, y_train_src.shape,  X_test_src.shape, y_test_src.shape, X_train_trg.shape, y_train_trg.shape, X_test_trg.shape, y_test_trg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get tf.data objects for each set\n",
    "src_train_set = tf.data.Dataset.from_tensor_slices((X_train_src, y_train_src))\n",
    "src_train_set = src_train_set.shuffle(X_train_src.shape[0])\n",
    "src_train_set = src_train_set.batch(batch_size, drop_remainder=True)\n",
    "src_train_set = src_train_set.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "src_train_set = mirrored_strategy.experimental_distribute_dataset(src_train_set)\n",
    "\n",
    "trg_train_set = tf.data.Dataset.from_tensor_slices((X_train_trg, y_train_trg))\n",
    "trg_train_set = trg_train_set.shuffle(X_train_trg.shape[0])\n",
    "trg_train_set = trg_train_set.batch(batch_size, drop_remainder=True)\n",
    "trg_train_set = trg_train_set.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "trg_train_set = trg_train_set.repeat(-1)\n",
    "trg_train_set = mirrored_strategy.experimental_distribute_dataset(trg_train_set)\n",
    "  \n",
    "src_test_set = tf.data.Dataset.from_tensor_slices((X_test_src, y_test_src))\n",
    "src_test_set = src_test_set.batch(batch_size, drop_remainder=False)\n",
    "src_test_set = src_test_set.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "trg_test_set = tf.data.Dataset.from_tensor_slices((X_test_trg, y_test_trg))\n",
    "trg_test_set = trg_test_set.batch(batch_size, drop_remainder=False)\n",
    "trg_test_set = trg_test_set.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_WEIGHT_DECAY = 1e-4\n",
    "BATCH_NORM_DECAY = 0.9\n",
    "BATCH_NORM_EPSILON = 1e-5\n",
    "\n",
    "class IdentityBlock(tf.keras.Model):\n",
    "  def __init__(self, kernel_size, filters, stage, block):\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    super().__init__(name='stage-' + str(stage) + '_block-' + block)\n",
    "\n",
    "    filters1, filters2, filters3 = filters\n",
    "    bn_axis = -1\n",
    "\n",
    "    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1),\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '2a')\n",
    "    self.bn2a = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '2a')\n",
    "\n",
    "    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size,\n",
    "                                         padding='same',\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '2b')\n",
    "    self.bn2b = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '2b')\n",
    "\n",
    "    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1),\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '2c')\n",
    "    self.bn2c = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '2c')\n",
    "\n",
    "  def call(self, input_tensor, training=False):\n",
    "    x = self.conv2a(input_tensor)\n",
    "    x = self.bn2a(x, training=training)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = self.conv2b(x)\n",
    "    x = self.bn2b(x, training=training)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = self.conv2c(x)\n",
    "    x = self.bn2c(x, training=training)\n",
    "\n",
    "    x = tf.keras.layers.add([x, input_tensor])\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\"\"\"A block that has a conv layer at shortcut.\n",
    "\n",
    "Note that from stage 3,\n",
    "the second conv layer at main path is with strides=(2, 2)\n",
    "And the shortcut should have strides=(2, 2) as well\n",
    "\n",
    "Args:\n",
    "  kernel_size: the kernel size of middle conv layer at main path\n",
    "  filters: list of integers, the filters of 3 conv layer at main path\n",
    "  stage: integer, current stage label, used for generating layer names\n",
    "  block: 'a','b'..., current block label, used for generating layer names\n",
    "  strides: Strides for the second conv layer in the block.\n",
    "\n",
    "Returns:\n",
    "  A Keras model instance for the block.\n",
    "\"\"\"\n",
    "class ConvBlock(tf.keras.Model):\n",
    "  def __init__(self, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    super().__init__(name='stage-' + str(stage) + '_block-' + block)\n",
    "\n",
    "    filters1, filters2, filters3 = filters\n",
    "    bn_axis = -1\n",
    "\n",
    "    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1),\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '2a')\n",
    "    self.bn2a = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '2a')\n",
    "\n",
    "    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size,\n",
    "                                         strides=strides,\n",
    "                                         padding='same',\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '2b')\n",
    "    self.bn2b = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '2b')\n",
    "\n",
    "    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1),\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '2c')\n",
    "    self.bn2c = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '2c')\n",
    "\n",
    "    self.conv2s = tf.keras.layers.Conv2D(filters3, (1, 1),\n",
    "                                         strides=strides,\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '1')\n",
    "    self.bn2s = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '1')\n",
    "\n",
    "  def call(self, input_tensor, training=False):\n",
    "    x = self.conv2a(input_tensor)\n",
    "    x = self.bn2a(x, training=training)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = self.conv2b(x)\n",
    "    x = self.bn2b(x, training=training)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = self.conv2c(x)\n",
    "    x = self.bn2c(x, training=training)\n",
    "\n",
    "    shortcut = self.conv2s(input_tensor)\n",
    "    shortcut = self.bn2s(shortcut, training=training)\n",
    "\n",
    "    x = tf.keras.layers.add([x, shortcut])\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\"\"\"Instantiates the ResNet50 architecture.\n",
    "\n",
    "Args:\n",
    "  num_classes: `int` number of classes for image classification.\n",
    "\n",
    "Returns:\n",
    "    A Keras model instance.\n",
    "\"\"\"\n",
    "class ResNet50(tf.keras.Model):\n",
    "  def __init__(self, num_classes, num_features):\n",
    "    super().__init__(name='generator')\n",
    "    bn_axis = -1\n",
    "\n",
    "    #self.conv1_pad = tf.keras.layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')\n",
    "    self.conv1 = tf.keras.layers.Conv2D(32, (7, 7),\n",
    "                                        strides=(2, 2),\n",
    "                                        padding='valid',\n",
    "                                        use_bias=False,\n",
    "                                        kernel_initializer='he_normal',\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                        name='conv1')\n",
    "    self.bn1 = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                  momentum=BATCH_NORM_DECAY,\n",
    "                                                  epsilon=BATCH_NORM_EPSILON,\n",
    "                                                  name='bn_conv1')\n",
    "    self.relu1 = tf.keras.layers.Activation('relu', name='relu1')\n",
    "    self.max_pool1 = tf.keras.layers.MaxPooling2D((3, 3),\n",
    "                                                  strides=(2, 2),\n",
    "                                                  padding='same',\n",
    "                                                  name='max_pool1')\n",
    "\n",
    "    self.blocks = []\n",
    "    self.blocks.append(ConvBlock(3, [32, 32, 128], strides=(1, 1), stage=2, block='a'))\n",
    "    self.blocks.append(IdentityBlock(3, [32, 32, 128], stage=2, block='b'))\n",
    "\n",
    "    self.blocks.append(ConvBlock(3, [64, 64, 256], stage=3, block='a'))\n",
    "    self.blocks.append(IdentityBlock(3, [64, 64, 256], stage=3, block='b'))\n",
    "\n",
    "    self.blocks.append(ConvBlock(3, [64, 64, 256], stage=4, block='a'))\n",
    "    self.blocks.append(IdentityBlock(3, [64, 64, 256], stage=4, block='b'))\n",
    "\n",
    "    self.avg_pool = tf.keras.layers.GlobalAveragePooling2D(name='avg_pool')\n",
    "    self.fc1 = tf.keras.layers.Dense(num_features,\n",
    "                                     activation='relu',\n",
    "                                     kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                     kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                     bias_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                     name='fc1')\n",
    "    self.logits = tf.keras.layers.Dense(num_classes,\n",
    "                                        activation=None,\n",
    "                                        kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                        bias_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                        name='logits')\n",
    "\n",
    "  def call(self, img_input, training=False):\n",
    "    x = self.conv1(img_input)\n",
    "    x = self.bn1(x, training=training)\n",
    "    x = self.relu1(x)\n",
    "    x = self.max_pool1(x)\n",
    "\n",
    "    for block in self.blocks:\n",
    "      x = block(x)\n",
    "\n",
    "    x = self.avg_pool(x)\n",
    "    fc1 = self.fc1(x)\n",
    "    logits = self.logits(fc1)\n",
    "    return logits, fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super().__init__(name='discriminator')  \n",
    "    self.dense1 = tf.keras.layers.Dense(100, activation='relu')\n",
    "    self.logits = tf.keras.layers.Dense(1, activation=None)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = self.dense1(inputs)\n",
    "    x = self.logits(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cross_entropy_loss(labels, logits):\n",
    "  loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=logits)\n",
    "  return tf.reduce_mean(loss)\n",
    "\n",
    "def get_domain_confusion_loss(src_logits, trg_logits):\n",
    "  discriminator_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(src_logits),\n",
    "                                                               logits=src_logits) + \\\n",
    "                       tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(trg_logits),\n",
    "                                                               logits=trg_logits)\n",
    "  return 0.5 * tf.reduce_mean(discriminator_loss)\n",
    "\n",
    "def virtual_adversarial_images(images, logits, pert_norm_radius=3.5):  \n",
    "  with tf.GradientTape() as tape:\n",
    "    # Get normalised noise matrix\n",
    "    noise = tf.random.normal(shape=tf.shape(images))\n",
    "    noise = 1e-6 * tf.nn.l2_normalize(noise, axis=tf.range(1, len(noise.shape)))\n",
    "\n",
    "    # Add noise to image and get new logits\n",
    "    noise_logits, _ = generator(images + noise, \n",
    "                                tf.constant(False, dtype=tf.bool))\n",
    "\n",
    "    # Get loss from noisey logits\n",
    "    noise_loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=logits, logits=noise_logits)\n",
    "    noise_loss = tf.reduce_mean(noise_loss)\n",
    "\n",
    "  # Based on perturbed image loss, get direction of greatest error\n",
    "  adversarial_noise = tape.gradient(noise_loss, \n",
    "                                    [noise],\n",
    "                                    unconnected_gradients='zero')[0]\n",
    "\n",
    "  adversarial_noise = tf.nn.l2_normalize(adversarial_noise, \n",
    "                                         axis=tf.range(1, 4))\n",
    "\n",
    "  # return images with adversarial perturbation\n",
    "  return images + pert_norm_radius * adversarial_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_total_loss         = tf.keras.metrics.Mean(name='train_total_loss')\n",
    "train_domain_loss        = tf.keras.metrics.Mean(name='train_domain_loss')\n",
    "train_src_vat_loss       = tf.keras.metrics.Mean(name='train_src_vat_loss')\n",
    "train_trg_vat_loss       = tf.keras.metrics.Mean(name='train_trg_vat_loss')\n",
    "train_cond_entropy_loss  = tf.keras.metrics.Mean(name='train_cond_entropy_loss')\n",
    "train_cross_entropy_loss = tf.keras.metrics.Mean(name='train_cross_entropy_loss')\n",
    "train_discriminator_loss = tf.keras.metrics.Mean(name='train_discriminator_loss')\n",
    "src_test_accuracy        = tf.keras.metrics.CategoricalAccuracy(name='src_test_accuracy')\n",
    "trg_test_accuracy        = tf.keras.metrics.CategoricalAccuracy(name='trg_test_accuracy')\n",
    "src_train_accuracy       = tf.keras.metrics.CategoricalAccuracy(name='src_train_accuracy')\n",
    "trg_train_accuracy       = tf.keras.metrics.CategoricalAccuracy(name='trg_train_accuracy')\n",
    "\n",
    "def train_gen_step(src_images, src_labels, trg_images, trg_labels):  \n",
    "  with tf.GradientTape() as gen_tape:\n",
    "    src_logits, src_enc = generator(src_images, training=True)\n",
    "    trg_logits, trg_enc = generator(trg_images, training=True)  \n",
    "    src_adver_images    = virtual_adversarial_images(src_images, tf.nn.softmax(src_logits))\n",
    "    src_adver_logits, _ = generator(tf.stop_gradient(src_adver_images), training=True)\n",
    "    trg_adver_images    = virtual_adversarial_images(trg_images, tf.nn.softmax(trg_logits))\n",
    "    trg_adver_logits, _ = generator(tf.stop_gradient(trg_adver_images), training=True)\n",
    "    src_disc_logits     = discriminator(src_enc)\n",
    "    trg_disc_logits     = discriminator(trg_enc)\n",
    "\n",
    "    cross_entropy_loss  = get_cross_entropy_loss(labels=src_labels, \n",
    "                                                 logits=src_logits)\n",
    "    cross_cond_loss     = get_cross_entropy_loss(labels=tf.nn.softmax(trg_logits), \n",
    "                                                 logits=trg_logits)\n",
    "    src_vat_loss        = get_cross_entropy_loss(labels=tf.nn.softmax(tf.stop_gradient(src_logits)),\n",
    "                                                 logits=src_adver_logits)\n",
    "    trg_vat_loss        = get_cross_entropy_loss(labels=tf.nn.softmax(tf.stop_gradient(trg_logits)),\n",
    "                                                 logits=trg_adver_logits)\n",
    "    domain_loss         = get_domain_confusion_loss(src_logits=trg_disc_logits, \n",
    "                                                    trg_logits=src_disc_logits)\n",
    "\n",
    "    total_loss = 1    * cross_entropy_loss + \\\n",
    "                 1e-2 * domain_loss + \\\n",
    "                 1e-2 * cross_cond_loss + \\\n",
    "                 1e-2 * trg_vat_loss + \\\n",
    "                 1    * src_vat_loss    \n",
    "    \n",
    "  gen_gradients = gen_tape.gradient(total_loss, generator.trainable_variables)\n",
    "  gen_optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n",
    "\n",
    "  src_train_accuracy(src_labels, src_logits)\n",
    "  trg_train_accuracy(trg_labels, trg_logits)\n",
    "  train_cross_entropy_loss(cross_entropy_loss)\n",
    "  train_cond_entropy_loss(cross_cond_loss)\n",
    "  train_src_vat_loss(src_vat_loss)\n",
    "  train_trg_vat_loss(trg_vat_loss)\n",
    "  train_domain_loss(domain_loss)\n",
    "  train_total_loss(total_loss)\n",
    "  \n",
    "def train_disc_step(src_images, trg_images):  \n",
    "  with tf.GradientTape() as disc_tape:\n",
    "    _, src_enc          = generator(src_images, training=True)\n",
    "    _, trg_enc          = generator(trg_images, training=True)  \n",
    "    src_disc_logits     = discriminator(src_enc)\n",
    "    trg_disc_logits     = discriminator(trg_enc)    \n",
    "    domain_conf_loss    = get_domain_confusion_loss(src_logits=src_disc_logits, \n",
    "                                                    trg_logits=trg_disc_logits)\n",
    "  \n",
    "  disc_gradients = disc_tape.gradient(domain_conf_loss, \n",
    "                                      discriminator.trainable_variables)\n",
    "  disc_optimizer.apply_gradients(zip(disc_gradients, discriminator.trainable_variables))\n",
    "  train_discriminator_loss(domain_conf_loss)\n",
    "\n",
    "@tf.function\n",
    "def test_source_step(source_images, source_labels):\n",
    "  source_logits, _ = generator(source_images, training=False)\n",
    "  src_test_accuracy(source_labels, source_logits)\n",
    "    \n",
    "@tf.function\n",
    "def test_target_step(target_images, target_labels):\n",
    "  target_logits, _ = generator(target_images, training=False)\n",
    "  trg_test_accuracy(target_labels, target_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "  @tf.function\n",
    "  def dist_train_gen_step(src_images, src_labels, trg_images, trg_labels):\n",
    "    mirrored_strategy.experimental_run_v2(train_gen_step,\n",
    "                                          args=(src_images, \n",
    "                                                src_labels, \n",
    "                                                trg_images, \n",
    "                                                trg_labels,))\n",
    "\n",
    "  @tf.function\n",
    "  def dist_train_disc_step(src_images, trg_images):\n",
    "    mirrored_strategy.experimental_run_v2(train_disc_step,\n",
    "                                          args=(src_images, \n",
    "                                                trg_images,))\n",
    "    \n",
    "  generator      = ResNet50(num_classes, 256)\n",
    "  discriminator  = Discriminator()\n",
    "  disc_optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate, beta_1 = 0.5)\n",
    "  gen_optimizer  = tf.keras.optimizers.Adam(learning_rate = learning_rate, beta_1 = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0826 17:00:44.563490 140073858193152 deprecation.py:323] From /home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/keras/layers/normalization.py:457: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, TotalL: 4.4456, CrossE: 2.2000, CondE: 2.1948, disc: 0.6936, domain: 0.6934, Src VAT: 2.1948, Trg VAT: 2.1948, Src Train Acc: 11.50, Trg Train Acc: 11.94, Src Test Acc: 10.51, Trg Test Acc: 11.19\n",
      "Epoch: 002, TotalL: 4.3945, CrossE: 2.1693, CondE: 2.1742, disc: 0.6945, domain: 0.6939, Src VAT: 2.1748, Trg VAT: 2.1742, Src Train Acc: 13.24, Trg Train Acc: 13.93, Src Test Acc: 17.12, Trg Test Acc: 17.29\n",
      "Epoch: 003, TotalL: 4.2027, CrossE: 2.0740, CondE: 2.0782, disc: 0.6982, domain: 0.6966, Src VAT: 2.0802, Trg VAT: 2.0782, Src Train Acc: 17.32, Trg Train Acc: 18.49, Src Test Acc: 19.07, Trg Test Acc: 17.79\n",
      "Epoch: 004, TotalL: 3.9061, CrossE: 1.9148, CondE: 1.9463, disc: 0.7018, domain: 0.7024, Src VAT: 1.9454, Trg VAT: 1.9463, Src Train Acc: 26.04, Trg Train Acc: 26.56, Src Test Acc: 27.24, Trg Test Acc: 32.92\n",
      "Epoch: 005, TotalL: 3.3822, CrossE: 1.6571, CondE: 1.6915, disc: 0.7108, domain: 0.7126, Src VAT: 1.6841, Trg VAT: 1.6915, Src Train Acc: 34.29, Trg Train Acc: 34.64, Src Test Acc: 35.80, Trg Test Acc: 37.84\n",
      "Epoch: 006, TotalL: 3.1353, CrossE: 1.5356, CondE: 1.5712, disc: 0.7064, domain: 0.7226, Src VAT: 1.5610, Trg VAT: 1.5712, Src Train Acc: 38.54, Trg Train Acc: 38.63, Src Test Acc: 38.13, Trg Test Acc: 39.26\n",
      "Epoch: 007, TotalL: 2.9562, CrossE: 1.4450, CondE: 1.4895, disc: 0.7041, domain: 0.7259, Src VAT: 1.4742, Trg VAT: 1.4895, Src Train Acc: 43.19, Trg Train Acc: 42.14, Src Test Acc: 42.80, Trg Test Acc: 43.11\n",
      "Epoch: 008, TotalL: 2.7465, CrossE: 1.3340, CondE: 1.4031, disc: 0.7038, domain: 0.7272, Src VAT: 1.3772, Trg VAT: 1.4031, Src Train Acc: 48.91, Trg Train Acc: 46.35, Src Test Acc: 48.25, Trg Test Acc: 49.37\n",
      "Epoch: 009, TotalL: 2.4613, CrossE: 1.1897, CondE: 1.2776, disc: 0.7045, domain: 0.7331, Src VAT: 1.2388, Trg VAT: 1.2776, Src Train Acc: 55.08, Trg Train Acc: 50.26, Src Test Acc: 55.64, Trg Test Acc: 54.47\n",
      "Epoch: 010, TotalL: 2.1907, CrossE: 1.0538, CondE: 1.1548, disc: 0.7032, domain: 0.7397, Src VAT: 1.1064, Trg VAT: 1.1548, Src Train Acc: 60.76, Trg Train Acc: 53.47, Src Test Acc: 59.92, Trg Test Acc: 57.23\n",
      "Epoch: 011, TotalL: 1.9935, CrossE: 0.9619, CondE: 1.0605, disc: 0.7022, domain: 0.7520, Src VAT: 1.0029, Trg VAT: 1.0605, Src Train Acc: 63.59, Trg Train Acc: 55.56, Src Test Acc: 65.37, Trg Test Acc: 58.73\n",
      "Epoch: 012, TotalL: 1.8537, CrossE: 0.8960, CondE: 0.9925, disc: 0.6986, domain: 0.7665, Src VAT: 0.9301, Trg VAT: 0.9925, Src Train Acc: 65.93, Trg Train Acc: 57.34, Src Test Acc: 68.87, Trg Test Acc: 59.98\n",
      "Epoch: 013, TotalL: 1.7454, CrossE: 0.8434, CondE: 0.9424, disc: 0.6994, domain: 0.7659, Src VAT: 0.8755, Trg VAT: 0.9424, Src Train Acc: 67.19, Trg Train Acc: 58.77, Src Test Acc: 70.43, Trg Test Acc: 61.57\n",
      "Epoch: 014, TotalL: 1.6649, CrossE: 0.8033, CondE: 0.9048, disc: 0.6919, domain: 0.7739, Src VAT: 0.8358, Trg VAT: 0.9048, Src Train Acc: 68.97, Trg Train Acc: 60.33, Src Test Acc: 72.37, Trg Test Acc: 61.32\n",
      "Epoch: 015, TotalL: 1.5894, CrossE: 0.7657, CondE: 0.8667, disc: 0.6911, domain: 0.7838, Src VAT: 0.7986, Trg VAT: 0.8667, Src Train Acc: 70.14, Trg Train Acc: 61.98, Src Test Acc: 74.32, Trg Test Acc: 62.41\n",
      "Epoch: 016, TotalL: 1.5199, CrossE: 0.7313, CondE: 0.8313, disc: 0.6871, domain: 0.7934, Src VAT: 0.7641, Trg VAT: 0.8313, Src Train Acc: 71.44, Trg Train Acc: 62.72, Src Test Acc: 74.71, Trg Test Acc: 65.00\n",
      "Epoch: 017, TotalL: 1.4580, CrossE: 0.7008, CondE: 0.8007, disc: 0.6856, domain: 0.7998, Src VAT: 0.7331, Trg VAT: 0.8007, Src Train Acc: 72.66, Trg Train Acc: 63.80, Src Test Acc: 75.88, Trg Test Acc: 65.75\n",
      "Epoch: 018, TotalL: 1.4021, CrossE: 0.6728, CondE: 0.7736, disc: 0.6848, domain: 0.8074, Src VAT: 0.7057, Trg VAT: 0.7736, Src Train Acc: 73.87, Trg Train Acc: 65.45, Src Test Acc: 77.82, Trg Test Acc: 67.08\n",
      "Epoch: 019, TotalL: 1.3516, CrossE: 0.6485, CondE: 0.7475, disc: 0.6826, domain: 0.8158, Src VAT: 0.6800, Trg VAT: 0.7475, Src Train Acc: 75.48, Trg Train Acc: 66.23, Src Test Acc: 78.60, Trg Test Acc: 68.34\n",
      "Epoch: 020, TotalL: 1.3072, CrossE: 0.6273, CondE: 0.7245, disc: 0.6824, domain: 0.8176, Src VAT: 0.6572, Trg VAT: 0.7245, Src Train Acc: 76.13, Trg Train Acc: 66.75, Src Test Acc: 78.99, Trg Test Acc: 69.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0826 17:16:12.253764 140098547242752 ultratb.py:155] Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-14-f79b47ab12c3>\", line 6, in <module>\n",
      "    for source_data, target_data in zip(src_train_set, trg_train_set):\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/distribute/input_lib.py\", line 227, in __next__\n",
      "    return self.get_next()\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/distribute/input_lib.py\", line 256, in get_next\n",
      "    global_has_value, replicas = _get_next_as_optional(self, self._strategy)\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/distribute/input_lib.py\", line 183, in _get_next_as_optional\n",
      "    reduce_util.ReduceOp.SUM, worker_has_values, axis=None)\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 832, in reduce\n",
      "    return super(StrategyV1, self).reduce(reduce_op, value, axis)\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 556, in reduce\n",
      "    return self._extended._reduce(reduce_op, value)  # pylint: disable=protected-access\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 1209, in _reduce\n",
      "    device_util.current() or \"/device:CPU:0\"))[0]\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/distribute/mirrored_strategy.py\", line 735, in _reduce_to\n",
      "    reduce_op, value, destinations=destinations)\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/distribute/cross_device_ops.py\", line 258, in reduce\n",
      "    destinations)\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/distribute/cross_device_ops.py\", line 672, in reduce_implementation\n",
      "    return self._batch_all_reduce(reduce_op, [per_replica_value])[0]\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/distribute/cross_device_ops.py\", line 702, in _batch_all_reduce\n",
      "    dense_results = self._do_batch_all_reduce(reduce_op, dense_values)\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/distribute/cross_device_ops.py\", line 735, in _do_batch_all_reduce\n",
      "    device_grad_packs)\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/distribute/cross_device_utils.py\", line 43, in aggregate_gradients_using_nccl\n",
      "    agg_grads = nccl_ops.all_sum(single_grads)\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/ops/nccl_ops.py\", line 47, in all_sum\n",
      "    return _apply_all_reduce('sum', tensors)\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/ops/nccl_ops.py\", line 234, in _apply_all_reduce\n",
      "    return def_function.function(_all_reduce)()\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/eager/def_function.py\", line 414, in __call__\n",
      "    self._initialize(args, kwds, add_initializers_to=initializer_map)\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/eager/def_function.py\", line 357, in _initialize\n",
      "    *args, **kwds))\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/eager/function.py\", line 1349, in _get_concrete_function_internal_garbage_collected\n",
      "    graph_function, _, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/eager/function.py\", line 1652, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/eager/function.py\", line 1545, in _create_graph_function\n",
      "    capture_by_value=self._capture_by_value),\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/framework/func_graph.py\", line 715, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/eager/def_function.py\", line 307, in wrapped_fn\n",
      "    return weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/framework/func_graph.py\", line 702, in wrapper\n",
      "    ), args, kwargs)\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/autograph/impl/api.py\", line 450, in converted_call\n",
      "    result = converted_f(*effective_args, **kwargs)\n",
      "  File \"/tmp/tmpwvmoug8p.py\", line 24, in tf___all_reduce\n",
      "    ag__.for_stmt(tensors, None, loop_body, ())\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/autograph/operators/control_flow.py\", line 110, in for_stmt\n",
      "    return _py_for_stmt(iter_, extra_test, body, init_state)\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/autograph/operators/control_flow.py\", line 119, in _py_for_stmt\n",
      "    state = body(target, *state)\n",
      "  File \"/tmp/tmpwvmoug8p.py\", line 22, in loop_body\n",
      "    ag__.converted_call('append', res, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (ag__.converted_call('nccl_all_reduce', gen_nccl_ops, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (), {'input': t, 'reduction': reduction, 'num_devices': ag__.converted_call(len, None, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (tensors,), None), 'shared_name': shared_name}),), None)\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/autograph/impl/api.py\", line 356, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs)\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/autograph/impl/api.py\", line 253, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_nccl_ops.py\", line 89, in nccl_all_reduce\n",
      "    _attrs = (\"reduction\", _op.get_attr(\"reduction\"), \"T\", _op.get_attr(\"T\"),\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2638, in get_attr\n",
      "    with c_api_util.tf_buffer() as buf:\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/kjakkala/.local/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1410, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 672, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 718, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/lib/python3.5/posixpath.py\", line 372, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/usr/lib/python3.5/posixpath.py\", line 406, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/usr/lib/python3.5/posixpath.py\", line 161, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "train_template = 'Epoch: {:03d}, TotalL: {:.4f}, CrossE: {:.4f}, CondE: {:.4f}, disc: {:.4f}, domain: {:.4f}, Src VAT: {:.4f}, Trg VAT: {:.4f}, Src Train Acc: {:.2f}, Trg Train Acc: {:.2f}, '\n",
    "test_template  = 'Src Test Acc: {:.2f}, Trg Test Acc: {:.2f}'\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  with mirrored_strategy.scope():\n",
    "    for source_data, target_data in zip(src_train_set, trg_train_set):\n",
    "      dist_train_gen_step(source_data[0], source_data[1], target_data[0], target_data[1])    \n",
    "      dist_train_disc_step(source_data[0], target_data[0])         \n",
    "\n",
    "    print(train_template.format(epoch+1,\n",
    "                                train_total_loss.result(),\n",
    "                                train_cross_entropy_loss.result(),\n",
    "                                train_cond_entropy_loss.result(),\n",
    "                                train_discriminator_loss.result(),\n",
    "                                train_domain_loss.result(),\n",
    "                                train_src_vat_loss.result(),\n",
    "                                train_trg_vat_loss.result(),\n",
    "                                src_train_accuracy.result()*100,\n",
    "                                trg_train_accuracy.result()*100), end=\"\")\n",
    "\n",
    "    train_total_loss.reset_states()\n",
    "    train_cross_entropy_loss.reset_states()\n",
    "    train_cond_entropy_loss.reset_states()\n",
    "    src_train_accuracy.reset_states()\n",
    "    trg_train_accuracy.reset_states()\n",
    "    train_discriminator_loss.reset_states()\n",
    "    train_domain_loss.reset_states()\n",
    "    train_src_vat_loss.reset_states()\n",
    "    train_trg_vat_loss.reset_states()\n",
    "\n",
    "  for target_data in trg_test_set:\n",
    "    test_target_step(target_data[0], target_data[1])\n",
    "\n",
    "  for source_data in src_test_set:\n",
    "    test_source_step(source_data[0], source_data[1])\n",
    "\n",
    "  print(test_template.format(src_test_accuracy.result()*100,\n",
    "                             trg_test_accuracy.result()*100))\n",
    "\n",
    "  src_test_accuracy.reset_states()\n",
    "  trg_test_accuracy.reset_states()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
