{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes    = 9\n",
    "batch_size     = 32\n",
    "train_days     = 3\n",
    "epochs         = 200\n",
    "learning_rate  = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9145, 128, 1024, 1) (9145, 2) \n",
      " [b'arahman3', b'harika', b'hchen32', b'jlaivins', b'kjakkala', b'pjanakar', b'ppinyoan', b'pwang13', b'upattnai', b'wrang']\n"
     ]
    }
   ],
   "source": [
    "#Read data\n",
    "hf = h5py.File('/home/kjakkala/mmwave/data/source_data.h5', 'r')\n",
    "X_data = np.expand_dims(hf.get('X_data'), axis=-1).astype(np.float32)\n",
    "y_data = np.array(hf.get('y_data')).astype(np.int32)\n",
    "classes = list(hf.get('classes'))\n",
    "hf.close()\n",
    "print(X_data.shape, y_data.shape, \"\\n\", classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8740, 128, 1024, 1) (8740, 2)\n"
     ]
    }
   ],
   "source": [
    "#balence dataset to 95 samples per day for each person\n",
    "X_data_tmp = []\n",
    "y_data_tmp = []\n",
    "for day in range(10):\n",
    "  for idx in range(len(classes)):\n",
    "    X_data_tmp.extend(X_data[(y_data[:, 0] == idx) & (y_data[:, 1] == day)][:95])\n",
    "    y_data_tmp.extend(y_data[(y_data[:, 0] == idx) & (y_data[:, 1] == day)][:95])\n",
    "X_data = np.array(X_data_tmp)\n",
    "y_data = np.array(y_data_tmp)\n",
    "del X_data_tmp, y_data_tmp\n",
    "print(X_data.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8550, 128, 1024, 1) (8550, 2) \n",
      " [b'arahman3', b'hchen32', b'jlaivins', b'kjakkala', b'pjanakar', b'ppinyoan', b'pwang13', b'upattnai', b'wrang']\n"
     ]
    }
   ],
   "source": [
    "#remove harika's data\n",
    "X_data = np.delete(X_data, np.where(y_data[:, 0] == 1)[0], 0)\n",
    "y_data = np.delete(y_data, np.where(y_data[:, 0] == 1)[0], 0)\n",
    "\n",
    "#update labes to handle 9 classes instead of 10\n",
    "y_data[y_data[:, 0] >= 2, 0] -= 1\n",
    "del classes[1]\n",
    "print(X_data.shape, y_data.shape, \"\\n\", classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2308, 128, 1024, 1) (2308, 9) (257, 128, 1024, 1) (257, 9) (4788, 128, 1024, 1) (4788, 9) (1197, 128, 1024, 1) (1197, 9)\n"
     ]
    }
   ],
   "source": [
    "#split days of data to train and test\n",
    "X_src = X_data[y_data[:, 1] < train_days]\n",
    "y_src = y_data[y_data[:, 1] < train_days, 0]\n",
    "y_src = np.eye(len(classes))[y_src]\n",
    "X_train_src, X_test_src, y_train_src, y_test_src = train_test_split(X_src,\n",
    "                                                                    y_src,\n",
    "                                                                    stratify=y_src,\n",
    "                                                                    test_size=0.10,\n",
    "                                                                    random_state=42)\n",
    "\n",
    "X_trg  = X_data[y_data[:, 1] >= train_days]\n",
    "y_trg  = y_data[y_data[:, 1] >= train_days, 0]\n",
    "y_trg = np.eye(len(classes))[y_trg]\n",
    "X_train_trg, X_test_trg, y_train_trg, y_test_trg = train_test_split(X_trg,\n",
    "                                                                    y_trg,\n",
    "                                                                    stratify=y_trg,\n",
    "                                                                    test_size=0.20,\n",
    "                                                                    random_state=42)\n",
    "del X_src, y_src, X_trg, y_trg\n",
    "\n",
    "y_train_trg = y_train_trg.astype(np.int64)\n",
    "y_test_trg  = y_test_trg.astype(np.int64)\n",
    "y_train_src = y_train_src.astype(np.int64)\n",
    "y_test_src  = y_test_src.astype(np.int64)\n",
    "\n",
    "print(X_train_src.shape, y_train_src.shape,  X_test_src.shape, y_test_src.shape, X_train_trg.shape, y_train_trg.shape, X_test_trg.shape, y_test_trg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2308, 128, 1024, 1) (2308, 9) (257, 128, 1024, 1) (257, 9) (4788, 128, 1024, 1) (4788, 9) (1197, 128, 1024, 1) (1197, 9)\n"
     ]
    }
   ],
   "source": [
    "#standardise dataset\n",
    "src_mean = np.mean(X_train_src)\n",
    "X_train_src -= src_mean\n",
    "src_std  = np.std(X_train_src)\n",
    "X_train_src /= src_std\n",
    "\n",
    "X_test_src -= src_mean\n",
    "X_test_src /= src_std\n",
    "\n",
    "trg_mean = np.mean(X_train_trg)\n",
    "X_train_trg -= trg_mean\n",
    "trg_std  = np.std(X_train_trg)\n",
    "X_train_trg /= trg_std\n",
    "\n",
    "X_test_trg -= src_mean\n",
    "X_test_trg /= src_std\n",
    "\n",
    "print(X_train_src.shape, y_train_src.shape,  X_test_src.shape, y_test_src.shape, X_train_trg.shape, y_train_trg.shape, X_test_trg.shape, y_test_trg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get tf.data objects for each set\n",
    "src_train_set = tf.data.Dataset.from_tensor_slices((X_train_src, y_train_src))\n",
    "src_train_set = src_train_set.shuffle(X_train_src.shape[0])\n",
    "src_train_set = src_train_set.batch(batch_size, drop_remainder=True)\n",
    "src_train_set = src_train_set.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "trg_train_set = tf.data.Dataset.from_tensor_slices((X_train_trg, y_train_trg))\n",
    "trg_train_set = trg_train_set.shuffle(X_train_trg.shape[0])\n",
    "trg_train_set = trg_train_set.batch(batch_size, drop_remainder=True)\n",
    "trg_train_set = trg_train_set.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "trg_train_set = trg_train_set.repeat(-1)\n",
    "\n",
    "src_test_set = tf.data.Dataset.from_tensor_slices((X_test_src, y_test_src))\n",
    "src_test_set = src_test_set.batch(batch_size, drop_remainder=False)\n",
    "src_test_set = src_test_set.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "trg_test_set = tf.data.Dataset.from_tensor_slices((X_test_trg, y_test_trg))\n",
    "trg_test_set = trg_test_set.batch(batch_size, drop_remainder=False)\n",
    "trg_test_set = trg_test_set.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_WEIGHT_DECAY = 1e-4\n",
    "BATCH_NORM_DECAY = 0.9\n",
    "BATCH_NORM_EPSILON = 1e-5\n",
    "\n",
    "class IdentityBlock(tf.keras.Model):\n",
    "  def __init__(self, kernel_size, filters, stage, block):\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    super().__init__(name='stage-' + str(stage) + '_block-' + block)\n",
    "\n",
    "    filters1, filters2, filters3 = filters\n",
    "    bn_axis = -1\n",
    "\n",
    "    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1),\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '2a')\n",
    "    self.bn2a = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '2a')\n",
    "\n",
    "    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size,\n",
    "                                         padding='same',\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '2b')\n",
    "    self.bn2b = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '2b')\n",
    "\n",
    "    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1),\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '2c')\n",
    "    self.bn2c = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '2c')\n",
    "\n",
    "  def call(self, input_tensor, training=False):\n",
    "    x = self.conv2a(input_tensor)\n",
    "    x = self.bn2a(x, training=training)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = self.conv2b(x)\n",
    "    x = self.bn2b(x, training=training)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = self.conv2c(x)\n",
    "    x = self.bn2c(x, training=training)\n",
    "\n",
    "    x = tf.keras.layers.add([x, input_tensor])\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\"\"\"A block that has a conv layer at shortcut.\n",
    "\n",
    "Note that from stage 3,\n",
    "the second conv layer at main path is with strides=(2, 2)\n",
    "And the shortcut should have strides=(2, 2) as well\n",
    "\n",
    "Args:\n",
    "  kernel_size: the kernel size of middle conv layer at main path\n",
    "  filters: list of integers, the filters of 3 conv layer at main path\n",
    "  stage: integer, current stage label, used for generating layer names\n",
    "  block: 'a','b'..., current block label, used for generating layer names\n",
    "  strides: Strides for the second conv layer in the block.\n",
    "\n",
    "Returns:\n",
    "  A Keras model instance for the block.\n",
    "\"\"\"\n",
    "class ConvBlock(tf.keras.Model):\n",
    "  def __init__(self, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    super().__init__(name='stage-' + str(stage) + '_block-' + block)\n",
    "\n",
    "    filters1, filters2, filters3 = filters\n",
    "    bn_axis = -1\n",
    "\n",
    "    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1),\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '2a')\n",
    "    self.bn2a = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '2a')\n",
    "\n",
    "    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size,\n",
    "                                         strides=strides,\n",
    "                                         padding='same',\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '2b')\n",
    "    self.bn2b = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '2b')\n",
    "\n",
    "    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1),\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '2c')\n",
    "    self.bn2c = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '2c')\n",
    "\n",
    "    self.conv2s = tf.keras.layers.Conv2D(filters3, (1, 1),\n",
    "                                         strides=strides,\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '1')\n",
    "    self.bn2s = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '1')\n",
    "\n",
    "  def call(self, input_tensor, training=False):\n",
    "    x = self.conv2a(input_tensor)\n",
    "    x = self.bn2a(x, training=training)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = self.conv2b(x)\n",
    "    x = self.bn2b(x, training=training)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = self.conv2c(x)\n",
    "    x = self.bn2c(x, training=training)\n",
    "\n",
    "    shortcut = self.conv2s(input_tensor)\n",
    "    shortcut = self.bn2s(shortcut, training=training)\n",
    "\n",
    "    x = tf.keras.layers.add([x, shortcut])\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\"\"\"Instantiates the ResNet50 architecture.\n",
    "\n",
    "Args:\n",
    "  num_classes: `int` number of classes for image classification.\n",
    "\n",
    "Returns:\n",
    "    A Keras model instance.\n",
    "\"\"\"\n",
    "class ResNet50(tf.keras.Model):\n",
    "  def __init__(self, num_classes, num_features):\n",
    "    super().__init__(name='generator')\n",
    "    bn_axis = -1\n",
    "\n",
    "    self.conv1_pad = tf.keras.layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')\n",
    "    self.conv1 = tf.keras.layers.Conv2D(32, (7, 7),\n",
    "                                        strides=(2, 2),\n",
    "                                        padding='valid',\n",
    "                                        use_bias=False,\n",
    "                                        kernel_initializer='he_normal',\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                        name='conv1')\n",
    "    self.bn1 = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                  momentum=BATCH_NORM_DECAY,\n",
    "                                                  epsilon=BATCH_NORM_EPSILON,\n",
    "                                                  name='bn_conv1')\n",
    "    self.relu1 = tf.keras.layers.Activation('relu', name='relu1')\n",
    "    self.max_pool1 = tf.keras.layers.MaxPooling2D((3, 3),\n",
    "                                                  strides=(2, 2),\n",
    "                                                  padding='same',\n",
    "                                                  name='max_pool1')\n",
    "\n",
    "    self.blocks = []\n",
    "    self.blocks.append(ConvBlock(3, [32, 32, 128], strides=(1, 1), stage=2, block='a'))\n",
    "    self.blocks.append(IdentityBlock(3, [32, 32, 128], stage=2, block='b'))\n",
    "\n",
    "    self.blocks.append(ConvBlock(3, [64, 64, 256], stage=3, block='a'))\n",
    "    self.blocks.append(IdentityBlock(3, [64, 64, 256], stage=3, block='b'))\n",
    "\n",
    "    self.blocks.append(ConvBlock(3, [64, 64, 256], stage=4, block='a'))\n",
    "    self.blocks.append(IdentityBlock(3, [64, 64, 256], stage=4, block='b'))\n",
    "\n",
    "    self.avg_pool = tf.keras.layers.GlobalAveragePooling2D(name='avg_pool')\n",
    "    self.fc1 = tf.keras.layers.Dense(num_features,\n",
    "                                     activation='relu',\n",
    "                                     kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                     kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                     bias_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                     name='fc1')\n",
    "    self.logits = tf.keras.layers.Dense(num_classes,\n",
    "                                        activation=None,\n",
    "                                        kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                        bias_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                        name='logits')\n",
    "\n",
    "  def call(self, img_input, training=False):\n",
    "    x = self.conv1_pad(img_input)\n",
    "    x = self.conv1(x)\n",
    "    x = self.bn1(x, training=training)\n",
    "    x = self.relu1(x)\n",
    "    x = self.max_pool1(x)\n",
    "\n",
    "    for block in self.blocks:\n",
    "      x = block(x)\n",
    "\n",
    "    x = self.avg_pool(x)\n",
    "    fc1 = self.fc1(x)\n",
    "    logits = self.logits(fc1)\n",
    "    return logits, fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cross_entropy_loss(labels, logits):\n",
    "  loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=logits)\n",
    "  return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cross_entropy_loss = tf.keras.metrics.Mean(name='train_cross_entropy_loss')\n",
    "src_test_accuracy        = tf.keras.metrics.CategoricalAccuracy(name='src_test_accuracy')\n",
    "trg_test_accuracy        = tf.keras.metrics.CategoricalAccuracy(name='trg_test_accuracy')\n",
    "src_train_accuracy       = tf.keras.metrics.CategoricalAccuracy(name='src_train_accuracy')\n",
    "\n",
    "@tf.function\n",
    "def test_source_step(source_images, source_labels):\n",
    "  source_logits, _ = generator(source_images, training=False)\n",
    "  src_test_accuracy(source_labels, source_logits)\n",
    "\n",
    "@tf.function\n",
    "def test_target_step(target_images, target_labels):\n",
    "  target_logits, _ = generator(target_images, training=False)\n",
    "  trg_test_accuracy(target_labels, target_logits)\n",
    "\n",
    "@tf.function\n",
    "def train_baseline_step(src_images, src_labels):\n",
    "  with tf.GradientTape() as gen_tape:\n",
    "    src_logits, _ = generator(src_images, training=True)\n",
    "    cross_entropy_loss  = get_cross_entropy_loss(labels=src_labels,\n",
    "                                                 logits=src_logits)\n",
    "\n",
    "  gen_gradients = gen_tape.gradient(cross_entropy_loss, generator.trainable_variables)\n",
    "  gen_optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n",
    "\n",
    "  src_train_accuracy(src_labels, src_logits)\n",
    "  train_cross_entropy_loss(cross_entropy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, CrossE: 2.1983, Src Train Acc: 10.37, Src Test Acc: 14.79, Trg Test Acc: 14.54\n",
      "Epoch: 002, CrossE: 2.1885, Src Train Acc: 12.67, Src Test Acc: 14.40, Trg Test Acc: 14.29\n",
      "Epoch: 003, CrossE: 2.1317, Src Train Acc: 17.40, Src Test Acc: 23.35, Trg Test Acc: 25.81\n",
      "Epoch: 004, CrossE: 2.0298, Src Train Acc: 20.62, Src Test Acc: 28.79, Trg Test Acc: 27.23\n",
      "Epoch: 005, CrossE: 1.8985, Src Train Acc: 22.87, Src Test Acc: 29.57, Trg Test Acc: 31.75\n",
      "Epoch: 006, CrossE: 1.7865, Src Train Acc: 26.91, Src Test Acc: 31.91, Trg Test Acc: 34.59\n",
      "Epoch: 007, CrossE: 1.6957, Src Train Acc: 31.90, Src Test Acc: 33.85, Trg Test Acc: 34.09\n",
      "Epoch: 008, CrossE: 1.5719, Src Train Acc: 38.15, Src Test Acc: 44.36, Trg Test Acc: 43.36\n",
      "Epoch: 009, CrossE: 1.4395, Src Train Acc: 43.84, Src Test Acc: 49.03, Trg Test Acc: 45.70\n",
      "Epoch: 010, CrossE: 1.3333, Src Train Acc: 48.13, Src Test Acc: 52.14, Trg Test Acc: 49.12\n",
      "Epoch: 011, CrossE: 1.2523, Src Train Acc: 50.78, Src Test Acc: 56.81, Trg Test Acc: 52.21\n",
      "Epoch: 012, CrossE: 1.1916, Src Train Acc: 53.65, Src Test Acc: 58.37, Trg Test Acc: 53.80\n",
      "Epoch: 013, CrossE: 1.1439, Src Train Acc: 55.69, Src Test Acc: 59.53, Trg Test Acc: 54.30\n",
      "Epoch: 014, CrossE: 1.1055, Src Train Acc: 57.34, Src Test Acc: 63.42, Trg Test Acc: 54.72\n",
      "Epoch: 015, CrossE: 1.0760, Src Train Acc: 58.46, Src Test Acc: 64.59, Trg Test Acc: 54.64\n",
      "Epoch: 016, CrossE: 1.0436, Src Train Acc: 60.07, Src Test Acc: 65.37, Trg Test Acc: 56.06\n",
      "Epoch: 017, CrossE: 1.0129, Src Train Acc: 61.20, Src Test Acc: 65.37, Trg Test Acc: 56.89\n",
      "Epoch: 018, CrossE: 0.9857, Src Train Acc: 62.46, Src Test Acc: 68.09, Trg Test Acc: 57.64\n",
      "Epoch: 019, CrossE: 0.9553, Src Train Acc: 64.15, Src Test Acc: 70.82, Trg Test Acc: 59.31\n",
      "Epoch: 020, CrossE: 0.9274, Src Train Acc: 65.02, Src Test Acc: 72.37, Trg Test Acc: 61.32\n",
      "Epoch: 021, CrossE: 0.9002, Src Train Acc: 66.02, Src Test Acc: 73.93, Trg Test Acc: 62.99\n",
      "Epoch: 022, CrossE: 0.8717, Src Train Acc: 67.14, Src Test Acc: 74.71, Trg Test Acc: 63.83\n",
      "Epoch: 023, CrossE: 0.8446, Src Train Acc: 68.10, Src Test Acc: 76.26, Trg Test Acc: 64.91\n",
      "Epoch: 024, CrossE: 0.8168, Src Train Acc: 68.92, Src Test Acc: 77.04, Trg Test Acc: 65.25\n",
      "Epoch: 025, CrossE: 0.7949, Src Train Acc: 69.49, Src Test Acc: 77.82, Trg Test Acc: 66.67\n",
      "Epoch: 026, CrossE: 0.7751, Src Train Acc: 70.83, Src Test Acc: 77.04, Trg Test Acc: 66.08\n",
      "Epoch: 027, CrossE: 0.7559, Src Train Acc: 71.66, Src Test Acc: 77.43, Trg Test Acc: 66.25\n",
      "Epoch: 028, CrossE: 0.7374, Src Train Acc: 72.35, Src Test Acc: 76.26, Trg Test Acc: 66.17\n",
      "Epoch: 029, CrossE: 0.7190, Src Train Acc: 73.22, Src Test Acc: 78.21, Trg Test Acc: 66.67\n",
      "Epoch: 030, CrossE: 0.7008, Src Train Acc: 74.35, Src Test Acc: 78.60, Trg Test Acc: 67.50\n",
      "Epoch: 031, CrossE: 0.6832, Src Train Acc: 74.91, Src Test Acc: 79.38, Trg Test Acc: 68.50\n",
      "Epoch: 032, CrossE: 0.6669, Src Train Acc: 75.48, Src Test Acc: 79.77, Trg Test Acc: 69.34\n",
      "Epoch: 033, CrossE: 0.6511, Src Train Acc: 75.78, Src Test Acc: 80.54, Trg Test Acc: 69.92\n",
      "Epoch: 034, CrossE: 0.6360, Src Train Acc: 76.43, Src Test Acc: 81.32, Trg Test Acc: 70.34\n",
      "Epoch: 035, CrossE: 0.6201, Src Train Acc: 77.39, Src Test Acc: 81.71, Trg Test Acc: 70.68\n",
      "Epoch: 036, CrossE: 0.6041, Src Train Acc: 77.73, Src Test Acc: 81.71, Trg Test Acc: 70.59\n",
      "Epoch: 037, CrossE: 0.5889, Src Train Acc: 77.99, Src Test Acc: 82.10, Trg Test Acc: 71.43\n",
      "Epoch: 038, CrossE: 0.5722, Src Train Acc: 78.86, Src Test Acc: 82.49, Trg Test Acc: 72.01\n",
      "Epoch: 039, CrossE: 0.5559, Src Train Acc: 79.51, Src Test Acc: 82.88, Trg Test Acc: 73.35\n",
      "Epoch: 040, CrossE: 0.5391, Src Train Acc: 80.16, Src Test Acc: 83.66, Trg Test Acc: 74.19\n",
      "Epoch: 041, CrossE: 0.5209, Src Train Acc: 80.51, Src Test Acc: 84.82, Trg Test Acc: 75.19\n",
      "Epoch: 042, CrossE: 0.5075, Src Train Acc: 81.21, Src Test Acc: 85.99, Trg Test Acc: 75.69\n",
      "Epoch: 043, CrossE: 0.4923, Src Train Acc: 82.25, Src Test Acc: 85.99, Trg Test Acc: 75.94\n",
      "Epoch: 044, CrossE: 0.4743, Src Train Acc: 82.68, Src Test Acc: 86.77, Trg Test Acc: 76.27\n",
      "Epoch: 045, CrossE: 0.4575, Src Train Acc: 83.25, Src Test Acc: 86.38, Trg Test Acc: 77.19\n",
      "Epoch: 046, CrossE: 0.4397, Src Train Acc: 84.42, Src Test Acc: 86.38, Trg Test Acc: 77.36\n",
      "Epoch: 047, CrossE: 0.4240, Src Train Acc: 84.98, Src Test Acc: 87.94, Trg Test Acc: 77.36\n",
      "Epoch: 048, CrossE: 0.4096, Src Train Acc: 85.37, Src Test Acc: 88.72, Trg Test Acc: 77.69\n",
      "Epoch: 049, CrossE: 0.4003, Src Train Acc: 85.81, Src Test Acc: 88.33, Trg Test Acc: 77.69\n",
      "Epoch: 050, CrossE: 0.3834, Src Train Acc: 86.76, Src Test Acc: 88.72, Trg Test Acc: 76.94\n",
      "Epoch: 051, CrossE: 0.3710, Src Train Acc: 86.98, Src Test Acc: 88.33, Trg Test Acc: 76.78\n",
      "Epoch: 052, CrossE: 0.3593, Src Train Acc: 87.76, Src Test Acc: 87.94, Trg Test Acc: 76.02\n",
      "Epoch: 053, CrossE: 0.3483, Src Train Acc: 87.98, Src Test Acc: 87.94, Trg Test Acc: 75.52\n",
      "Epoch: 054, CrossE: 0.3397, Src Train Acc: 88.24, Src Test Acc: 87.94, Trg Test Acc: 73.85\n",
      "Epoch: 055, CrossE: 0.3268, Src Train Acc: 88.54, Src Test Acc: 86.38, Trg Test Acc: 72.93\n",
      "Epoch: 056, CrossE: 0.3178, Src Train Acc: 88.72, Src Test Acc: 87.16, Trg Test Acc: 73.35\n",
      "Epoch: 057, CrossE: 0.3092, Src Train Acc: 89.41, Src Test Acc: 85.99, Trg Test Acc: 73.27\n",
      "Epoch: 058, CrossE: 0.2989, Src Train Acc: 89.63, Src Test Acc: 87.94, Trg Test Acc: 73.52\n",
      "Epoch: 059, CrossE: 0.2908, Src Train Acc: 89.93, Src Test Acc: 87.16, Trg Test Acc: 73.10\n",
      "Epoch: 060, CrossE: 0.2810, Src Train Acc: 90.41, Src Test Acc: 87.16, Trg Test Acc: 72.60\n",
      "Epoch: 061, CrossE: 0.2766, Src Train Acc: 90.45, Src Test Acc: 87.16, Trg Test Acc: 72.60\n",
      "Epoch: 062, CrossE: 0.2696, Src Train Acc: 90.80, Src Test Acc: 86.77, Trg Test Acc: 73.35\n",
      "Epoch: 063, CrossE: 0.2644, Src Train Acc: 90.97, Src Test Acc: 87.16, Trg Test Acc: 73.77\n",
      "Epoch: 064, CrossE: 0.2575, Src Train Acc: 91.41, Src Test Acc: 87.16, Trg Test Acc: 74.52\n",
      "Epoch: 065, CrossE: 0.2469, Src Train Acc: 91.75, Src Test Acc: 86.77, Trg Test Acc: 74.19\n",
      "Epoch: 066, CrossE: 0.2417, Src Train Acc: 91.88, Src Test Acc: 87.16, Trg Test Acc: 74.44\n",
      "Epoch: 067, CrossE: 0.2386, Src Train Acc: 92.19, Src Test Acc: 87.94, Trg Test Acc: 76.11\n",
      "Epoch: 068, CrossE: 0.2292, Src Train Acc: 92.14, Src Test Acc: 89.11, Trg Test Acc: 77.11\n",
      "Epoch: 069, CrossE: 0.2235, Src Train Acc: 92.66, Src Test Acc: 89.88, Trg Test Acc: 78.53\n",
      "Epoch: 070, CrossE: 0.2144, Src Train Acc: 92.71, Src Test Acc: 90.66, Trg Test Acc: 79.70\n",
      "Epoch: 071, CrossE: 0.2176, Src Train Acc: 92.66, Src Test Acc: 92.61, Trg Test Acc: 80.95\n",
      "Epoch: 072, CrossE: 0.2107, Src Train Acc: 93.19, Src Test Acc: 92.22, Trg Test Acc: 81.79\n",
      "Epoch: 073, CrossE: 0.2075, Src Train Acc: 93.14, Src Test Acc: 92.22, Trg Test Acc: 82.54\n",
      "Epoch: 074, CrossE: 0.1887, Src Train Acc: 93.40, Src Test Acc: 93.00, Trg Test Acc: 83.54\n",
      "Epoch: 075, CrossE: 0.1884, Src Train Acc: 93.66, Src Test Acc: 93.77, Trg Test Acc: 84.29\n",
      "Epoch: 076, CrossE: 0.1914, Src Train Acc: 93.84, Src Test Acc: 94.16, Trg Test Acc: 84.54\n",
      "Epoch: 077, CrossE: 0.1761, Src Train Acc: 93.92, Src Test Acc: 93.00, Trg Test Acc: 85.63\n",
      "Epoch: 078, CrossE: 0.1725, Src Train Acc: 94.27, Src Test Acc: 93.00, Trg Test Acc: 86.30\n",
      "Epoch: 079, CrossE: 0.1736, Src Train Acc: 94.36, Src Test Acc: 94.94, Trg Test Acc: 85.63\n",
      "Epoch: 080, CrossE: 0.1752, Src Train Acc: 94.44, Src Test Acc: 93.39, Trg Test Acc: 86.47\n",
      "Epoch: 081, CrossE: 0.1732, Src Train Acc: 94.40, Src Test Acc: 83.66, Trg Test Acc: 73.43\n",
      "Epoch: 082, CrossE: 0.1741, Src Train Acc: 94.36, Src Test Acc: 93.77, Trg Test Acc: 85.96\n",
      "Epoch: 083, CrossE: 0.1611, Src Train Acc: 94.62, Src Test Acc: 93.00, Trg Test Acc: 86.05\n",
      "Epoch: 084, CrossE: 0.1503, Src Train Acc: 95.36, Src Test Acc: 93.39, Trg Test Acc: 85.80\n",
      "Epoch: 085, CrossE: 0.1518, Src Train Acc: 95.53, Src Test Acc: 93.77, Trg Test Acc: 86.30\n",
      "Epoch: 086, CrossE: 0.1548, Src Train Acc: 95.18, Src Test Acc: 94.94, Trg Test Acc: 86.97\n",
      "Epoch: 087, CrossE: 0.1391, Src Train Acc: 95.75, Src Test Acc: 93.77, Trg Test Acc: 87.13\n",
      "Epoch: 088, CrossE: 0.1475, Src Train Acc: 95.36, Src Test Acc: 92.61, Trg Test Acc: 85.30\n",
      "Epoch: 089, CrossE: 0.1535, Src Train Acc: 94.75, Src Test Acc: 83.66, Trg Test Acc: 75.94\n",
      "Epoch: 090, CrossE: 0.1757, Src Train Acc: 94.27, Src Test Acc: 87.94, Trg Test Acc: 78.28\n",
      "Epoch: 091, CrossE: 0.1909, Src Train Acc: 93.97, Src Test Acc: 94.55, Trg Test Acc: 88.22\n",
      "Epoch: 092, CrossE: 0.1388, Src Train Acc: 95.05, Src Test Acc: 93.39, Trg Test Acc: 88.64\n",
      "Epoch: 093, CrossE: 0.1204, Src Train Acc: 95.83, Src Test Acc: 95.72, Trg Test Acc: 88.64\n",
      "Epoch: 094, CrossE: 0.1240, Src Train Acc: 95.96, Src Test Acc: 94.55, Trg Test Acc: 88.14\n",
      "Epoch: 095, CrossE: 0.1227, Src Train Acc: 96.05, Src Test Acc: 94.55, Trg Test Acc: 87.97\n",
      "Epoch: 096, CrossE: 0.1148, Src Train Acc: 96.09, Src Test Acc: 94.16, Trg Test Acc: 88.72\n",
      "Epoch: 097, CrossE: 0.1111, Src Train Acc: 96.40, Src Test Acc: 94.94, Trg Test Acc: 88.39\n",
      "Epoch: 098, CrossE: 0.1119, Src Train Acc: 96.31, Src Test Acc: 93.77, Trg Test Acc: 89.22\n",
      "Epoch: 099, CrossE: 0.1089, Src Train Acc: 96.61, Src Test Acc: 94.94, Trg Test Acc: 88.72\n",
      "Epoch: 100, CrossE: 0.1047, Src Train Acc: 96.35, Src Test Acc: 93.00, Trg Test Acc: 88.47\n",
      "Epoch: 101, CrossE: 0.0972, Src Train Acc: 97.05, Src Test Acc: 94.94, Trg Test Acc: 87.72\n",
      "Epoch: 102, CrossE: 0.0986, Src Train Acc: 96.53, Src Test Acc: 90.66, Trg Test Acc: 80.79\n",
      "Epoch: 103, CrossE: 0.2275, Src Train Acc: 95.40, Src Test Acc: 93.39, Trg Test Acc: 87.39\n",
      "Epoch: 104, CrossE: 0.0787, Src Train Acc: 97.61, Src Test Acc: 92.22, Trg Test Acc: 85.38\n",
      "Epoch: 105, CrossE: 0.0740, Src Train Acc: 97.70, Src Test Acc: 94.16, Trg Test Acc: 88.14\n",
      "Epoch: 106, CrossE: 0.0761, Src Train Acc: 97.48, Src Test Acc: 93.77, Trg Test Acc: 83.21\n",
      "Epoch: 107, CrossE: 0.1332, Src Train Acc: 95.88, Src Test Acc: 94.55, Trg Test Acc: 88.72\n",
      "Epoch: 108, CrossE: 0.0634, Src Train Acc: 97.92, Src Test Acc: 93.39, Trg Test Acc: 87.13\n",
      "Epoch: 109, CrossE: 0.0615, Src Train Acc: 98.13, Src Test Acc: 93.00, Trg Test Acc: 87.39\n",
      "Epoch: 110, CrossE: 0.0852, Src Train Acc: 97.31, Src Test Acc: 93.00, Trg Test Acc: 87.39\n",
      "Epoch: 111, CrossE: 0.2321, Src Train Acc: 93.62, Src Test Acc: 93.00, Trg Test Acc: 88.81\n",
      "Epoch: 112, CrossE: 0.0714, Src Train Acc: 98.09, Src Test Acc: 93.00, Trg Test Acc: 86.72\n",
      "Epoch: 113, CrossE: 0.0600, Src Train Acc: 98.05, Src Test Acc: 90.66, Trg Test Acc: 86.05\n",
      "Epoch: 114, CrossE: 0.0617, Src Train Acc: 97.92, Src Test Acc: 92.61, Trg Test Acc: 85.71\n",
      "Epoch: 115, CrossE: 0.0544, Src Train Acc: 98.31, Src Test Acc: 91.83, Trg Test Acc: 86.55\n",
      "Epoch: 116, CrossE: 0.0921, Src Train Acc: 96.66, Src Test Acc: 91.83, Trg Test Acc: 87.13\n",
      "Epoch: 117, CrossE: 0.0722, Src Train Acc: 97.61, Src Test Acc: 89.88, Trg Test Acc: 80.28\n",
      "Epoch: 118, CrossE: 0.2482, Src Train Acc: 94.88, Src Test Acc: 93.77, Trg Test Acc: 88.05\n",
      "Epoch: 119, CrossE: 0.0523, Src Train Acc: 98.57, Src Test Acc: 93.39, Trg Test Acc: 87.72\n",
      "Epoch: 120, CrossE: 0.0473, Src Train Acc: 98.52, Src Test Acc: 91.44, Trg Test Acc: 86.97\n",
      "Epoch: 121, CrossE: 0.0401, Src Train Acc: 99.00, Src Test Acc: 94.94, Trg Test Acc: 88.14\n",
      "Epoch: 122, CrossE: 0.0422, Src Train Acc: 98.57, Src Test Acc: 90.66, Trg Test Acc: 86.38\n",
      "Epoch: 123, CrossE: 0.0792, Src Train Acc: 97.31, Src Test Acc: 91.05, Trg Test Acc: 86.47\n",
      "Epoch: 124, CrossE: 0.0600, Src Train Acc: 98.05, Src Test Acc: 92.61, Trg Test Acc: 86.88\n",
      "Epoch: 125, CrossE: 0.0725, Src Train Acc: 97.44, Src Test Acc: 92.61, Trg Test Acc: 86.80\n",
      "Epoch: 126, CrossE: 0.0515, Src Train Acc: 98.31, Src Test Acc: 91.44, Trg Test Acc: 85.71\n",
      "Epoch: 127, CrossE: 0.0692, Src Train Acc: 97.48, Src Test Acc: 94.94, Trg Test Acc: 88.97\n",
      "Epoch: 128, CrossE: 0.1228, Src Train Acc: 96.35, Src Test Acc: 93.77, Trg Test Acc: 88.64\n",
      "Epoch: 129, CrossE: 0.0617, Src Train Acc: 98.18, Src Test Acc: 90.66, Trg Test Acc: 85.88\n",
      "Epoch: 130, CrossE: 0.3008, Src Train Acc: 94.05, Src Test Acc: 94.94, Trg Test Acc: 89.14\n",
      "Epoch: 131, CrossE: 0.0440, Src Train Acc: 98.91, Src Test Acc: 95.72, Trg Test Acc: 89.81\n",
      "Epoch: 132, CrossE: 0.0370, Src Train Acc: 99.00, Src Test Acc: 94.94, Trg Test Acc: 89.06\n",
      "Epoch: 133, CrossE: 0.0317, Src Train Acc: 99.22, Src Test Acc: 94.16, Trg Test Acc: 89.64\n",
      "Epoch: 134, CrossE: 0.0302, Src Train Acc: 99.22, Src Test Acc: 92.61, Trg Test Acc: 87.72\n",
      "Epoch: 135, CrossE: 0.0399, Src Train Acc: 99.05, Src Test Acc: 93.39, Trg Test Acc: 87.89\n",
      "Epoch: 136, CrossE: 0.0423, Src Train Acc: 98.83, Src Test Acc: 96.89, Trg Test Acc: 90.56\n",
      "Epoch: 137, CrossE: 0.0305, Src Train Acc: 99.35, Src Test Acc: 96.11, Trg Test Acc: 91.31\n",
      "Epoch: 138, CrossE: 0.2730, Src Train Acc: 94.18, Src Test Acc: 95.33, Trg Test Acc: 88.89\n",
      "Epoch: 139, CrossE: 0.0532, Src Train Acc: 98.48, Src Test Acc: 96.11, Trg Test Acc: 89.97\n",
      "Epoch: 140, CrossE: 0.0358, Src Train Acc: 98.87, Src Test Acc: 94.55, Trg Test Acc: 89.31\n",
      "Epoch: 141, CrossE: 0.0268, Src Train Acc: 99.13, Src Test Acc: 94.16, Trg Test Acc: 88.14\n",
      "Epoch: 142, CrossE: 0.0243, Src Train Acc: 99.39, Src Test Acc: 95.72, Trg Test Acc: 89.22\n",
      "Epoch: 143, CrossE: 0.0403, Src Train Acc: 98.83, Src Test Acc: 96.11, Trg Test Acc: 89.72\n",
      "Epoch: 144, CrossE: 0.2402, Src Train Acc: 94.70, Src Test Acc: 94.16, Trg Test Acc: 85.80\n",
      "Epoch: 145, CrossE: 0.0545, Src Train Acc: 98.74, Src Test Acc: 95.72, Trg Test Acc: 91.40\n",
      "Epoch: 146, CrossE: 0.0289, Src Train Acc: 99.52, Src Test Acc: 94.16, Trg Test Acc: 88.89\n",
      "Epoch: 147, CrossE: 0.0249, Src Train Acc: 99.48, Src Test Acc: 94.55, Trg Test Acc: 87.64\n",
      "Epoch: 148, CrossE: 0.0208, Src Train Acc: 99.61, Src Test Acc: 96.11, Trg Test Acc: 88.05\n",
      "Epoch: 149, CrossE: 0.0201, Src Train Acc: 99.52, Src Test Acc: 94.94, Trg Test Acc: 88.81\n",
      "Epoch: 150, CrossE: 0.0310, Src Train Acc: 99.31, Src Test Acc: 95.33, Trg Test Acc: 88.81\n",
      "Epoch: 151, CrossE: 0.0214, Src Train Acc: 99.57, Src Test Acc: 95.33, Trg Test Acc: 90.98\n",
      "Epoch: 152, CrossE: 0.0162, Src Train Acc: 99.70, Src Test Acc: 95.72, Trg Test Acc: 89.72\n",
      "Epoch: 153, CrossE: 0.0122, Src Train Acc: 99.74, Src Test Acc: 97.67, Trg Test Acc: 89.22\n",
      "Epoch: 154, CrossE: 0.0127, Src Train Acc: 99.83, Src Test Acc: 97.28, Trg Test Acc: 90.23\n",
      "Epoch: 155, CrossE: 1.4330, Src Train Acc: 76.26, Src Test Acc: 87.94, Trg Test Acc: 74.69\n",
      "Epoch: 156, CrossE: 0.2522, Src Train Acc: 91.41, Src Test Acc: 91.83, Trg Test Acc: 80.12\n",
      "Epoch: 157, CrossE: 0.1766, Src Train Acc: 93.92, Src Test Acc: 93.00, Trg Test Acc: 82.04\n",
      "Epoch: 158, CrossE: 0.1428, Src Train Acc: 95.14, Src Test Acc: 93.00, Trg Test Acc: 83.21\n",
      "Epoch: 159, CrossE: 0.1070, Src Train Acc: 96.40, Src Test Acc: 94.55, Trg Test Acc: 84.46\n",
      "Epoch: 160, CrossE: 0.0824, Src Train Acc: 97.40, Src Test Acc: 94.55, Trg Test Acc: 85.96\n",
      "Epoch: 161, CrossE: 0.0643, Src Train Acc: 98.09, Src Test Acc: 93.77, Trg Test Acc: 87.55\n",
      "Epoch: 162, CrossE: 0.0473, Src Train Acc: 98.52, Src Test Acc: 95.72, Trg Test Acc: 88.72\n",
      "Epoch: 163, CrossE: 0.0343, Src Train Acc: 99.18, Src Test Acc: 94.55, Trg Test Acc: 88.81\n",
      "Epoch: 164, CrossE: 0.0293, Src Train Acc: 99.48, Src Test Acc: 94.55, Trg Test Acc: 88.55\n",
      "Epoch: 165, CrossE: 0.0232, Src Train Acc: 99.57, Src Test Acc: 96.11, Trg Test Acc: 88.97\n",
      "Epoch: 166, CrossE: 0.0209, Src Train Acc: 99.48, Src Test Acc: 96.50, Trg Test Acc: 90.31\n",
      "Epoch: 167, CrossE: 0.0183, Src Train Acc: 99.70, Src Test Acc: 96.50, Trg Test Acc: 90.39\n",
      "Epoch: 168, CrossE: 0.0212, Src Train Acc: 99.44, Src Test Acc: 96.89, Trg Test Acc: 88.81\n",
      "Epoch: 169, CrossE: 0.2045, Src Train Acc: 95.10, Src Test Acc: 95.33, Trg Test Acc: 86.63\n",
      "Epoch: 170, CrossE: 0.0400, Src Train Acc: 98.96, Src Test Acc: 98.05, Trg Test Acc: 90.73\n",
      "Epoch: 171, CrossE: 0.0135, Src Train Acc: 99.83, Src Test Acc: 97.28, Trg Test Acc: 90.48\n",
      "Epoch: 172, CrossE: 0.0103, Src Train Acc: 99.83, Src Test Acc: 97.67, Trg Test Acc: 90.48\n",
      "Epoch: 173, CrossE: 0.0081, Src Train Acc: 99.96, Src Test Acc: 97.28, Trg Test Acc: 90.64\n",
      "Epoch: 174, CrossE: 0.0067, Src Train Acc: 99.96, Src Test Acc: 97.28, Trg Test Acc: 91.23\n",
      "Epoch: 175, CrossE: 0.0057, Src Train Acc: 99.96, Src Test Acc: 97.28, Trg Test Acc: 91.31\n",
      "Epoch: 176, CrossE: 0.0057, Src Train Acc: 99.91, Src Test Acc: 96.89, Trg Test Acc: 91.65\n",
      "Epoch: 177, CrossE: 0.0043, Src Train Acc: 99.96, Src Test Acc: 97.67, Trg Test Acc: 91.31\n",
      "Epoch: 178, CrossE: 0.0043, Src Train Acc: 99.96, Src Test Acc: 97.67, Trg Test Acc: 91.40\n",
      "Epoch: 179, CrossE: 0.0034, Src Train Acc: 99.96, Src Test Acc: 97.67, Trg Test Acc: 91.31\n",
      "Epoch: 180, CrossE: 0.0029, Src Train Acc: 100.00, Src Test Acc: 97.28, Trg Test Acc: 91.40\n",
      "Epoch: 181, CrossE: 0.0024, Src Train Acc: 100.00, Src Test Acc: 96.89, Trg Test Acc: 91.40\n",
      "Epoch: 182, CrossE: 0.0021, Src Train Acc: 100.00, Src Test Acc: 97.28, Trg Test Acc: 91.31\n",
      "Epoch: 183, CrossE: 0.0019, Src Train Acc: 100.00, Src Test Acc: 96.50, Trg Test Acc: 91.23\n",
      "Epoch: 184, CrossE: 0.0017, Src Train Acc: 100.00, Src Test Acc: 96.11, Trg Test Acc: 91.31\n",
      "Epoch: 185, CrossE: 0.0015, Src Train Acc: 100.00, Src Test Acc: 96.11, Trg Test Acc: 91.31\n",
      "Epoch: 186, CrossE: 0.0013, Src Train Acc: 100.00, Src Test Acc: 96.11, Trg Test Acc: 91.06\n",
      "Epoch: 187, CrossE: 0.0012, Src Train Acc: 100.00, Src Test Acc: 96.11, Trg Test Acc: 91.06\n",
      "Epoch: 188, CrossE: 0.0011, Src Train Acc: 100.00, Src Test Acc: 96.11, Trg Test Acc: 91.06\n",
      "Epoch: 189, CrossE: 0.0010, Src Train Acc: 100.00, Src Test Acc: 96.11, Trg Test Acc: 91.06\n",
      "Epoch: 190, CrossE: 0.0009, Src Train Acc: 100.00, Src Test Acc: 96.11, Trg Test Acc: 91.06\n",
      "Epoch: 191, CrossE: 0.0008, Src Train Acc: 100.00, Src Test Acc: 96.50, Trg Test Acc: 91.23\n",
      "Epoch: 192, CrossE: 0.0008, Src Train Acc: 100.00, Src Test Acc: 96.50, Trg Test Acc: 91.23\n",
      "Epoch: 193, CrossE: 0.0007, Src Train Acc: 100.00, Src Test Acc: 96.50, Trg Test Acc: 91.31\n",
      "Epoch: 194, CrossE: 0.0006, Src Train Acc: 100.00, Src Test Acc: 96.89, Trg Test Acc: 91.31\n",
      "Epoch: 195, CrossE: 0.0006, Src Train Acc: 100.00, Src Test Acc: 96.89, Trg Test Acc: 91.23\n",
      "Epoch: 196, CrossE: 0.0006, Src Train Acc: 100.00, Src Test Acc: 96.89, Trg Test Acc: 91.23\n",
      "Epoch: 197, CrossE: 0.0005, Src Train Acc: 100.00, Src Test Acc: 96.89, Trg Test Acc: 91.23\n",
      "Epoch: 198, CrossE: 0.0005, Src Train Acc: 100.00, Src Test Acc: 96.89, Trg Test Acc: 91.23\n",
      "Epoch: 199, CrossE: 0.0004, Src Train Acc: 100.00, Src Test Acc: 96.89, Trg Test Acc: 91.14\n",
      "Epoch: 200, CrossE: 0.0004, Src Train Acc: 100.00, Src Test Acc: 97.28, Trg Test Acc: 91.23\n"
     ]
    }
   ],
   "source": [
    "generator      = ResNet50(num_classes, 64)\n",
    "gen_optimizer  = tf.keras.optimizers.Adam(learning_rate = learning_rate, beta_1 = 0.5)\n",
    "\n",
    "train_template = 'Epoch: {:03d}, CrossE: {:.4f}, Src Train Acc: {:.2f}, '\n",
    "test_template  = 'Src Test Acc: {:.2f}, Trg Test Acc: {:.2f}'\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  for source_data in src_train_set:\n",
    "    train_baseline_step(source_data[0], source_data[1])\n",
    "\n",
    "  print(train_template.format(epoch+1,\n",
    "                              train_cross_entropy_loss.result(),\n",
    "                              src_train_accuracy.result()*100), end=\"\")\n",
    "\n",
    "  train_cross_entropy_loss.reset_states()\n",
    "  src_train_accuracy.reset_states()\n",
    "\n",
    "  for target_data in trg_test_set:\n",
    "    test_target_step(target_data[0], target_data[1])\n",
    "\n",
    "  for source_data in src_test_set:\n",
    "    test_source_step(source_data[0], source_data[1])\n",
    "\n",
    "  print(test_template.format(src_test_accuracy.result()*100,\n",
    "                             trg_test_accuracy.result()*100))\n",
    "\n",
    "  src_test_accuracy.reset_states()\n",
    "  trg_test_accuracy.reset_states()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
