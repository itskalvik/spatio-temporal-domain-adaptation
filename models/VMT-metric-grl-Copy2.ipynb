{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/kjakkala/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kjakkala/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kjakkala/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kjakkala/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kjakkala/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kjakkala/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes     = 9\n",
    "batch_size      = 8\n",
    "train_src_days  = 3\n",
    "train_trg_days  = 3\n",
    "epochs          = 500\n",
    "learning_rate   = 0.0001\n",
    "num_hidden      = [1024, 512]\n",
    "num_features    = 256\n",
    "alpha           = 0.05\n",
    "disc_activation = 'selu'\n",
    "gen_activation  = 'selu'\n",
    "train_trg_env_days = 2\n",
    "notes           = \"VMT_gauss_noise_cv_data_center_adapt_grl2d_serverconftime_{}trg_day_resize224_highertrg\".format(train_trg_env_days)\n",
    "\n",
    "log_data = \"classes-{}_bs-{}_train_src_days-{}_train_trg_days-{}_lr-{}_num_hidden-{}_num_feat-{}_disc_act-{}_gen_act-{}_center_alpha-{}_{}\".format(num_classes, \n",
    "                                                                                                                                                        batch_size, \n",
    "                                                                                                                                                        train_src_days, \n",
    "                                                                                                                                                        train_trg_days, \n",
    "                                                                                                                                                        learning_rate, \n",
    "                                                                                                                                                        num_hidden, \n",
    "                                                                                                                                                        num_features,\n",
    "                                                                                                                                                        disc_activation,\n",
    "                                                                                                                                                        gen_activation,\n",
    "                                                                                                                                                        alpha,\n",
    "                                                                                                                                                        notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_data(data, output_shape=(224, 224)):\n",
    "  _, height, width, channels = data.shape\n",
    "  data = data.transpose((1, 2, 3, 0)) \n",
    "  data = resize(data.reshape(height, width, -1), output_shape)\n",
    "  data = data.reshape(*output_shape, channels, -1)\n",
    "  data = data.transpose((3, 0, 1, 2))\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9127, 224, 224, 1) (9127, 2) \n",
      " ['arahman3', 'harika', 'hchen32', 'jlaivins', 'kjakkala', 'pjanakar', 'ppinyoan', 'pwang13', 'upattnai', 'wrang']\n",
      "(8737, 224, 224, 1) (8737, 2)\n",
      "(8547, 224, 224, 1) (8547, 2) \n",
      " ['arahman3', 'hchen32', 'jlaivins', 'kjakkala', 'pjanakar', 'ppinyoan', 'pwang13', 'upattnai', 'wrang']\n",
      "(2308, 224, 224, 1) (2308, 9) (257, 224, 224, 1) (257, 9) (2563, 224, 224, 1) (2563, 9) (3419, 224, 224, 1) (3419, 9)\n"
     ]
    }
   ],
   "source": [
    "#Read data\n",
    "hf = h5py.File('/home/kjakkala/mmwave/data/source_data.h5', 'r')\n",
    "X_data = resize_data(np.expand_dims(hf.get('X_data'), axis=-1))\n",
    "y_data = np.array(hf.get('y_data'))\n",
    "classes = list(hf.get('classes'))\n",
    "classes = [n.decode(\"ascii\", \"ignore\") for n in classes]\n",
    "hf.close()\n",
    "print(X_data.shape, y_data.shape, \"\\n\", classes)\n",
    "\n",
    "#balence dataset to 95 samples per day for each person\n",
    "X_data_tmp = []\n",
    "y_data_tmp = []\n",
    "for day in range(10):\n",
    "  for idx in range(len(classes)):\n",
    "    X_data_tmp.extend(X_data[(y_data[:, 0] == idx) & (y_data[:, 1] == day)][:95])\n",
    "    y_data_tmp.extend(y_data[(y_data[:, 0] == idx) & (y_data[:, 1] == day)][:95])\n",
    "X_data = np.array(X_data_tmp)\n",
    "y_data = np.array(y_data_tmp)\n",
    "del X_data_tmp, y_data_tmp\n",
    "print(X_data.shape, y_data.shape)\n",
    "\n",
    "#remove harika's data\n",
    "X_data = np.delete(X_data, np.where(y_data[:, 0] == 1)[0], 0)\n",
    "y_data = np.delete(y_data, np.where(y_data[:, 0] == 1)[0], 0)\n",
    "\n",
    "#update labes to handle 9 classes instead of 10\n",
    "y_data[y_data[:, 0] >= 2, 0] -= 1\n",
    "del classes[1]\n",
    "print(X_data.shape, y_data.shape, \"\\n\", classes)\n",
    "\n",
    "#split days of data to train and test\n",
    "X_src = X_data[y_data[:, 1] < train_src_days]\n",
    "y_src = y_data[y_data[:, 1] < train_src_days, 0]\n",
    "y_src = np.eye(len(classes))[y_src]\n",
    "X_train_src, X_test_src, y_train_src, y_test_src = train_test_split(X_src,\n",
    "                                                                    y_src,\n",
    "                                                                    stratify=y_src,\n",
    "                                                                    test_size=0.10,\n",
    "                                                                    random_state=42)\n",
    "\n",
    "X_trg = X_data[y_data[:, 1] >= train_src_days]\n",
    "y_trg = y_data[y_data[:, 1] >= train_src_days]\n",
    "X_train_trg = X_trg[y_trg[:, 1] < train_src_days+train_trg_days]\n",
    "y_train_trg = y_trg[y_trg[:, 1] < train_src_days+train_trg_days, 0]\n",
    "y_train_trg = np.eye(len(classes))[y_train_trg]\n",
    "\n",
    "X_test_trg = X_data[y_data[:, 1] >= train_src_days+train_trg_days]\n",
    "y_test_trg = y_data[y_data[:, 1] >= train_src_days+train_trg_days, 0]\n",
    "y_test_trg = np.eye(len(classes))[y_test_trg]\n",
    "\n",
    "del X_src, y_src, X_trg, y_trg, X_data, y_data\n",
    "\n",
    "#standardise dataset\n",
    "src_mean = np.mean(X_train_src)\n",
    "X_train_src -= src_mean\n",
    "src_std  = np.std(X_train_src)\n",
    "X_train_src /= src_std\n",
    "\n",
    "X_test_src -= src_mean\n",
    "X_test_src /= src_std\n",
    "\n",
    "trg_mean = np.mean(X_train_trg)\n",
    "X_train_trg -= trg_mean\n",
    "trg_std  = np.std(X_train_trg)\n",
    "X_train_trg /= trg_std\n",
    "\n",
    "X_test_trg -= src_mean\n",
    "X_test_trg /= src_std\n",
    "\n",
    "X_train_src = X_train_src.astype(np.float32)\n",
    "y_train_src = y_train_src.astype(np.uint8)\n",
    "X_test_src  = X_test_src.astype(np.float32)\n",
    "y_test_src  = y_test_src.astype(np.uint8)\n",
    "X_train_trg = X_train_trg.astype(np.float32)\n",
    "y_train_trg = y_train_trg.astype(np.uint8)\n",
    "X_test_trg  = X_test_trg.astype(np.float32)\n",
    "y_test_trg  = y_test_trg.astype(np.uint8)\n",
    "\n",
    "print(X_train_src.shape, y_train_src.shape,  X_test_src.shape, y_test_src.shape, X_train_trg.shape, y_train_trg.shape, X_test_trg.shape, y_test_trg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 224, 224, 1) (900, 9) (450, 224, 224, 1) (450, 9)\n",
      "(898, 224, 224, 1) (898, 9) (448, 224, 224, 1) (448, 9)\n",
      "(899, 224, 224, 1) (899, 9)\n"
     ]
    }
   ],
   "source": [
    "def get_trg_data(fname, src_classes, train_trg_days):\n",
    "  #Read data\n",
    "  hf = h5py.File(fname, 'r')\n",
    "  X_data_trg = resize_data(np.expand_dims(hf.get('X_data'), axis=-1))\n",
    "  y_data_trg = np.array(hf.get('y_data'))\n",
    "  trg_classes = list(hf.get('classes'))\n",
    "  trg_classes = [n.decode(\"ascii\", \"ignore\") for n in trg_classes]\n",
    "  hf.close()\n",
    "\n",
    "  #split days of data to train and test\n",
    "  X_train_trg = X_data_trg[y_data_trg[:, 1] < train_trg_days]\n",
    "  y_train_trg = y_data_trg[y_data_trg[:, 1] < train_trg_days, 0]\n",
    "  y_train_trg = np.array([src_classes.index(trg_classes[y_train_trg[i]]) for i in range(y_train_trg.shape[0])])\n",
    "  y_train_trg = np.eye(len(src_classes))[y_train_trg]\n",
    "  y_train_trg = y_train_trg.astype(np.int64)\n",
    "\n",
    "  X_test_trg = X_data_trg[y_data_trg[:, 1] >= train_trg_days]\n",
    "  y_test_trg = y_data_trg[y_data_trg[:, 1] >= train_trg_days, 0]\n",
    "  y_test_trg = np.eye(len(src_classes))[y_test_trg]\n",
    "  y_test_trg = y_test_trg.astype(np.int64)\n",
    "\n",
    "  #standardise dataset  \n",
    "  trg_mean     = np.mean(X_train_trg)\n",
    "  X_train_trg -= trg_mean\n",
    "  trg_std      = np.std(X_train_trg)\n",
    "  X_train_trg /= trg_std\n",
    "\n",
    "  X_test_trg  -= trg_mean\n",
    "  X_test_trg  /= trg_std\n",
    "  \n",
    "  return X_train_trg.astype(np.float32), y_train_trg.astype(np.uint8), X_test_trg.astype(np.float32), y_test_trg.astype(np.uint8)\n",
    "\n",
    "X_train_conf,   y_train_conf,   X_test_conf,   y_test_conf   = get_trg_data('/home/kjakkala/mmwave/data/target_conf_data.h5',   classes, train_trg_env_days)\n",
    "X_train_server, y_train_server, X_test_server, y_test_server = get_trg_data('/home/kjakkala/mmwave/data/target_server_data.h5', classes, train_trg_env_days)\n",
    "X_data_office,  y_data_office,  _,             _             = get_trg_data('/home/kjakkala/mmwave/data/target_office_data.h5', classes, 3)\n",
    "\n",
    "print(X_train_conf.shape,   y_train_conf.shape,    X_test_conf.shape,   y_test_conf.shape)\n",
    "print(X_train_server.shape, y_train_server.shape,  X_test_server.shape, y_test_server.shape)\n",
    "print(X_data_office.shape, y_data_office.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get tf.data objects for each set\n",
    "\n",
    "#Test\n",
    "conf_test_set = tf.data.Dataset.from_tensor_slices((X_test_conf, y_test_conf))\n",
    "conf_test_set = conf_test_set.batch(batch_size, drop_remainder=False)\n",
    "conf_test_set = conf_test_set.prefetch(batch_size)\n",
    "\n",
    "server_test_set = tf.data.Dataset.from_tensor_slices((X_test_server, y_test_server))\n",
    "server_test_set = server_test_set.batch(batch_size, drop_remainder=False)\n",
    "server_test_set = server_test_set.prefetch(batch_size)\n",
    "\n",
    "office_test_set = tf.data.Dataset.from_tensor_slices((X_data_office, y_data_office))\n",
    "office_test_set = office_test_set.batch(batch_size, drop_remainder=False)\n",
    "office_test_set = office_test_set.prefetch(batch_size)\n",
    "\n",
    "src_test_set = tf.data.Dataset.from_tensor_slices((X_test_src, y_test_src))\n",
    "src_test_set = src_test_set.batch(batch_size, drop_remainder=False)\n",
    "src_test_set = src_test_set.prefetch(batch_size)\n",
    "\n",
    "trg_test_set = tf.data.Dataset.from_tensor_slices((X_test_trg, y_test_trg))\n",
    "trg_test_set = trg_test_set.batch(batch_size, drop_remainder=False)\n",
    "trg_test_set = trg_test_set.prefetch(batch_size)\n",
    "\n",
    "#Train\n",
    "src_train_set = tf.data.Dataset.from_tensor_slices((X_train_src, y_train_src))\n",
    "src_train_set = src_train_set.shuffle(X_train_src.shape[0])\n",
    "src_train_set = src_train_set.batch(batch_size, drop_remainder=True)\n",
    "src_train_set = src_train_set.prefetch(batch_size)\n",
    "\n",
    "server_train_set = tf.data.Dataset.from_tensor_slices((X_train_server, y_train_server))\n",
    "server_train_set = server_train_set.shuffle(X_train_server.shape[0])\n",
    "server_train_set = server_train_set.batch(batch_size, drop_remainder=True)\n",
    "server_train_set = server_train_set.prefetch(batch_size)\n",
    "server_train_set = server_train_set.repeat(-1)\n",
    "\n",
    "conf_train_set = tf.data.Dataset.from_tensor_slices((X_train_conf, y_train_conf))\n",
    "conf_train_set = conf_train_set.shuffle(X_train_conf.shape[0])\n",
    "conf_train_set = conf_train_set.batch(batch_size, drop_remainder=True)\n",
    "conf_train_set = conf_train_set.prefetch(batch_size)\n",
    "conf_train_set = conf_train_set.repeat(-1)\n",
    "\n",
    "if (X_train_trg.shape[0] > 0):\n",
    "  time_train_set = tf.data.Dataset.from_tensor_slices((X_train_trg, y_train_trg))\n",
    "  time_train_set = time_train_set.shuffle(X_train_trg.shape[0])\n",
    "  time_train_set = time_train_set.batch(batch_size, drop_remainder=True)\n",
    "  time_train_set = time_train_set.prefetch(batch_size)\n",
    "  time_train_set = time_train_set.repeat(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_WEIGHT_DECAY = 1e-4\n",
    "BATCH_NORM_DECAY = 0.9\n",
    "BATCH_NORM_EPSILON = 1e-5\n",
    "\n",
    "class GaussianNoise(tf.keras.layers.Layer):\n",
    "  def __init__(self, std):\n",
    "    super(GaussianNoise, self).__init__()\n",
    "    self.std = std\n",
    "\n",
    "  def build(self, input_shapes):\n",
    "    pass\n",
    "\n",
    "  def call(self, inputs, training=False):\n",
    "    eps = tf.random.normal(shape=tf.shape(inputs), mean=0.0, stddev=self.std)\n",
    "    return tf.where(training, inputs + eps, inputs)\n",
    "\n",
    "class IdentityBlock(tf.keras.Model):\n",
    "  def __init__(self, kernel_size, filters, stage, block, activation='relu'):\n",
    "    self.activation = activation#get tf.data objects for each set\n",
    "\n",
    "#Test\n",
    "conf_test_set = tf.data.Dataset.from_tensor_slices((X_test_conf, y_test_conf))\n",
    "conf_test_set = conf_test_set.batch(batch_size, drop_remainder=False)\n",
    "conf_test_set = conf_test_set.prefetch(batch_size)\n",
    "\n",
    "server_test_set = tf.data.Dataset.from_tensor_slices((X_test_server, y_test_server))\n",
    "server_test_set = server_test_set.batch(batch_size, drop_remainder=False)\n",
    "server_test_set = server_test_set.prefetch(batch_size)\n",
    "\n",
    "office_test_set = tf.data.Dataset.from_tensor_slices((X_data_office, y_data_office))\n",
    "office_test_set = office_test_set.batch(batch_size, drop_remainder=False)\n",
    "office_test_set = office_test_set.prefetch(batch_size)\n",
    "\n",
    "src_test_set = tf.data.Dataset.from_tensor_slices((X_test_src, y_test_src))\n",
    "src_test_set = src_test_set.batch(batch_size, drop_remainder=False)\n",
    "src_test_set = src_test_set.prefetch(batch_size)\n",
    "\n",
    "trg_test_set = tf.data.Dataset.from_tensor_slices((X_test_trg, y_test_trg))\n",
    "trg_test_set = trg_test_set.batch(batch_size, drop_remainder=False)\n",
    "trg_test_set = trg_test_set.prefetch(batch_size)\n",
    "\n",
    "#Train\n",
    "src_train_set = tf.data.Dataset.from_tensor_slices((X_train_src, y_train_src))\n",
    "src_train_set = src_train_set.shuffle(X_train_src.shape[0])\n",
    "src_train_set = src_train_set.batch(batch_size, drop_remainder=True)\n",
    "src_train_set = src_train_set.prefetch(batch_size)\n",
    "\n",
    "server_train_set = tf.data.Dataset.from_tensor_slices((X_train_server, y_train_server))\n",
    "server_train_set = server_train_set.shuffle(X_train_server.shape[0])\n",
    "server_train_set = server_train_set.batch(batch_size, drop_remainder=True)\n",
    "server_train_set = server_train_set.prefetch(batch_size)\n",
    "server_train_set = server_train_set.repeat(-1)\n",
    "\n",
    "conf_train_set = tf.data.Dataset.from_tensor_slices((X_train_conf, y_train_conf))\n",
    "conf_train_set = conf_train_set.shuffle(X_train_conf.shape[0])\n",
    "conf_train_set = conf_train_set.batch(batch_size, drop_remainder=True)\n",
    "conf_train_set = conf_train_set.prefetch(batch_size)\n",
    "conf_train_set = conf_train_set.repeat(-1)\n",
    "\n",
    "if (X_train_trg.shape[0] > 0):\n",
    "  time_train_set = tf.data.Dataset.from_tensor_slices((X_train_trg, y_train_trg))\n",
    "  time_train_set = time_train_set.shuffle(X_train_trg.shape[0])\n",
    "  time_train_set = time_train_set.batch(batch_size, drop_remainder=True)\n",
    "  time_train_set = time_train_set.prefetch(batch_size)\n",
    "  time_train_set = time_train_set.repeat(-1)\n",
    "    \n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    super().__init__(name='stage-' + str(stage) + '_block-' + block)\n",
    "\n",
    "    filters1, filters2, filters3 = filters\n",
    "    bn_axis = -1\n",
    "\n",
    "    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1),\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '2a')\n",
    "    self.bn2a = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '2a')\n",
    "\n",
    "    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size,\n",
    "                                         padding='same',\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '2b')\n",
    "    self.bn2b = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '2b')\n",
    "\n",
    "    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1),\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '2c')\n",
    "    self.bn2c = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '2c')\n",
    "\n",
    "  def call(self, input_tensor, training=False):\n",
    "    x = self.conv2a(input_tensor)\n",
    "    x = self.bn2a(x, training=training)\n",
    "    x = tf.keras.layers.Activation(self.activation)(x)\n",
    "\n",
    "    x = self.conv2b(x)\n",
    "    x = self.bn2b(x, training=training)\n",
    "    x = tf.keras.layers.Activation(self.activation)(x)\n",
    "\n",
    "    x = self.conv2c(x)\n",
    "    x = self.bn2c(x, training=training)\n",
    "\n",
    "    x = tf.keras.layers.add([x, input_tensor])\n",
    "    x = tf.keras.layers.Activation(self.activation)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\"\"\"A block that has a conv layer at shortcut.\n",
    "\n",
    "Note that from stage 3,\n",
    "the second conv layer at main path is with strides=(2, 2)\n",
    "And the shortcut should have strides=(2, 2) as well\n",
    "\n",
    "Args:\n",
    "  kernel_size: the kernel size of middle conv layer at main path\n",
    "  filters: list of integers, the filters of 3 conv layer at main path\n",
    "  stage: integer, current stage label, used for generating layer names\n",
    "  block: 'a','b'..., current block label, used for generating layer names\n",
    "  strides: Strides for the second conv layer in the block.\n",
    "\n",
    "Returns:\n",
    "  A Keras model instance for the block.\n",
    "\"\"\"\n",
    "class ConvBlock(tf.keras.Model):\n",
    "  def __init__(self, kernel_size, filters, stage, block, strides=(2, 2), activation='relu'):\n",
    "    self.activation = activation\n",
    "    \n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    super().__init__(name='stage-' + str(stage) + '_block-' + block)\n",
    "\n",
    "    filters1, filters2, filters3 = filters\n",
    "    bn_axis = -1\n",
    "\n",
    "    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1),\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '2a')\n",
    "    self.bn2a = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '2a')\n",
    "\n",
    "    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size,\n",
    "                                         strides=strides,\n",
    "                                         padding='same',\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '2b')\n",
    "    self.bn2b = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '2b')\n",
    "\n",
    "    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1),\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '2c')\n",
    "    self.bn2c = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '2c')\n",
    "\n",
    "    self.conv2s = tf.keras.layers.Conv2D(filters3, (1, 1),\n",
    "                                         strides=strides,\n",
    "                                         use_bias=False,\n",
    "                                         kernel_initializer='he_normal',\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                         name=conv_name_base + '1')\n",
    "    self.bn2s = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                   momentum=BATCH_NORM_DECAY,\n",
    "                                                   epsilon=BATCH_NORM_EPSILON,\n",
    "                                                   name=bn_name_base + '1')\n",
    "    self.gauss1   = GaussianNoise(1)\n",
    "\n",
    "  def call(self, input_tensor, training=False):\n",
    "    x = self.conv2a(input_tensor)\n",
    "    x = self.bn2a(x, training=training)\n",
    "    x = tf.keras.layers.Activation(self.activation)(x)\n",
    "\n",
    "    x = self.conv2b(x)\n",
    "    x = self.bn2b(x, training=training)\n",
    "    x = tf.keras.layers.Activation(self.activation)(x)\n",
    "\n",
    "    x = self.conv2c(x)\n",
    "    x = self.bn2c(x, training=training)\n",
    "\n",
    "    shortcut = self.conv2s(input_tensor)\n",
    "    shortcut = self.bn2s(shortcut, training=training)\n",
    "\n",
    "    x = tf.keras.layers.add([x, shortcut])\n",
    "    x = tf.keras.layers.Activation(self.activation)(x)\n",
    "    x = self.gauss1(x)\n",
    "    return x\n",
    "\n",
    "class Discriminator(tf.keras.Model):\n",
    "  def __init__(self, num_hidden, num_classes, activation='relu'):\n",
    "    super().__init__(name='discriminator')  \n",
    "    self.hidden_layers = []\n",
    "    for dim in num_hidden:\n",
    "      self.hidden_layers.append(tf.keras.layers.Dense(dim, activation=activation))\n",
    "    self.logits = tf.keras.layers.Dense(num_classes, activation=None)\n",
    "\n",
    "  def call(self, x):\n",
    "    for layer in self.hidden_layers:\n",
    "      x = layer(x)\n",
    "    x = self.logits(x)\n",
    "\n",
    "    return x\n",
    "  \n",
    "@tf.custom_gradient\n",
    "def reverse_gradient(x, hp_lambda):\n",
    "    def custom_grad(dy):\n",
    "        return tf.math.multiply(tf.negative(dy), hp_lambda)\n",
    "    return x, custom_grad\n",
    "  \n",
    "class GradientReversal(tf.keras.layers.Layer):\n",
    "  def __init__(self):\n",
    "    super(GradientReversal, self).__init__()\n",
    "    \n",
    "  def build(self, input_shapes):\n",
    "    pass\n",
    "\n",
    "  def call(self, inputs, lambda_hp):\n",
    "    return reverse_gradient(inputs, lambda_hp)\n",
    "  \n",
    "\"\"\"Instantiates the ResNet50 architecture.\n",
    "\n",
    "Args:\n",
    "  num_classes: `int` number of classes for image classification.\n",
    "\n",
    "Returns:\n",
    "    A Keras model instance.\n",
    "\"\"\"\n",
    "class ResNet50(tf.keras.Model):\n",
    "  def __init__(self, num_classes, num_features, num_hidden, activation='relu'):\n",
    "    super().__init__(name='generator')\n",
    "    bn_axis = -1\n",
    "    self.activation = activation\n",
    "\n",
    "    self.conv1 = tf.keras.layers.Conv2D(32, (7, 7),\n",
    "                                        strides=(2, 2),\n",
    "                                        padding='valid',\n",
    "                                        use_bias=False,\n",
    "                                        kernel_initializer='he_normal',\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                        name='conv1')\n",
    "    self.bn1 = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                                  momentum=BATCH_NORM_DECAY,\n",
    "                                                  epsilon=BATCH_NORM_EPSILON,\n",
    "                                                  name='bn_conv1')\n",
    "    self.act1 = tf.keras.layers.Activation(self.activation, name=self.activation+'1')\n",
    "    self.max_pool1 = tf.keras.layers.MaxPooling2D((3, 3),\n",
    "                                                  strides=(2, 2),\n",
    "                                                  padding='same',\n",
    "                                                  name='max_pool1')\n",
    "\n",
    "    self.blocks = []\n",
    "    self.blocks.append(ConvBlock(3, [32, 32, 128], strides=(1, 1), stage=2, block='a', activation=self.activation))\n",
    "    self.blocks.append(IdentityBlock(3, [32, 32, 128], stage=2, block='b', activation=self.activation))\n",
    "\n",
    "    self.blocks.append(ConvBlock(3, [64, 64, 256], stage=3, block='a', activation=self.activation))\n",
    "    self.blocks.append(IdentityBlock(3, [64, 64, 256], stage=3, block='b', activation=self.activation))\n",
    "\n",
    "    self.blocks.append(ConvBlock(3, [64, 64, 256], stage=4, block='a', activation=self.activation))\n",
    "    self.blocks.append(IdentityBlock(3, [64, 64, 256], stage=4, block='b', activation=self.activation))\n",
    "\n",
    "    self.avg_pool = tf.keras.layers.GlobalAveragePooling2D(name='avg_pool')\n",
    "    self.fc1 = tf.keras.layers.Dense(num_features,\n",
    "                                     activation=self.activation,\n",
    "                                     kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                     kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                     bias_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                     name='fc1')\n",
    "    \n",
    "    self.disc = Discriminator(num_hidden, 4, activation=self.activation)\n",
    "    \n",
    "    self.logits = tf.keras.layers.Dense(num_classes,\n",
    "                                        activation=None,\n",
    "                                        kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                        bias_regularizer=tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                        name='logits')\n",
    "\n",
    "  def call(self, img_input, training=False, lambda_hp=1):    \n",
    "    x = self.conv1(img_input)\n",
    "    x = self.bn1(x, training=training)\n",
    "    x = self.act1(x)\n",
    "    x = self.max_pool1(x)\n",
    "\n",
    "    for block in self.blocks:\n",
    "      x = block(x)\n",
    "\n",
    "    x = self.avg_pool(x)\n",
    "    fc1 = self.fc1(x)\n",
    "    \n",
    "    grad_rev = GradientReversal()(fc1, lambda_hp)\n",
    "    disc_logits = self.disc(grad_rev)\n",
    "    \n",
    "    logits = self.logits(fc1)\n",
    "    return logits, fc1, disc_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cross_entropy_loss(labels, logits):\n",
    "  loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=logits)\n",
    "  return tf.reduce_mean(loss)\n",
    "\n",
    "class CenterLoss():\n",
    "    def __init__(self, batch_size, num_classes, len_features, alpha):\n",
    "      self.centers = tf.Variable(tf.zeros([num_classes, len_features]),\n",
    "                                 dtype=tf.float32,\n",
    "                                 trainable=False)\n",
    "      self.alpha = alpha\n",
    "      self.num_classes = num_classes\n",
    "      self.batch_size = batch_size    \n",
    "      self.margin = tf.constant(100, dtype=\"float32\")\n",
    "      self.norm = lambda x: tf.reduce_sum(tf.square(x), 1)\n",
    "      self.EdgeWeights = tf.ones((self.num_classes,self.num_classes)) - \\\n",
    "                                  tf.eye(self.num_classes)\n",
    "\n",
    "    def get_center_loss(self, features, labels):\n",
    "      labels = tf.reshape(tf.argmax(labels, axis=-1), [-1])\n",
    "      centers0 = tf.math.unsorted_segment_mean(features, \n",
    "                                               labels, \n",
    "                                               self.num_classes)\n",
    "      center_pairwise_dist = tf.transpose(self.norm(tf.expand_dims(centers0, 2) - \\\n",
    "                                                    tf.transpose(centers0)))\n",
    "      self.inter_loss = tf.math.reduce_sum(tf.multiply(tf.maximum(0.0, self.margin - center_pairwise_dist), \n",
    "                                                       self.EdgeWeights))\n",
    "\n",
    "      unique_label, unique_idx, unique_count = tf.unique_with_counts(labels)\n",
    "      appear_times = tf.gather(unique_count, unique_idx)\n",
    "      appear_times = tf.reshape(appear_times, [-1, 1])\n",
    "      centers_batch = tf.gather(self.centers, labels)\n",
    "      diff = centers_batch - features\n",
    "      diff /= tf.cast((1 + appear_times), tf.float32)\n",
    "      diff *= self.alpha\n",
    "      self.centers_update_op = tf.compat.v1.scatter_sub(self.centers, \n",
    "                                                        labels, \n",
    "                                                        diff)\n",
    "\n",
    "      self.intra_loss   = tf.nn.l2_loss(features - centers_batch)\n",
    "      self.center_loss  = self.intra_loss + self.inter_loss\n",
    "      self.center_loss /= (self.num_classes*self.batch_size+self.num_classes*self.num_classes)\n",
    "      return self.center_loss\n",
    "      \n",
    "def virtual_adversarial_images(images, logits, pert_norm_radius=3.5):  \n",
    "  with tf.GradientTape() as tape:\n",
    "    # Get normalised noise matrix\n",
    "    noise = tf.random.normal(shape=tf.shape(images))\n",
    "    noise = 1e-6 * tf.nn.l2_normalize(noise, axis=tf.range(1, len(noise.shape)))\n",
    "\n",
    "    # Add noise to image and get new logits\n",
    "    noise_logits, _, _ = generator(images + noise, \n",
    "                                   tf.constant(False, dtype=tf.bool))\n",
    "\n",
    "    # Get loss from noisey logits\n",
    "    noise_loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=logits, logits=noise_logits)\n",
    "    noise_loss = tf.reduce_mean(noise_loss)\n",
    "\n",
    "  # Based on perturbed image loss, get direction of greatest error\n",
    "  adversarial_noise = tape.gradient(noise_loss, \n",
    "                                    [noise],\n",
    "                                    unconnected_gradients='zero')[0]\n",
    "\n",
    "  adversarial_noise = tf.nn.l2_normalize(adversarial_noise, \n",
    "                                         axis=tf.range(1, 4))\n",
    "\n",
    "  # return images with adversarial perturbation\n",
    "  return images + pert_norm_radius * adversarial_noise\n",
    "\n",
    "def mixup_preprocess(x, y, batch_size, alpha=1):\n",
    "    # random sample the lambda value from beta distribution.\n",
    "    weight     = np.random.beta(alpha, alpha, batch_size)\n",
    "    x_weight   = weight.reshape(batch_size, 1, 1, 1)\n",
    "    y_weight   = weight.reshape(batch_size, 1)\n",
    "    \n",
    "    # Perform the mixup.\n",
    "    indices = tf.random.shuffle(tf.range(batch_size))\n",
    "    mixup_images = (x * x_weight) + (tf.gather(x, indices) * (1 - x_weight))\n",
    "    mixup_labels = (y * y_weight) + (tf.gather(y, indices) * (1 - y_weight))    \n",
    "    \n",
    "    return mixup_images, tf.nn.softmax(mixup_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_total_loss         = tf.keras.metrics.Mean(name='train_total_loss')\n",
    "train_domain_loss        = tf.keras.metrics.Mean(name='train_domain_loss')\n",
    "train_src_vat_loss       = tf.keras.metrics.Mean(name='train_src_vat_loss')\n",
    "train_trg_vat_loss       = tf.keras.metrics.Mean(name='train_trg_vat_loss')\n",
    "train_src_mixup_loss     = tf.keras.metrics.Mean(name='train_src_mixup_loss')\n",
    "train_trg_mixup_loss     = tf.keras.metrics.Mean(name='train_trg_mixup_loss')\n",
    "train_cond_entropy_loss  = tf.keras.metrics.Mean(name='train_cond_entropy_loss')\n",
    "train_cross_entropy_loss = tf.keras.metrics.Mean(name='train_cross_entropy_loss')\n",
    "train_discriminator_loss = tf.keras.metrics.Mean(name='train_discriminator_loss')\n",
    "src_test_accuracy        = tf.keras.metrics.CategoricalAccuracy(name='src_test_accuracy')\n",
    "trg_test_accuracy        = tf.keras.metrics.CategoricalAccuracy(name='trg_test_accuracy')\n",
    "office_test_accuracy     = tf.keras.metrics.CategoricalAccuracy(name='office_test_accuracy')\n",
    "server_test_accuracy     = tf.keras.metrics.CategoricalAccuracy(name='server_test_accuracy')\n",
    "conf_test_accuracy       = tf.keras.metrics.CategoricalAccuracy(name='conf_test_accuracy')\n",
    "src_train_accuracy       = tf.keras.metrics.CategoricalAccuracy(name='src_train_accuracy')\n",
    "trg_train_accuracy       = tf.keras.metrics.CategoricalAccuracy(name='trg_train_accuracy')\n",
    "\n",
    "@tf.function\n",
    "def train_gen_step(src_images, src_labels, trg_images_ser, trg_labels_ser, trg_images_conf, trg_labels_conf, trg_images, trg_labels, lambda_hp):  \n",
    "  with tf.GradientTape() as gen_tape:\n",
    "    #Logits\n",
    "    src_logits, src_enc, src_disc                = generator(src_images,      training=True, lambda_hp=lambda_hp)\n",
    "    trg_logits_ser, trg_enc_ser, trg_disc_ser    = generator(trg_images_ser,  training=True, lambda_hp=lambda_hp) \n",
    "    trg_logits_conf, trg_enc_conf, trg_disc_conf = generator(trg_images_conf, training=True, lambda_hp=lambda_hp) \n",
    "    trg_logits, trg_enc, trg_disc                = generator(trg_images,      training=True, lambda_hp=lambda_hp)\n",
    "        \n",
    "    #VAT\n",
    "    src_adver_images            = virtual_adversarial_images(src_images, tf.nn.softmax(src_logits))\n",
    "    src_adver_logits, _, _      = generator(tf.stop_gradient(src_adver_images), training=True)\n",
    "    trg_adver_images_ser        = virtual_adversarial_images(trg_images_ser, tf.nn.softmax(trg_logits_ser))\n",
    "    trg_adver_logits_ser, _, _  = generator(tf.stop_gradient(trg_adver_images_ser), training=True)\n",
    "    trg_adver_images_conf       = virtual_adversarial_images(trg_images_conf, tf.nn.softmax(trg_logits_conf))\n",
    "    trg_adver_logits_conf, _, _ = generator(tf.stop_gradient(trg_adver_images_conf), training=True)\n",
    "    trg_adver_images            = virtual_adversarial_images(trg_images, tf.nn.softmax(trg_logits))\n",
    "    trg_adver_logits, _, _      = generator(tf.stop_gradient(trg_adver_images), training=True)\n",
    "    \n",
    "    #MixUp\n",
    "    src_mixup_images, src_mixup_labels = mixup_preprocess(src_images, src_logits, batch_size)\n",
    "    src_mixup_logits, _, _             = generator(tf.stop_gradient(src_mixup_images),\n",
    "                                                   training=True)\n",
    "    trg_mixup_images_ser, trg_mixup_labels_ser = mixup_preprocess(trg_images_ser, trg_logits_ser, batch_size)\n",
    "    trg_mixup_logits_ser, _, _                 = generator(tf.stop_gradient(trg_mixup_images_ser),\n",
    "                                                           training=True)\n",
    "    trg_mixup_images_conf, trg_mixup_labels_conf = mixup_preprocess(trg_images_conf, trg_logits_conf, batch_size)\n",
    "    trg_mixup_logits_conf, _, _                  = generator(tf.stop_gradient(trg_mixup_images_conf),\n",
    "                                                             training=True)\n",
    "    trg_mixup_images, trg_mixup_labels      = mixup_preprocess(trg_images, trg_logits, batch_size)\n",
    "    trg_mixup_logits, _, _                  = generator(tf.stop_gradient(trg_mixup_images),\n",
    "                                                        training=True)\n",
    "    \n",
    "    cross_entropy_loss  = get_cross_entropy_loss(labels=src_labels, \n",
    "                                                 logits=src_logits)\n",
    "    cross_cond_loss     = get_cross_entropy_loss(labels=tf.nn.softmax(tf.concat([trg_logits_ser, \n",
    "                                                                                 trg_logits_conf,\n",
    "                                                                                 trg_logits], 0)), \n",
    "                                                 logits=tf.concat([trg_logits_ser, \n",
    "                                                                   trg_logits_conf,\n",
    "                                                                   trg_logits], 0))\n",
    "    \n",
    "    src_vat_loss        = get_cross_entropy_loss(labels=tf.nn.softmax(tf.stop_gradient(src_logits)),\n",
    "                                                 logits=src_adver_logits)\n",
    "    trg_vat_loss        = get_cross_entropy_loss(labels=tf.nn.softmax(tf.stop_gradient(tf.concat([trg_logits_ser, \n",
    "                                                                                                  trg_logits_conf,\n",
    "                                                                                                  trg_logits], 0))),\n",
    "                                                 logits=tf.concat([trg_adver_logits_ser, \n",
    "                                                                   trg_adver_logits_conf,\n",
    "                                                                   trg_adver_logits], 0))\n",
    "    \n",
    "    src_mixup_loss      = get_cross_entropy_loss(labels=tf.stop_gradient(src_mixup_labels), \n",
    "                                                 logits=src_mixup_logits)\n",
    "    trg_mixup_loss      = get_cross_entropy_loss(labels=tf.stop_gradient(tf.concat([trg_mixup_labels_ser, \n",
    "                                                                                    trg_mixup_labels_conf,\n",
    "                                                                                    trg_mixup_labels], 0)), \n",
    "                                                 logits=tf.concat([trg_mixup_logits_ser, \n",
    "                                                                   trg_mixup_logits_conf,\n",
    "                                                                   trg_mixup_logits], 0))\n",
    "          \n",
    "    batch_center_loss   = center_loss.get_center_loss(src_enc, src_labels)\n",
    "    domain_loss         = get_cross_entropy_loss(labels=tf.one_hot(tf.cast(tf.concat([tf.zeros(tf.shape(src_disc)[0]),\n",
    "                                                                                      tf.ones(tf.shape(trg_disc_ser)[0]),\n",
    "                                                                                      tf.ones(tf.shape(trg_disc_conf)[0])*2,\n",
    "                                                                                      tf.ones(tf.shape(trg_disc)[0])*3], 0), tf.uint8), 4),\n",
    "                                                 logits = tf.concat([src_disc, \n",
    "                                                                     trg_disc_ser, \n",
    "                                                                     trg_disc_conf, \n",
    "                                                                     trg_disc], 0)) \n",
    "\n",
    "    total_loss = cross_entropy_loss + \\\n",
    "                 8e-1 * domain_loss + \\\n",
    "                 8e-1 * cross_cond_loss + \\\n",
    "                 1    * src_mixup_loss +\\\n",
    "                 8e-1 * trg_mixup_loss +\\\n",
    "                 8e-1 * trg_vat_loss + \\\n",
    "                 1    * src_vat_loss + \\\n",
    "                 1    * batch_center_loss\n",
    "    \n",
    "  gen_gradients = gen_tape.gradient(total_loss, generator.trainable_variables)\n",
    "  with tf.control_dependencies([center_loss.centers_update_op]):\n",
    "    gen_optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n",
    "\n",
    "  src_train_accuracy(src_labels, src_logits)\n",
    "  trg_train_accuracy(tf.concat([trg_labels_ser, trg_labels_conf], 0), tf.concat([trg_logits_ser, trg_logits_conf], 0))\n",
    "  train_cross_entropy_loss(cross_entropy_loss)\n",
    "  train_cond_entropy_loss(cross_cond_loss)\n",
    "  train_src_mixup_loss(src_mixup_loss)\n",
    "  train_trg_mixup_loss(trg_mixup_loss)\n",
    "  train_src_vat_loss(src_vat_loss)\n",
    "  train_trg_vat_loss(trg_vat_loss)\n",
    "  train_domain_loss(domain_loss)\n",
    "  train_total_loss(total_loss)\n",
    "  \n",
    "@tf.function\n",
    "def test_step(images):\n",
    "  return generator(images, training=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0909 16:08:37.067141 140329877661440 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0909 16:08:40.245446 140329877661440 deprecation.py:323] From /home/kjakkala/.local/lib/python3.5/site-packages/tensorflow/python/keras/backend.py:4075: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, TotalL: 25.7594, CrossE: 2.0249, CondE: 2.0958, disc: 0.0000, domain: 1.3925, Src VAT: 2.0992, Trg VAT: 2.0958, Src MixUp: 2.1190, Trg MixUp: 2.1235, Src Train Acc: 20.49, Trg Train Acc: 17.90, Src Test Acc: 24.90, Trg Test Acc: 28.78, Server Test Acc: 21.65, Office Test Acc: 11.35, Conf Test Acc: 25.11\n",
      "Epoch: 002, TotalL: 22.6801, CrossE: 1.8432, CondE: 1.8307, disc: 0.0000, domain: 1.9873, Src VAT: 1.8332, Trg VAT: 1.8307, Src MixUp: 1.9162, Trg MixUp: 1.9457, Src Train Acc: 26.48, Trg Train Acc: 21.53, Src Test Acc: 28.02, Trg Test Acc: 27.64, Server Test Acc: 16.07, Office Test Acc: 26.47, Conf Test Acc: 25.11\n",
      "Epoch: 003, TotalL: 20.6430, CrossE: 1.7783, CondE: 1.6708, disc: 0.0000, domain: 1.4181, Src VAT: 1.6674, Trg VAT: 1.6708, Src MixUp: 1.7838, Trg MixUp: 1.8259, Src Train Acc: 27.91, Trg Train Acc: 23.22, Src Test Acc: 30.35, Trg Test Acc: 31.18, Server Test Acc: 17.63, Office Test Acc: 29.59, Conf Test Acc: 24.44\n",
      "Epoch: 004, TotalL: 19.9467, CrossE: 1.7048, CondE: 1.6048, disc: 0.0000, domain: 1.4084, Src VAT: 1.5960, Trg VAT: 1.6048, Src MixUp: 1.7348, Trg MixUp: 1.7835, Src Train Acc: 30.56, Trg Train Acc: 25.13, Src Test Acc: 33.85, Trg Test Acc: 33.49, Server Test Acc: 18.30, Office Test Acc: 31.92, Conf Test Acc: 25.78\n",
      "Epoch: 005, TotalL: 19.4035, CrossE: 1.6268, CondE: 1.5532, disc: 0.0000, domain: 1.4053, Src VAT: 1.5400, Trg VAT: 1.5532, Src MixUp: 1.6765, Trg MixUp: 1.7549, Src Train Acc: 35.55, Trg Train Acc: 28.04, Src Test Acc: 40.86, Trg Test Acc: 38.23, Server Test Acc: 28.12, Office Test Acc: 37.82, Conf Test Acc: 32.89\n",
      "Epoch: 006, TotalL: 18.8423, CrossE: 1.5353, CondE: 1.5005, disc: 0.0000, domain: 1.3741, Src VAT: 1.4855, Trg VAT: 1.5005, Src MixUp: 1.6353, Trg MixUp: 1.7209, Src Train Acc: 39.41, Trg Train Acc: 31.25, Src Test Acc: 41.25, Trg Test Acc: 40.36, Server Test Acc: 30.58, Office Test Acc: 42.49, Conf Test Acc: 34.89\n",
      "Epoch: 007, TotalL: 18.2479, CrossE: 1.4319, CondE: 1.4226, disc: 0.0000, domain: 1.3557, Src VAT: 1.4129, Trg VAT: 1.4226, Src MixUp: 1.5848, Trg MixUp: 1.6625, Src Train Acc: 44.79, Trg Train Acc: 33.57, Src Test Acc: 43.19, Trg Test Acc: 44.63, Server Test Acc: 32.37, Office Test Acc: 43.27, Conf Test Acc: 37.11\n",
      "Epoch: 008, TotalL: 17.5361, CrossE: 1.3116, CondE: 1.3271, disc: 0.0000, domain: 1.3474, Src VAT: 1.3210, Trg VAT: 1.3271, Src MixUp: 1.5186, Trg MixUp: 1.5915, Src Train Acc: 49.26, Trg Train Acc: 35.39, Src Test Acc: 47.86, Trg Test Acc: 50.04, Server Test Acc: 36.16, Office Test Acc: 43.16, Conf Test Acc: 39.78\n",
      "Epoch: 009, TotalL: 16.6900, CrossE: 1.1664, CondE: 1.2214, disc: 0.0000, domain: 1.3276, Src VAT: 1.2120, Trg VAT: 1.2214, Src MixUp: 1.4215, Trg MixUp: 1.5032, Src Train Acc: 56.34, Trg Train Acc: 38.56, Src Test Acc: 57.20, Trg Test Acc: 52.47, Server Test Acc: 35.71, Office Test Acc: 43.83, Conf Test Acc: 39.78\n",
      "Epoch: 010, TotalL: 15.9402, CrossE: 1.0443, CondE: 1.1270, disc: 0.0000, domain: 1.3143, Src VAT: 1.1088, Trg VAT: 1.1270, Src MixUp: 1.3186, Trg MixUp: 1.4335, Src Train Acc: 61.33, Trg Train Acc: 39.71, Src Test Acc: 59.53, Trg Test Acc: 53.64, Server Test Acc: 34.60, Office Test Acc: 41.82, Conf Test Acc: 38.22\n",
      "Epoch: 011, TotalL: 15.2323, CrossE: 0.9217, CondE: 1.0479, disc: 0.0000, domain: 1.3040, Src VAT: 1.0052, Trg VAT: 1.0479, Src MixUp: 1.2249, Trg MixUp: 1.3654, Src Train Acc: 66.84, Trg Train Acc: 41.15, Src Test Acc: 62.65, Trg Test Acc: 58.09, Server Test Acc: 37.50, Office Test Acc: 38.04, Conf Test Acc: 41.11\n",
      "Epoch: 012, TotalL: 14.6729, CrossE: 0.8376, CondE: 0.9734, disc: 0.0000, domain: 1.2933, Src VAT: 0.9166, Trg VAT: 0.9734, Src MixUp: 1.1642, Trg MixUp: 1.3124, Src Train Acc: 69.44, Trg Train Acc: 42.14, Src Test Acc: 68.09, Trg Test Acc: 58.96, Server Test Acc: 39.06, Office Test Acc: 39.38, Conf Test Acc: 44.22\n",
      "Epoch: 013, TotalL: 14.2061, CrossE: 0.7606, CondE: 0.9207, disc: 0.0000, domain: 1.2915, Src VAT: 0.8446, Trg VAT: 0.9207, Src MixUp: 1.1015, Trg MixUp: 1.2731, Src Train Acc: 72.61, Trg Train Acc: 44.53, Src Test Acc: 63.42, Trg Test Acc: 58.41, Server Test Acc: 37.95, Office Test Acc: 41.16, Conf Test Acc: 40.44\n",
      "Epoch: 014, TotalL: 13.8094, CrossE: 0.6955, CondE: 0.8680, disc: 0.0000, domain: 1.3055, Src VAT: 0.7834, Trg VAT: 0.8680, Src MixUp: 1.0353, Trg MixUp: 1.2364, Src Train Acc: 74.87, Trg Train Acc: 45.53, Src Test Acc: 68.09, Trg Test Acc: 62.94, Server Test Acc: 38.39, Office Test Acc: 46.38, Conf Test Acc: 44.00\n",
      "Epoch: 015, TotalL: 13.3155, CrossE: 0.5969, CondE: 0.8157, disc: 0.0000, domain: 1.2981, Src VAT: 0.7124, Trg VAT: 0.8157, Src MixUp: 0.9869, Trg MixUp: 1.1955, Src Train Acc: 78.52, Trg Train Acc: 48.07, Src Test Acc: 67.32, Trg Test Acc: 61.95, Server Test Acc: 40.62, Office Test Acc: 50.17, Conf Test Acc: 43.11\n",
      "Epoch: 016, TotalL: 12.9566, CrossE: 0.5292, CondE: 0.7734, disc: 0.0000, domain: 1.3036, Src VAT: 0.6522, Trg VAT: 0.7734, Src MixUp: 0.9410, Trg MixUp: 1.1714, Src Train Acc: 81.34, Trg Train Acc: 50.85, Src Test Acc: 73.93, Trg Test Acc: 65.28, Server Test Acc: 43.97, Office Test Acc: 46.38, Conf Test Acc: 46.67\n",
      "Epoch: 017, TotalL: 12.5729, CrossE: 0.4624, CondE: 0.7251, disc: 0.0000, domain: 1.3032, Src VAT: 0.5908, Trg VAT: 0.7251, Src MixUp: 0.8822, Trg MixUp: 1.1236, Src Train Acc: 83.42, Trg Train Acc: 51.80, Src Test Acc: 76.26, Trg Test Acc: 65.78, Server Test Acc: 44.42, Office Test Acc: 46.05, Conf Test Acc: 49.56\n",
      "Epoch: 018, TotalL: 12.2290, CrossE: 0.4066, CondE: 0.6832, disc: 0.0000, domain: 1.3050, Src VAT: 0.5390, Trg VAT: 0.6832, Src MixUp: 0.8341, Trg MixUp: 1.0906, Src Train Acc: 86.20, Trg Train Acc: 54.54, Src Test Acc: 75.49, Trg Test Acc: 64.84, Server Test Acc: 47.10, Office Test Acc: 46.38, Conf Test Acc: 48.67\n",
      "Epoch: 019, TotalL: 11.8392, CrossE: 0.3369, CondE: 0.6404, disc: 0.0000, domain: 1.3043, Src VAT: 0.4757, Trg VAT: 0.6404, Src MixUp: 0.7786, Trg MixUp: 1.0646, Src Train Acc: 88.93, Trg Train Acc: 56.71, Src Test Acc: 81.32, Trg Test Acc: 70.17, Server Test Acc: 51.34, Office Test Acc: 48.61, Conf Test Acc: 52.89\n",
      "Epoch: 020, TotalL: 11.5452, CrossE: 0.2781, CondE: 0.6034, disc: 0.0000, domain: 1.3070, Src VAT: 0.4186, Trg VAT: 0.6034, Src MixUp: 0.7381, Trg MixUp: 1.0408, Src Train Acc: 91.62, Trg Train Acc: 59.79, Src Test Acc: 76.26, Trg Test Acc: 66.95, Server Test Acc: 50.89, Office Test Acc: 47.83, Conf Test Acc: 52.67\n",
      "Epoch: 021, TotalL: 11.3026, CrossE: 0.2454, CondE: 0.5646, disc: 0.0000, domain: 1.3076, Src VAT: 0.3748, Trg VAT: 0.5646, Src MixUp: 0.7192, Trg MixUp: 1.0064, Src Train Acc: 93.23, Trg Train Acc: 61.83, Src Test Acc: 82.10, Trg Test Acc: 70.11, Server Test Acc: 48.21, Office Test Acc: 42.94, Conf Test Acc: 56.44\n",
      "Epoch: 022, TotalL: 11.0561, CrossE: 0.2097, CondE: 0.5387, disc: 0.0000, domain: 1.3079, Src VAT: 0.3360, Trg VAT: 0.5387, Src MixUp: 0.6645, Trg MixUp: 0.9875, Src Train Acc: 93.97, Trg Train Acc: 63.89, Src Test Acc: 81.71, Trg Test Acc: 71.66, Server Test Acc: 52.23, Office Test Acc: 48.50, Conf Test Acc: 55.78\n",
      "Epoch: 023, TotalL: 10.7398, CrossE: 0.1603, CondE: 0.4990, disc: 0.0000, domain: 1.3064, Src VAT: 0.2900, Trg VAT: 0.4990, Src MixUp: 0.6247, Trg MixUp: 0.9625, Src Train Acc: 95.92, Trg Train Acc: 66.60, Src Test Acc: 75.49, Trg Test Acc: 64.43, Server Test Acc: 45.31, Office Test Acc: 42.16, Conf Test Acc: 49.56\n",
      "Epoch: 024, TotalL: 10.4528, CrossE: 0.1194, CondE: 0.4582, disc: 0.0000, domain: 1.3092, Src VAT: 0.2460, Trg VAT: 0.4582, Src MixUp: 0.5954, Trg MixUp: 0.9289, Src Train Acc: 97.70, Trg Train Acc: 69.34, Src Test Acc: 82.88, Trg Test Acc: 73.79, Server Test Acc: 54.91, Office Test Acc: 49.05, Conf Test Acc: 58.89\n",
      "Epoch: 025, TotalL: 10.3752, CrossE: 0.1148, CondE: 0.4411, disc: 0.0000, domain: 1.3129, Src VAT: 0.2308, Trg VAT: 0.4411, Src MixUp: 0.5847, Trg MixUp: 0.9113, Src Train Acc: 97.22, Trg Train Acc: 69.51, Src Test Acc: 74.32, Trg Test Acc: 65.81, Server Test Acc: 50.00, Office Test Acc: 49.72, Conf Test Acc: 50.89\n",
      "Epoch: 026, TotalL: 10.1413, CrossE: 0.0909, CondE: 0.4117, disc: 0.0000, domain: 1.3171, Src VAT: 0.1937, Trg VAT: 0.4117, Src MixUp: 0.5432, Trg MixUp: 0.8873, Src Train Acc: 98.05, Trg Train Acc: 72.37, Src Test Acc: 84.82, Trg Test Acc: 77.95, Server Test Acc: 61.61, Office Test Acc: 53.62, Conf Test Acc: 64.67\n",
      "Epoch: 027, TotalL: 9.9251, CrossE: 0.0725, CondE: 0.3789, disc: 0.0000, domain: 1.3140, Src VAT: 0.1649, Trg VAT: 0.3789, Src MixUp: 0.4977, Trg MixUp: 0.8538, Src Train Acc: 98.48, Trg Train Acc: 73.70, Src Test Acc: 87.55, Trg Test Acc: 78.41, Server Test Acc: 61.38, Office Test Acc: 53.50, Conf Test Acc: 63.11\n",
      "Epoch: 028, TotalL: 9.8135, CrossE: 0.0604, CondE: 0.3567, disc: 0.0000, domain: 1.3241, Src VAT: 0.1475, Trg VAT: 0.3567, Src MixUp: 0.4769, Trg MixUp: 0.8461, Src Train Acc: 99.05, Trg Train Acc: 76.02, Src Test Acc: 83.27, Trg Test Acc: 75.14, Server Test Acc: 59.38, Office Test Acc: 52.61, Conf Test Acc: 62.00\n",
      "Epoch: 029, TotalL: 9.7101, CrossE: 0.0522, CondE: 0.3361, disc: 0.0000, domain: 1.3255, Src VAT: 0.1288, Trg VAT: 0.3361, Src MixUp: 0.4609, Trg MixUp: 0.8351, Src Train Acc: 98.78, Trg Train Acc: 76.71, Src Test Acc: 87.16, Trg Test Acc: 78.41, Server Test Acc: 62.28, Office Test Acc: 55.73, Conf Test Acc: 64.22\n",
      "Epoch: 030, TotalL: 9.6248, CrossE: 0.0456, CondE: 0.3162, disc: 0.0000, domain: 1.3263, Src VAT: 0.1205, Trg VAT: 0.3162, Src MixUp: 0.4595, Trg MixUp: 0.8070, Src Train Acc: 99.31, Trg Train Acc: 77.43, Src Test Acc: 87.94, Trg Test Acc: 82.42, Server Test Acc: 62.28, Office Test Acc: 62.18, Conf Test Acc: 66.00\n",
      "Epoch: 031, TotalL: 9.5000, CrossE: 0.0370, CondE: 0.2941, disc: 0.0000, domain: 1.3288, Src VAT: 0.1087, Trg VAT: 0.2941, Src MixUp: 0.4415, Trg MixUp: 0.7866, Src Train Acc: 99.61, Trg Train Acc: 79.90, Src Test Acc: 87.16, Trg Test Acc: 79.32, Server Test Acc: 64.51, Office Test Acc: 56.06, Conf Test Acc: 66.89\n",
      "Epoch: 032, TotalL: 9.4411, CrossE: 0.0410, CondE: 0.2775, disc: 0.0000, domain: 1.3324, Src VAT: 0.0943, Trg VAT: 0.2775, Src MixUp: 0.4284, Trg MixUp: 0.7681, Src Train Acc: 99.09, Trg Train Acc: 79.82, Src Test Acc: 91.83, Trg Test Acc: 83.45, Server Test Acc: 67.86, Office Test Acc: 61.51, Conf Test Acc: 69.78\n",
      "Epoch: 033, TotalL: 9.3020, CrossE: 0.0257, CondE: 0.2588, disc: 0.0000, domain: 1.3307, Src VAT: 0.0809, Trg VAT: 0.2588, Src MixUp: 0.4084, Trg MixUp: 0.7534, Src Train Acc: 99.74, Trg Train Acc: 81.29, Src Test Acc: 89.11, Trg Test Acc: 83.12, Server Test Acc: 64.73, Office Test Acc: 63.40, Conf Test Acc: 65.33\n",
      "Epoch: 034, TotalL: 9.2354, CrossE: 0.0235, CondE: 0.2431, disc: 0.0000, domain: 1.3344, Src VAT: 0.0748, Trg VAT: 0.2431, Src MixUp: 0.3964, Trg MixUp: 0.7395, Src Train Acc: 99.57, Trg Train Acc: 83.27, Src Test Acc: 85.99, Trg Test Acc: 78.85, Server Test Acc: 62.72, Office Test Acc: 54.17, Conf Test Acc: 63.11\n",
      "Epoch: 035, TotalL: 9.1830, CrossE: 0.0242, CondE: 0.2269, disc: 0.0000, domain: 1.3409, Src VAT: 0.0700, Trg VAT: 0.2269, Src MixUp: 0.3809, Trg MixUp: 0.7254, Src Train Acc: 99.61, Trg Train Acc: 83.27, Src Test Acc: 89.49, Trg Test Acc: 82.42, Server Test Acc: 63.84, Office Test Acc: 57.73, Conf Test Acc: 66.44\n",
      "Epoch: 036, TotalL: 9.1231, CrossE: 0.0245, CondE: 0.2149, disc: 0.0000, domain: 1.3428, Src VAT: 0.0666, Trg VAT: 0.2149, Src MixUp: 0.3700, Trg MixUp: 0.7032, Src Train Acc: 99.35, Trg Train Acc: 83.31, Src Test Acc: 84.82, Trg Test Acc: 74.20, Server Test Acc: 60.71, Office Test Acc: 49.39, Conf Test Acc: 64.00\n",
      "Epoch: 037, TotalL: 9.0893, CrossE: 0.0176, CondE: 0.2060, disc: 0.0000, domain: 1.3456, Src VAT: 0.0584, Trg VAT: 0.2060, Src MixUp: 0.3728, Trg MixUp: 0.7071, Src Train Acc: 99.61, Trg Train Acc: 84.03, Src Test Acc: 86.77, Trg Test Acc: 78.01, Server Test Acc: 59.60, Office Test Acc: 62.63, Conf Test Acc: 64.67\n",
      "Epoch: 038, TotalL: 8.9710, CrossE: 0.0129, CondE: 0.1840, disc: 0.0000, domain: 1.3432, Src VAT: 0.0487, Trg VAT: 0.1840, Src MixUp: 0.3623, Trg MixUp: 0.6717, Src Train Acc: 99.83, Trg Train Acc: 85.39, Src Test Acc: 89.49, Trg Test Acc: 82.95, Server Test Acc: 71.88, Office Test Acc: 59.96, Conf Test Acc: 69.11\n",
      "Epoch: 039, TotalL: 8.9056, CrossE: 0.0107, CondE: 0.1748, disc: 0.0000, domain: 1.3498, Src VAT: 0.0454, Trg VAT: 0.1748, Src MixUp: 0.3389, Trg MixUp: 0.6585, Src Train Acc: 99.91, Trg Train Acc: 85.18, Src Test Acc: 92.22, Trg Test Acc: 88.15, Server Test Acc: 71.21, Office Test Acc: 68.30, Conf Test Acc: 72.89\n",
      "Epoch: 040, TotalL: 9.1518, CrossE: 0.0600, CondE: 0.1856, disc: 0.0000, domain: 1.3530, Src VAT: 0.0617, Trg VAT: 0.1856, Src MixUp: 0.3772, Trg MixUp: 0.6810, Src Train Acc: 98.48, Trg Train Acc: 84.68, Src Test Acc: 93.77, Trg Test Acc: 87.36, Server Test Acc: 73.88, Office Test Acc: 64.96, Conf Test Acc: 72.67\n",
      "Epoch: 041, TotalL: 8.8547, CrossE: 0.0118, CondE: 0.1580, disc: 0.0000, domain: 1.3463, Src VAT: 0.0394, Trg VAT: 0.1580, Src MixUp: 0.3378, Trg MixUp: 0.6500, Src Train Acc: 99.83, Trg Train Acc: 86.44, Src Test Acc: 93.77, Trg Test Acc: 86.28, Server Test Acc: 72.54, Office Test Acc: 60.85, Conf Test Acc: 74.67\n",
      "Epoch: 042, TotalL: 8.8021, CrossE: 0.0076, CondE: 0.1490, disc: 0.0000, domain: 1.3525, Src VAT: 0.0355, Trg VAT: 0.1490, Src MixUp: 0.3292, Trg MixUp: 0.6331, Src Train Acc: 100.00, Trg Train Acc: 86.91, Src Test Acc: 93.77, Trg Test Acc: 87.80, Server Test Acc: 71.65, Office Test Acc: 66.52, Conf Test Acc: 71.56\n",
      "Epoch: 043, TotalL: 8.7408, CrossE: 0.0071, CondE: 0.1436, disc: 0.0000, domain: 1.3523, Src VAT: 0.0327, Trg VAT: 0.1436, Src MixUp: 0.3201, Trg MixUp: 0.6095, Src Train Acc: 100.00, Trg Train Acc: 87.04, Src Test Acc: 89.11, Trg Test Acc: 81.19, Server Test Acc: 68.08, Office Test Acc: 47.72, Conf Test Acc: 67.33\n",
      "Epoch: 044, TotalL: 8.7393, CrossE: 0.0058, CondE: 0.1332, disc: 0.0000, domain: 1.3538, Src VAT: 0.0293, Trg VAT: 0.1332, Src MixUp: 0.3204, Trg MixUp: 0.6219, Src Train Acc: 100.00, Trg Train Acc: 86.87, Src Test Acc: 91.05, Trg Test Acc: 83.12, Server Test Acc: 70.76, Office Test Acc: 58.73, Conf Test Acc: 72.44\n",
      "Epoch: 045, TotalL: 8.7087, CrossE: 0.0074, CondE: 0.1299, disc: 0.0000, domain: 1.3510, Src VAT: 0.0285, Trg VAT: 0.1299, Src MixUp: 0.3094, Trg MixUp: 0.6132, Src Train Acc: 99.87, Trg Train Acc: 87.39, Src Test Acc: 85.60, Trg Test Acc: 74.73, Server Test Acc: 63.39, Office Test Acc: 52.61, Conf Test Acc: 69.11\n",
      "Epoch: 046, TotalL: 8.8041, CrossE: 0.0370, CondE: 0.1289, disc: 0.0000, domain: 1.3598, Src VAT: 0.0354, Trg VAT: 0.1289, Src MixUp: 0.3117, Trg MixUp: 0.5970, Src Train Acc: 98.96, Trg Train Acc: 87.04, Src Test Acc: 93.00, Trg Test Acc: 86.78, Server Test Acc: 77.23, Office Test Acc: 63.63, Conf Test Acc: 73.56\n",
      "Epoch: 047, TotalL: 8.6413, CrossE: 0.0050, CondE: 0.1127, disc: 0.0000, domain: 1.3612, Src VAT: 0.0255, Trg VAT: 0.1127, Src MixUp: 0.2981, Trg MixUp: 0.5918, Src Train Acc: 100.00, Trg Train Acc: 88.26, Src Test Acc: 91.83, Trg Test Acc: 87.48, Server Test Acc: 69.42, Office Test Acc: 66.07, Conf Test Acc: 69.56\n",
      "Epoch: 048, TotalL: 8.6936, CrossE: 0.0125, CondE: 0.1187, disc: 0.0000, domain: 1.3602, Src VAT: 0.0306, Trg VAT: 0.1187, Src MixUp: 0.3070, Trg MixUp: 0.5889, Src Train Acc: 99.74, Trg Train Acc: 87.63, Src Test Acc: 94.94, Trg Test Acc: 87.83, Server Test Acc: 73.44, Office Test Acc: 65.52, Conf Test Acc: 71.11\n",
      "Epoch: 049, TotalL: 8.5912, CrossE: 0.0044, CondE: 0.1068, disc: 0.0000, domain: 1.3583, Src VAT: 0.0220, Trg VAT: 0.1068, Src MixUp: 0.2816, Trg MixUp: 0.5811, Src Train Acc: 100.00, Trg Train Acc: 88.35, Src Test Acc: 94.16, Trg Test Acc: 90.79, Server Test Acc: 74.33, Office Test Acc: 73.75, Conf Test Acc: 74.22\n",
      "Epoch: 050, TotalL: 8.5865, CrossE: 0.0049, CondE: 0.0996, disc: 0.0000, domain: 1.3649, Src VAT: 0.0212, Trg VAT: 0.0996, Src MixUp: 0.2963, Trg MixUp: 0.5742, Src Train Acc: 99.96, Trg Train Acc: 88.35, Src Test Acc: 93.77, Trg Test Acc: 89.32, Server Test Acc: 74.33, Office Test Acc: 68.08, Conf Test Acc: 73.33\n",
      "Epoch: 051, TotalL: 8.5625, CrossE: 0.0038, CondE: 0.0985, disc: 0.0000, domain: 1.3641, Src VAT: 0.0195, Trg VAT: 0.0985, Src MixUp: 0.2740, Trg MixUp: 0.5686, Src Train Acc: 100.00, Trg Train Acc: 88.56, Src Test Acc: 94.16, Trg Test Acc: 91.31, Server Test Acc: 72.77, Office Test Acc: 70.63, Conf Test Acc: 74.22\n",
      "Epoch: 052, TotalL: 8.5090, CrossE: 0.0031, CondE: 0.0934, disc: 0.0000, domain: 1.3671, Src VAT: 0.0182, Trg VAT: 0.0934, Src MixUp: 0.2662, Trg MixUp: 0.5478, Src Train Acc: 100.00, Trg Train Acc: 88.69, Src Test Acc: 93.77, Trg Test Acc: 89.73, Server Test Acc: 72.54, Office Test Acc: 65.52, Conf Test Acc: 70.67\n",
      "Epoch: 053, TotalL: 8.5084, CrossE: 0.0031, CondE: 0.0845, disc: 0.0000, domain: 1.3664, Src VAT: 0.0175, Trg VAT: 0.0845, Src MixUp: 0.2866, Trg MixUp: 0.5447, Src Train Acc: 100.00, Trg Train Acc: 89.02, Src Test Acc: 94.55, Trg Test Acc: 91.40, Server Test Acc: 77.23, Office Test Acc: 71.41, Conf Test Acc: 78.67\n",
      "Epoch: 054, TotalL: 8.6252, CrossE: 0.0141, CondE: 0.0949, disc: 0.0000, domain: 1.3702, Src VAT: 0.0276, Trg VAT: 0.0949, Src MixUp: 0.2940, Trg MixUp: 0.5604, Src Train Acc: 99.57, Trg Train Acc: 88.50, Src Test Acc: 93.77, Trg Test Acc: 87.04, Server Test Acc: 72.10, Office Test Acc: 59.40, Conf Test Acc: 74.22\n",
      "Epoch: 055, TotalL: 8.4844, CrossE: 0.0029, CondE: 0.0798, disc: 0.0000, domain: 1.3692, Src VAT: 0.0158, Trg VAT: 0.0798, Src MixUp: 0.2847, Trg MixUp: 0.5340, Src Train Acc: 100.00, Trg Train Acc: 89.15, Src Test Acc: 93.39, Trg Test Acc: 87.36, Server Test Acc: 73.44, Office Test Acc: 63.85, Conf Test Acc: 71.33\n",
      "Epoch: 056, TotalL: 8.4820, CrossE: 0.0032, CondE: 0.0774, disc: 0.0000, domain: 1.3717, Src VAT: 0.0165, Trg VAT: 0.0774, Src MixUp: 0.2672, Trg MixUp: 0.5357, Src Train Acc: 99.96, Trg Train Acc: 89.13, Src Test Acc: 91.83, Trg Test Acc: 89.03, Server Test Acc: 77.46, Office Test Acc: 76.64, Conf Test Acc: 80.89\n",
      "Epoch: 057, TotalL: 8.9884, CrossE: 0.1652, CondE: 0.0988, disc: 0.0000, domain: 1.3700, Src VAT: 0.0366, Trg VAT: 0.0988, Src MixUp: 0.3115, Trg MixUp: 0.5559, Src Train Acc: 97.40, Trg Train Acc: 87.04, Src Test Acc: 94.94, Trg Test Acc: 91.66, Server Test Acc: 74.78, Office Test Acc: 69.08, Conf Test Acc: 74.44\n",
      "Epoch: 058, TotalL: 8.3997, CrossE: 0.0021, CondE: 0.0666, disc: 0.0000, domain: 1.3651, Src VAT: 0.0127, Trg VAT: 0.0666, Src MixUp: 0.2640, Trg MixUp: 0.5228, Src Train Acc: 100.00, Trg Train Acc: 89.17, Src Test Acc: 95.33, Trg Test Acc: 91.90, Server Test Acc: 77.01, Office Test Acc: 69.86, Conf Test Acc: 75.78\n",
      "Epoch: 059, TotalL: 8.3663, CrossE: 0.0018, CondE: 0.0618, disc: 0.0000, domain: 1.3647, Src VAT: 0.0113, Trg VAT: 0.0618, Src MixUp: 0.2664, Trg MixUp: 0.5088, Src Train Acc: 100.00, Trg Train Acc: 89.34, Src Test Acc: 94.94, Trg Test Acc: 89.79, Server Test Acc: 72.99, Office Test Acc: 67.52, Conf Test Acc: 72.89\n",
      "Epoch: 060, TotalL: 8.3995, CrossE: 0.0022, CondE: 0.0635, disc: 0.0000, domain: 1.3706, Src VAT: 0.0126, Trg VAT: 0.0635, Src MixUp: 0.2620, Trg MixUp: 0.5192, Src Train Acc: 100.00, Trg Train Acc: 89.50, Src Test Acc: 94.55, Trg Test Acc: 90.20, Server Test Acc: 76.34, Office Test Acc: 69.86, Conf Test Acc: 75.78\n",
      "Epoch: 061, TotalL: 8.3520, CrossE: 0.0016, CondE: 0.0558, disc: 0.0000, domain: 1.3712, Src VAT: 0.0106, Trg VAT: 0.0558, Src MixUp: 0.2493, Trg MixUp: 0.5058, Src Train Acc: 100.00, Trg Train Acc: 89.47, Src Test Acc: 94.16, Trg Test Acc: 91.23, Server Test Acc: 75.67, Office Test Acc: 72.53, Conf Test Acc: 77.33\n",
      "Epoch: 062, TotalL: 8.3466, CrossE: 0.0018, CondE: 0.0560, disc: 0.0000, domain: 1.3679, Src VAT: 0.0109, Trg VAT: 0.0560, Src MixUp: 0.2557, Trg MixUp: 0.4922, Src Train Acc: 100.00, Trg Train Acc: 89.37, Src Test Acc: 95.33, Trg Test Acc: 91.49, Server Test Acc: 76.34, Office Test Acc: 70.86, Conf Test Acc: 77.33\n",
      "Epoch: 063, TotalL: 8.3465, CrossE: 0.0018, CondE: 0.0525, disc: 0.0000, domain: 1.3709, Src VAT: 0.0111, Trg VAT: 0.0525, Src MixUp: 0.2454, Trg MixUp: 0.5008, Src Train Acc: 100.00, Trg Train Acc: 89.41, Src Test Acc: 95.33, Trg Test Acc: 90.44, Server Test Acc: 73.44, Office Test Acc: 68.30, Conf Test Acc: 75.33\n",
      "Epoch: 064, TotalL: 8.3418, CrossE: 0.0017, CondE: 0.0538, disc: 0.0000, domain: 1.3730, Src VAT: 0.0106, Trg VAT: 0.0538, Src MixUp: 0.2545, Trg MixUp: 0.4835, Src Train Acc: 100.00, Trg Train Acc: 89.45, Src Test Acc: 94.16, Trg Test Acc: 90.55, Server Test Acc: 74.78, Office Test Acc: 68.30, Conf Test Acc: 74.22\n",
      "Epoch: 065, TotalL: 8.3695, CrossE: 0.0021, CondE: 0.0537, disc: 0.0000, domain: 1.3768, Src VAT: 0.0126, Trg VAT: 0.0537, Src MixUp: 0.2571, Trg MixUp: 0.4843, Src Train Acc: 100.00, Trg Train Acc: 89.50, Src Test Acc: 95.33, Trg Test Acc: 91.28, Server Test Acc: 72.99, Office Test Acc: 72.64, Conf Test Acc: 71.11\n",
      "Epoch: 066, TotalL: 8.3426, CrossE: 0.0019, CondE: 0.0535, disc: 0.0000, domain: 1.3740, Src VAT: 0.0109, Trg VAT: 0.0535, Src MixUp: 0.2464, Trg MixUp: 0.4931, Src Train Acc: 100.00, Trg Train Acc: 89.67, Src Test Acc: 93.00, Trg Test Acc: 88.56, Server Test Acc: 75.00, Office Test Acc: 59.96, Conf Test Acc: 72.89\n",
      "Epoch: 067, TotalL: 8.3078, CrossE: 0.0016, CondE: 0.0457, disc: 0.0000, domain: 1.3709, Src VAT: 0.0097, Trg VAT: 0.0457, Src MixUp: 0.2402, Trg MixUp: 0.4885, Src Train Acc: 100.00, Trg Train Acc: 89.58, Src Test Acc: 93.00, Trg Test Acc: 90.55, Server Test Acc: 76.79, Office Test Acc: 72.08, Conf Test Acc: 76.00\n",
      "Epoch: 068, TotalL: 8.3473, CrossE: 0.0020, CondE: 0.0493, disc: 0.0000, domain: 1.3765, Src VAT: 0.0112, Trg VAT: 0.0493, Src MixUp: 0.2580, Trg MixUp: 0.4767, Src Train Acc: 100.00, Trg Train Acc: 89.37, Src Test Acc: 94.55, Trg Test Acc: 91.17, Server Test Acc: 80.36, Office Test Acc: 66.85, Conf Test Acc: 78.22\n",
      "Epoch: 069, TotalL: 8.3203, CrossE: 0.0016, CondE: 0.0432, disc: 0.0000, domain: 1.3762, Src VAT: 0.0096, Trg VAT: 0.0432, Src MixUp: 0.2472, Trg MixUp: 0.4774, Src Train Acc: 100.00, Trg Train Acc: 89.58, Src Test Acc: 91.44, Trg Test Acc: 88.42, Server Test Acc: 70.98, Office Test Acc: 58.62, Conf Test Acc: 72.89\n",
      "Epoch: 070, TotalL: 8.2504, CrossE: 0.0011, CondE: 0.0394, disc: 0.0000, domain: 1.3731, Src VAT: 0.0079, Trg VAT: 0.0394, Src MixUp: 0.2363, Trg MixUp: 0.4572, Src Train Acc: 100.00, Trg Train Acc: 89.56, Src Test Acc: 93.39, Trg Test Acc: 87.48, Server Test Acc: 72.54, Office Test Acc: 59.51, Conf Test Acc: 70.22\n",
      "Epoch: 071, TotalL: 8.7598, CrossE: 0.0970, CondE: 0.0708, disc: 0.0000, domain: 1.3862, Src VAT: 0.0331, Trg VAT: 0.0708, Src MixUp: 0.2786, Trg MixUp: 0.5100, Src Train Acc: 98.05, Trg Train Acc: 87.15, Src Test Acc: 95.33, Trg Test Acc: 92.89, Server Test Acc: 79.24, Office Test Acc: 69.52, Conf Test Acc: 77.33\n",
      "Epoch: 072, TotalL: 8.2309, CrossE: 0.0010, CondE: 0.0345, disc: 0.0000, domain: 1.3736, Src VAT: 0.0070, Trg VAT: 0.0345, Src MixUp: 0.2168, Trg MixUp: 0.4569, Src Train Acc: 100.00, Trg Train Acc: 89.69, Src Test Acc: 94.55, Trg Test Acc: 91.61, Server Test Acc: 73.66, Office Test Acc: 78.98, Conf Test Acc: 71.78\n",
      "Epoch: 073, TotalL: 8.2227, CrossE: 0.0009, CondE: 0.0326, disc: 0.0000, domain: 1.3743, Src VAT: 0.0068, Trg VAT: 0.0326, Src MixUp: 0.2331, Trg MixUp: 0.4478, Src Train Acc: 100.00, Trg Train Acc: 89.56, Src Test Acc: 96.89, Trg Test Acc: 92.98, Server Test Acc: 77.46, Office Test Acc: 76.42, Conf Test Acc: 76.00\n",
      "Epoch: 074, TotalL: 8.2260, CrossE: 0.0010, CondE: 0.0330, disc: 0.0000, domain: 1.3738, Src VAT: 0.0070, Trg VAT: 0.0330, Src MixUp: 0.2408, Trg MixUp: 0.4512, Src Train Acc: 100.00, Trg Train Acc: 89.63, Src Test Acc: 96.11, Trg Test Acc: 93.07, Server Test Acc: 77.01, Office Test Acc: 79.20, Conf Test Acc: 75.56\n",
      "Epoch: 075, TotalL: 8.1970, CrossE: 0.0009, CondE: 0.0311, disc: 0.0000, domain: 1.3752, Src VAT: 0.0069, Trg VAT: 0.0311, Src MixUp: 0.2177, Trg MixUp: 0.4494, Src Train Acc: 100.00, Trg Train Acc: 89.54, Src Test Acc: 97.28, Trg Test Acc: 93.62, Server Test Acc: 78.12, Office Test Acc: 75.42, Conf Test Acc: 79.11\n",
      "Epoch: 076, TotalL: 8.2310, CrossE: 0.0013, CondE: 0.0334, disc: 0.0000, domain: 1.3769, Src VAT: 0.0081, Trg VAT: 0.0334, Src MixUp: 0.2294, Trg MixUp: 0.4479, Src Train Acc: 100.00, Trg Train Acc: 89.54, Src Test Acc: 94.16, Trg Test Acc: 88.13, Server Test Acc: 71.65, Office Test Acc: 62.40, Conf Test Acc: 73.11\n",
      "Epoch: 077, TotalL: 8.2418, CrossE: 0.0025, CondE: 0.0354, disc: 0.0000, domain: 1.3774, Src VAT: 0.0085, Trg VAT: 0.0354, Src MixUp: 0.2288, Trg MixUp: 0.4416, Src Train Acc: 99.96, Trg Train Acc: 89.69, Src Test Acc: 96.50, Trg Test Acc: 92.42, Server Test Acc: 77.90, Office Test Acc: 75.42, Conf Test Acc: 78.89\n",
      "Epoch: 078, TotalL: 8.2416, CrossE: 0.0012, CondE: 0.0318, disc: 0.0000, domain: 1.3796, Src VAT: 0.0079, Trg VAT: 0.0318, Src MixUp: 0.2407, Trg MixUp: 0.4389, Src Train Acc: 100.00, Trg Train Acc: 89.74, Src Test Acc: 95.72, Trg Test Acc: 93.04, Server Test Acc: 74.55, Office Test Acc: 78.09, Conf Test Acc: 76.00\n",
      "Epoch: 079, TotalL: 8.2340, CrossE: 0.0015, CondE: 0.0327, disc: 0.0000, domain: 1.3803, Src VAT: 0.0078, Trg VAT: 0.0327, Src MixUp: 0.2285, Trg MixUp: 0.4456, Src Train Acc: 99.96, Trg Train Acc: 89.65, Src Test Acc: 95.33, Trg Test Acc: 90.64, Server Test Acc: 75.22, Office Test Acc: 65.52, Conf Test Acc: 78.00\n",
      "Epoch: 080, TotalL: 8.2170, CrossE: 0.0010, CondE: 0.0328, disc: 0.0000, domain: 1.3759, Src VAT: 0.0067, Trg VAT: 0.0328, Src MixUp: 0.2296, Trg MixUp: 0.4356, Src Train Acc: 100.00, Trg Train Acc: 89.61, Src Test Acc: 95.72, Trg Test Acc: 91.90, Server Test Acc: 77.68, Office Test Acc: 73.30, Conf Test Acc: 78.44\n",
      "Epoch: 081, TotalL: 8.2430, CrossE: 0.0019, CondE: 0.0338, disc: 0.0000, domain: 1.3821, Src VAT: 0.0085, Trg VAT: 0.0338, Src MixUp: 0.2245, Trg MixUp: 0.4370, Src Train Acc: 99.96, Trg Train Acc: 89.56, Src Test Acc: 95.72, Trg Test Acc: 92.02, Server Test Acc: 75.89, Office Test Acc: 72.08, Conf Test Acc: 76.67\n",
      "Epoch: 082, TotalL: 8.2035, CrossE: 0.0010, CondE: 0.0300, disc: 0.0000, domain: 1.3798, Src VAT: 0.0068, Trg VAT: 0.0300, Src MixUp: 0.2217, Trg MixUp: 0.4258, Src Train Acc: 100.00, Trg Train Acc: 89.63, Src Test Acc: 95.33, Trg Test Acc: 91.84, Server Test Acc: 78.79, Office Test Acc: 64.85, Conf Test Acc: 77.56\n",
      "Epoch: 083, TotalL: 8.2459, CrossE: 0.0019, CondE: 0.0333, disc: 0.0000, domain: 1.3799, Src VAT: 0.0083, Trg VAT: 0.0333, Src MixUp: 0.2336, Trg MixUp: 0.4353, Src Train Acc: 99.96, Trg Train Acc: 89.54, Src Test Acc: 97.28, Trg Test Acc: 92.95, Server Test Acc: 79.24, Office Test Acc: 76.20, Conf Test Acc: 77.78\n",
      "Epoch: 084, TotalL: 8.1661, CrossE: 0.0010, CondE: 0.0261, disc: 0.0000, domain: 1.3772, Src VAT: 0.0063, Trg VAT: 0.0261, Src MixUp: 0.2198, Trg MixUp: 0.4104, Src Train Acc: 100.00, Trg Train Acc: 89.50, Src Test Acc: 96.89, Trg Test Acc: 93.33, Server Test Acc: 77.23, Office Test Acc: 75.75, Conf Test Acc: 78.00\n",
      "Epoch: 085, TotalL: 8.2102, CrossE: 0.0014, CondE: 0.0279, disc: 0.0000, domain: 1.3806, Src VAT: 0.0077, Trg VAT: 0.0279, Src MixUp: 0.2298, Trg MixUp: 0.4140, Src Train Acc: 100.00, Trg Train Acc: 89.65, Src Test Acc: 97.28, Trg Test Acc: 94.03, Server Test Acc: 75.67, Office Test Acc: 75.86, Conf Test Acc: 76.67\n",
      "Epoch: 086, TotalL: 8.1681, CrossE: 0.0008, CondE: 0.0254, disc: 0.0000, domain: 1.3792, Src VAT: 0.0056, Trg VAT: 0.0254, Src MixUp: 0.2128, Trg MixUp: 0.4179, Src Train Acc: 100.00, Trg Train Acc: 89.58, Src Test Acc: 96.89, Trg Test Acc: 93.39, Server Test Acc: 78.12, Office Test Acc: 74.75, Conf Test Acc: 79.78\n",
      "Epoch: 087, TotalL: 8.1915, CrossE: 0.0010, CondE: 0.0258, disc: 0.0000, domain: 1.3800, Src VAT: 0.0063, Trg VAT: 0.0258, Src MixUp: 0.2223, Trg MixUp: 0.4207, Src Train Acc: 100.00, Trg Train Acc: 89.52, Src Test Acc: 94.94, Trg Test Acc: 88.45, Server Test Acc: 75.00, Office Test Acc: 62.85, Conf Test Acc: 75.56\n",
      "Epoch: 088, TotalL: 8.1581, CrossE: 0.0008, CondE: 0.0230, disc: 0.0000, domain: 1.3796, Src VAT: 0.0053, Trg VAT: 0.0230, Src MixUp: 0.2170, Trg MixUp: 0.4111, Src Train Acc: 100.00, Trg Train Acc: 89.56, Src Test Acc: 96.11, Trg Test Acc: 93.57, Server Test Acc: 81.25, Office Test Acc: 76.08, Conf Test Acc: 79.78\n",
      "Epoch: 089, TotalL: 8.1437, CrossE: 0.0008, CondE: 0.0233, disc: 0.0000, domain: 1.3816, Src VAT: 0.0055, Trg VAT: 0.0233, Src MixUp: 0.2069, Trg MixUp: 0.3980, Src Train Acc: 100.00, Trg Train Acc: 89.67, Src Test Acc: 94.55, Trg Test Acc: 90.29, Server Test Acc: 74.33, Office Test Acc: 69.97, Conf Test Acc: 73.78\n",
      "Epoch: 090, TotalL: 8.2060, CrossE: 0.0019, CondE: 0.0269, disc: 0.0000, domain: 1.3830, Src VAT: 0.0081, Trg VAT: 0.0269, Src MixUp: 0.2225, Trg MixUp: 0.4159, Src Train Acc: 99.96, Trg Train Acc: 89.47, Src Test Acc: 97.28, Trg Test Acc: 92.80, Server Test Acc: 79.46, Office Test Acc: 72.19, Conf Test Acc: 80.00\n",
      "Epoch: 091, TotalL: 8.1283, CrossE: 0.0006, CondE: 0.0213, disc: 0.0000, domain: 1.3786, Src VAT: 0.0046, Trg VAT: 0.0213, Src MixUp: 0.2087, Trg MixUp: 0.3922, Src Train Acc: 100.00, Trg Train Acc: 89.71, Src Test Acc: 92.61, Trg Test Acc: 89.38, Server Test Acc: 71.65, Office Test Acc: 70.86, Conf Test Acc: 71.33\n",
      "Epoch: 092, TotalL: 8.1740, CrossE: 0.0025, CondE: 0.0250, disc: 0.0000, domain: 1.3809, Src VAT: 0.0065, Trg VAT: 0.0250, Src MixUp: 0.2084, Trg MixUp: 0.4090, Src Train Acc: 99.96, Trg Train Acc: 89.54, Src Test Acc: 96.89, Trg Test Acc: 93.01, Server Test Acc: 76.34, Office Test Acc: 76.75, Conf Test Acc: 76.44\n",
      "Epoch: 093, TotalL: 8.1389, CrossE: 0.0009, CondE: 0.0218, disc: 0.0000, domain: 1.3813, Src VAT: 0.0054, Trg VAT: 0.0218, Src MixUp: 0.1981, Trg MixUp: 0.4056, Src Train Acc: 100.00, Trg Train Acc: 89.58, Src Test Acc: 98.05, Trg Test Acc: 94.09, Server Test Acc: 78.57, Office Test Acc: 76.42, Conf Test Acc: 80.67\n",
      "Epoch: 094, TotalL: 8.1273, CrossE: 0.0008, CondE: 0.0201, disc: 0.0000, domain: 1.3793, Src VAT: 0.0050, Trg VAT: 0.0201, Src MixUp: 0.2159, Trg MixUp: 0.3844, Src Train Acc: 100.00, Trg Train Acc: 89.58, Src Test Acc: 97.67, Trg Test Acc: 92.98, Server Test Acc: 76.34, Office Test Acc: 73.08, Conf Test Acc: 76.67\n",
      "Epoch: 095, TotalL: 8.1162, CrossE: 0.0006, CondE: 0.0211, disc: 0.0000, domain: 1.3789, Src VAT: 0.0044, Trg VAT: 0.0211, Src MixUp: 0.1945, Trg MixUp: 0.3972, Src Train Acc: 100.00, Trg Train Acc: 89.65, Src Test Acc: 94.94, Trg Test Acc: 91.43, Server Test Acc: 75.67, Office Test Acc: 72.53, Conf Test Acc: 75.11\n",
      "Epoch: 096, TotalL: 8.0858, CrossE: 0.0005, CondE: 0.0182, disc: 0.0000, domain: 1.3781, Src VAT: 0.0038, Trg VAT: 0.0182, Src MixUp: 0.1895, Trg MixUp: 0.3779, Src Train Acc: 100.00, Trg Train Acc: 89.67, Src Test Acc: 98.05, Trg Test Acc: 94.44, Server Test Acc: 78.12, Office Test Acc: 77.53, Conf Test Acc: 80.44\n",
      "Epoch: 097, TotalL: 8.0761, CrossE: 0.0005, CondE: 0.0168, disc: 0.0000, domain: 1.3783, Src VAT: 0.0039, Trg VAT: 0.0168, Src MixUp: 0.2047, Trg MixUp: 0.3674, Src Train Acc: 100.00, Trg Train Acc: 89.67, Src Test Acc: 96.11, Trg Test Acc: 92.02, Server Test Acc: 76.34, Office Test Acc: 76.42, Conf Test Acc: 76.67\n",
      "Epoch: 098, TotalL: 8.1097, CrossE: 0.0007, CondE: 0.0194, disc: 0.0000, domain: 1.3830, Src VAT: 0.0048, Trg VAT: 0.0194, Src MixUp: 0.1985, Trg MixUp: 0.3818, Src Train Acc: 100.00, Trg Train Acc: 89.61, Src Test Acc: 98.44, Trg Test Acc: 94.24, Server Test Acc: 78.79, Office Test Acc: 77.98, Conf Test Acc: 79.56\n",
      "Epoch: 099, TotalL: 8.1225, CrossE: 0.0007, CondE: 0.0203, disc: 0.0000, domain: 1.3807, Src VAT: 0.0047, Trg VAT: 0.0203, Src MixUp: 0.1985, Trg MixUp: 0.3922, Src Train Acc: 100.00, Trg Train Acc: 89.56, Src Test Acc: 96.50, Trg Test Acc: 94.79, Server Test Acc: 81.25, Office Test Acc: 79.31, Conf Test Acc: 80.00\n",
      "Epoch: 100, TotalL: 8.0916, CrossE: 0.0006, CondE: 0.0157, disc: 0.0000, domain: 1.3801, Src VAT: 0.0042, Trg VAT: 0.0157, Src MixUp: 0.1956, Trg MixUp: 0.3808, Src Train Acc: 100.00, Trg Train Acc: 89.63, Src Test Acc: 97.67, Trg Test Acc: 94.71, Server Test Acc: 81.47, Office Test Acc: 79.64, Conf Test Acc: 81.11\n",
      "Epoch: 101, TotalL: 8.0786, CrossE: 0.0005, CondE: 0.0155, disc: 0.0000, domain: 1.3825, Src VAT: 0.0038, Trg VAT: 0.0155, Src MixUp: 0.2012, Trg MixUp: 0.3711, Src Train Acc: 100.00, Trg Train Acc: 89.67, Src Test Acc: 93.77, Trg Test Acc: 90.44, Server Test Acc: 71.43, Office Test Acc: 68.63, Conf Test Acc: 73.56\n",
      "Epoch: 102, TotalL: 8.0937, CrossE: 0.0008, CondE: 0.0189, disc: 0.0000, domain: 1.3811, Src VAT: 0.0050, Trg VAT: 0.0189, Src MixUp: 0.1916, Trg MixUp: 0.3780, Src Train Acc: 100.00, Trg Train Acc: 89.65, Src Test Acc: 96.89, Trg Test Acc: 93.21, Server Test Acc: 77.46, Office Test Acc: 72.97, Conf Test Acc: 76.89\n",
      "Epoch: 103, TotalL: 8.1305, CrossE: 0.0009, CondE: 0.0199, disc: 0.0000, domain: 1.3825, Src VAT: 0.0056, Trg VAT: 0.0199, Src MixUp: 0.1977, Trg MixUp: 0.3938, Src Train Acc: 100.00, Trg Train Acc: 89.74, Src Test Acc: 98.44, Trg Test Acc: 94.30, Server Test Acc: 79.02, Office Test Acc: 76.75, Conf Test Acc: 79.33\n",
      "Epoch: 104, TotalL: 8.1167, CrossE: 0.0009, CondE: 0.0178, disc: 0.0000, domain: 1.3844, Src VAT: 0.0050, Trg VAT: 0.0178, Src MixUp: 0.2103, Trg MixUp: 0.3742, Src Train Acc: 100.00, Trg Train Acc: 89.65, Src Test Acc: 98.05, Trg Test Acc: 93.92, Server Test Acc: 75.67, Office Test Acc: 76.08, Conf Test Acc: 75.11\n",
      "Epoch: 105, TotalL: 8.1003, CrossE: 0.0005, CondE: 0.0175, disc: 0.0000, domain: 1.3813, Src VAT: 0.0041, Trg VAT: 0.0175, Src MixUp: 0.1927, Trg MixUp: 0.3878, Src Train Acc: 100.00, Trg Train Acc: 89.65, Src Test Acc: 97.67, Trg Test Acc: 94.85, Server Test Acc: 81.92, Office Test Acc: 76.20, Conf Test Acc: 81.56\n",
      "Epoch: 106, TotalL: 8.0524, CrossE: 0.0004, CondE: 0.0139, disc: 0.0000, domain: 1.3798, Src VAT: 0.0034, Trg VAT: 0.0139, Src MixUp: 0.1893, Trg MixUp: 0.3596, Src Train Acc: 100.00, Trg Train Acc: 89.65, Src Test Acc: 97.28, Trg Test Acc: 92.80, Server Test Acc: 75.22, Office Test Acc: 78.53, Conf Test Acc: 73.56\n",
      "Epoch: 107, TotalL: 8.0887, CrossE: 0.0006, CondE: 0.0143, disc: 0.0000, domain: 1.3848, Src VAT: 0.0042, Trg VAT: 0.0143, Src MixUp: 0.1975, Trg MixUp: 0.3793, Src Train Acc: 100.00, Trg Train Acc: 89.67, Src Test Acc: 95.33, Trg Test Acc: 93.54, Server Test Acc: 81.92, Office Test Acc: 72.53, Conf Test Acc: 79.33\n",
      "Epoch: 108, TotalL: 8.0752, CrossE: 0.0005, CondE: 0.0130, disc: 0.0000, domain: 1.3839, Src VAT: 0.0037, Trg VAT: 0.0130, Src MixUp: 0.2051, Trg MixUp: 0.3605, Src Train Acc: 100.00, Trg Train Acc: 89.63, Src Test Acc: 98.44, Trg Test Acc: 94.53, Server Test Acc: 78.79, Office Test Acc: 78.31, Conf Test Acc: 76.67\n",
      "Epoch: 109, TotalL: 8.0619, CrossE: 0.0006, CondE: 0.0141, disc: 0.0000, domain: 1.3832, Src VAT: 0.0040, Trg VAT: 0.0141, Src MixUp: 0.1814, Trg MixUp: 0.3661, Src Train Acc: 100.00, Trg Train Acc: 89.65, Src Test Acc: 96.11, Trg Test Acc: 93.62, Server Test Acc: 78.79, Office Test Acc: 77.42, Conf Test Acc: 77.78\n",
      "Epoch: 110, TotalL: 8.0812, CrossE: 0.0007, CondE: 0.0152, disc: 0.0000, domain: 1.3821, Src VAT: 0.0045, Trg VAT: 0.0152, Src MixUp: 0.1945, Trg MixUp: 0.3715, Src Train Acc: 100.00, Trg Train Acc: 89.56, Src Test Acc: 94.55, Trg Test Acc: 90.55, Server Test Acc: 71.21, Office Test Acc: 69.30, Conf Test Acc: 72.67\n",
      "Epoch: 111, TotalL: 8.0427, CrossE: 0.0005, CondE: 0.0125, disc: 0.0000, domain: 1.3801, Src VAT: 0.0034, Trg VAT: 0.0125, Src MixUp: 0.1868, Trg MixUp: 0.3539, Src Train Acc: 100.00, Trg Train Acc: 89.71, Src Test Acc: 97.67, Trg Test Acc: 94.50, Server Test Acc: 79.02, Office Test Acc: 76.97, Conf Test Acc: 79.78\n",
      "Epoch: 112, TotalL: 8.0667, CrossE: 0.0006, CondE: 0.0138, disc: 0.0000, domain: 1.3845, Src VAT: 0.0038, Trg VAT: 0.0138, Src MixUp: 0.1918, Trg MixUp: 0.3538, Src Train Acc: 100.00, Trg Train Acc: 89.65, Src Test Acc: 96.50, Trg Test Acc: 94.03, Server Test Acc: 79.46, Office Test Acc: 76.64, Conf Test Acc: 77.33\n",
      "Epoch: 113, TotalL: 8.0573, CrossE: 0.0005, CondE: 0.0121, disc: 0.0000, domain: 1.3834, Src VAT: 0.0038, Trg VAT: 0.0121, Src MixUp: 0.1899, Trg MixUp: 0.3589, Src Train Acc: 100.00, Trg Train Acc: 89.71, Src Test Acc: 96.50, Trg Test Acc: 93.68, Server Test Acc: 82.81, Office Test Acc: 76.31, Conf Test Acc: 79.33\n",
      "Epoch: 114, TotalL: 8.0751, CrossE: 0.0018, CondE: 0.0127, disc: 0.0000, domain: 1.3866, Src VAT: 0.0044, Trg VAT: 0.0127, Src MixUp: 0.1948, Trg MixUp: 0.3571, Src Train Acc: 99.91, Trg Train Acc: 89.67, Src Test Acc: 97.67, Trg Test Acc: 94.21, Server Test Acc: 82.14, Office Test Acc: 78.75, Conf Test Acc: 78.89\n",
      "Epoch: 115, TotalL: 8.0746, CrossE: 0.0007, CondE: 0.0120, disc: 0.0000, domain: 1.3845, Src VAT: 0.0043, Trg VAT: 0.0120, Src MixUp: 0.1968, Trg MixUp: 0.3582, Src Train Acc: 100.00, Trg Train Acc: 89.69, Src Test Acc: 98.05, Trg Test Acc: 94.71, Server Test Acc: 79.69, Office Test Acc: 79.76, Conf Test Acc: 77.78\n",
      "Epoch: 116, TotalL: 8.0577, CrossE: 0.0007, CondE: 0.0124, disc: 0.0000, domain: 1.3845, Src VAT: 0.0042, Trg VAT: 0.0124, Src MixUp: 0.1880, Trg MixUp: 0.3532, Src Train Acc: 100.00, Trg Train Acc: 89.69, Src Test Acc: 96.89, Trg Test Acc: 94.18, Server Test Acc: 78.35, Office Test Acc: 77.75, Conf Test Acc: 78.22\n",
      "Epoch: 117, TotalL: 8.0424, CrossE: 0.0004, CondE: 0.0113, disc: 0.0000, domain: 1.3848, Src VAT: 0.0032, Trg VAT: 0.0113, Src MixUp: 0.1857, Trg MixUp: 0.3550, Src Train Acc: 100.00, Trg Train Acc: 89.69, Src Test Acc: 98.05, Trg Test Acc: 94.41, Server Test Acc: 78.12, Office Test Acc: 76.08, Conf Test Acc: 77.56\n",
      "Epoch: 118, TotalL: 8.0282, CrossE: 0.0004, CondE: 0.0107, disc: 0.0000, domain: 1.3823, Src VAT: 0.0032, Trg VAT: 0.0107, Src MixUp: 0.1800, Trg MixUp: 0.3549, Src Train Acc: 100.00, Trg Train Acc: 89.63, Src Test Acc: 96.89, Trg Test Acc: 93.62, Server Test Acc: 74.78, Office Test Acc: 77.20, Conf Test Acc: 75.33\n",
      "Epoch: 119, TotalL: 8.1012, CrossE: 0.0017, CondE: 0.0151, disc: 0.0000, domain: 1.3861, Src VAT: 0.0057, Trg VAT: 0.0151, Src MixUp: 0.2016, Trg MixUp: 0.3599, Src Train Acc: 99.96, Trg Train Acc: 89.65, Src Test Acc: 96.50, Trg Test Acc: 91.58, Server Test Acc: 73.88, Office Test Acc: 75.97, Conf Test Acc: 75.11\n",
      "Epoch: 120, TotalL: 8.0297, CrossE: 0.0005, CondE: 0.0105, disc: 0.0000, domain: 1.3812, Src VAT: 0.0033, Trg VAT: 0.0105, Src MixUp: 0.1847, Trg MixUp: 0.3386, Src Train Acc: 100.00, Trg Train Acc: 89.65, Src Test Acc: 96.50, Trg Test Acc: 92.31, Server Test Acc: 77.46, Office Test Acc: 73.86, Conf Test Acc: 78.67\n",
      "Epoch: 121, TotalL: 8.0085, CrossE: 0.0004, CondE: 0.0099, disc: 0.0000, domain: 1.3831, Src VAT: 0.0029, Trg VAT: 0.0099, Src MixUp: 0.1763, Trg MixUp: 0.3385, Src Train Acc: 100.00, Trg Train Acc: 89.65, Src Test Acc: 98.05, Trg Test Acc: 95.44, Server Test Acc: 81.47, Office Test Acc: 80.65, Conf Test Acc: 79.56\n",
      "Epoch: 122, TotalL: 8.0090, CrossE: 0.0004, CondE: 0.0092, disc: 0.0000, domain: 1.3842, Src VAT: 0.0030, Trg VAT: 0.0092, Src MixUp: 0.1861, Trg MixUp: 0.3324, Src Train Acc: 100.00, Trg Train Acc: 89.67, Src Test Acc: 96.89, Trg Test Acc: 94.21, Server Test Acc: 78.35, Office Test Acc: 77.09, Conf Test Acc: 77.78\n",
      "Epoch: 123, TotalL: 8.0070, CrossE: 0.0004, CondE: 0.0099, disc: 0.0000, domain: 1.3831, Src VAT: 0.0032, Trg VAT: 0.0099, Src MixUp: 0.1758, Trg MixUp: 0.3368, Src Train Acc: 100.00, Trg Train Acc: 89.67, Src Test Acc: 97.67, Trg Test Acc: 94.50, Server Test Acc: 83.48, Office Test Acc: 78.75, Conf Test Acc: 80.89\n",
      "Epoch: 124, TotalL: 8.0156, CrossE: 0.0004, CondE: 0.0102, disc: 0.0000, domain: 1.3844, Src VAT: 0.0031, Trg VAT: 0.0102, Src MixUp: 0.1782, Trg MixUp: 0.3304, Src Train Acc: 100.00, Trg Train Acc: 89.69, Src Test Acc: 94.16, Trg Test Acc: 88.36, Server Test Acc: 70.54, Office Test Acc: 59.40, Conf Test Acc: 70.89\n",
      "Epoch: 125, TotalL: 8.0465, CrossE: 0.0009, CondE: 0.0125, disc: 0.0000, domain: 1.3846, Src VAT: 0.0047, Trg VAT: 0.0125, Src MixUp: 0.1843, Trg MixUp: 0.3428, Src Train Acc: 100.00, Trg Train Acc: 89.67, Src Test Acc: 98.05, Trg Test Acc: 93.36, Server Test Acc: 74.55, Office Test Acc: 74.64, Conf Test Acc: 75.56\n",
      "Epoch: 126, TotalL: 8.0187, CrossE: 0.0004, CondE: 0.0104, disc: 0.0000, domain: 1.3840, Src VAT: 0.0030, Trg VAT: 0.0104, Src MixUp: 0.1732, Trg MixUp: 0.3391, Src Train Acc: 100.00, Trg Train Acc: 89.67, Src Test Acc: 98.05, Trg Test Acc: 93.95, Server Test Acc: 79.69, Office Test Acc: 75.31, Conf Test Acc: 82.00\n",
      "Epoch: 127, TotalL: 8.0145, CrossE: 0.0004, CondE: 0.0091, disc: 0.0000, domain: 1.3837, Src VAT: 0.0029, Trg VAT: 0.0091, Src MixUp: 0.1793, Trg MixUp: 0.3409, Src Train Acc: 100.00, Trg Train Acc: 89.67, Src Test Acc: 97.67, Trg Test Acc: 94.33, Server Test Acc: 80.80, Office Test Acc: 78.98, Conf Test Acc: 80.00\n",
      "Epoch: 128, TotalL: 8.0083, CrossE: 0.0005, CondE: 0.0090, disc: 0.0000, domain: 1.3862, Src VAT: 0.0035, Trg VAT: 0.0090, Src MixUp: 0.1716, Trg MixUp: 0.3311, Src Train Acc: 100.00, Trg Train Acc: 89.69, Src Test Acc: 95.72, Trg Test Acc: 95.29, Server Test Acc: 78.79, Office Test Acc: 75.31, Conf Test Acc: 79.78\n",
      "Epoch: 129, TotalL: 8.0046, CrossE: 0.0003, CondE: 0.0093, disc: 0.0000, domain: 1.3832, Src VAT: 0.0027, Trg VAT: 0.0093, Src MixUp: 0.1793, Trg MixUp: 0.3300, Src Train Acc: 100.00, Trg Train Acc: 89.69, Src Test Acc: 95.33, Trg Test Acc: 91.02, Server Test Acc: 72.10, Office Test Acc: 66.85, Conf Test Acc: 74.67\n",
      "Epoch: 130, TotalL: 8.0109, CrossE: 0.0005, CondE: 0.0091, disc: 0.0000, domain: 1.3832, Src VAT: 0.0032, Trg VAT: 0.0091, Src MixUp: 0.1831, Trg MixUp: 0.3339, Src Train Acc: 100.00, Trg Train Acc: 89.67, Src Test Acc: 96.89, Trg Test Acc: 94.12, Server Test Acc: 75.22, Office Test Acc: 75.64, Conf Test Acc: 77.56\n",
      "Epoch: 131, TotalL: 8.0036, CrossE: 0.0004, CondE: 0.0091, disc: 0.0000, domain: 1.3857, Src VAT: 0.0033, Trg VAT: 0.0091, Src MixUp: 0.1769, Trg MixUp: 0.3287, Src Train Acc: 100.00, Trg Train Acc: 89.71, Src Test Acc: 97.28, Trg Test Acc: 95.23, Server Test Acc: 83.48, Office Test Acc: 79.64, Conf Test Acc: 81.33\n",
      "Epoch: 132, TotalL: 8.0220, CrossE: 0.0006, CondE: 0.0100, disc: 0.0000, domain: 1.3841, Src VAT: 0.0038, Trg VAT: 0.0100, Src MixUp: 0.1763, Trg MixUp: 0.3438, Src Train Acc: 100.00, Trg Train Acc: 89.67, Src Test Acc: 95.72, Trg Test Acc: 93.36, Server Test Acc: 79.91, Office Test Acc: 72.53, Conf Test Acc: 80.67\n",
      "Epoch: 133, TotalL: 7.9955, CrossE: 0.0004, CondE: 0.0092, disc: 0.0000, domain: 1.3851, Src VAT: 0.0029, Trg VAT: 0.0092, Src MixUp: 0.1735, Trg MixUp: 0.3278, Src Train Acc: 100.00, Trg Train Acc: 89.67, Src Test Acc: 97.28, Trg Test Acc: 92.92, Server Test Acc: 78.12, Office Test Acc: 83.09, Conf Test Acc: 75.33\n",
      "Epoch: 134, TotalL: 8.0077, CrossE: 0.0005, CondE: 0.0101, disc: 0.0000, domain: 1.3848, Src VAT: 0.0034, Trg VAT: 0.0101, Src MixUp: 0.1783, Trg MixUp: 0.3271, Src Train Acc: 100.00, Trg Train Acc: 89.67, Src Test Acc: 96.50, Trg Test Acc: 92.28, Server Test Acc: 76.79, Office Test Acc: 70.63, Conf Test Acc: 77.11\n",
      "Epoch: 135, TotalL: 8.0529, CrossE: 0.0010, CondE: 0.0128, disc: 0.0000, domain: 1.3849, Src VAT: 0.0043, Trg VAT: 0.0128, Src MixUp: 0.1858, Trg MixUp: 0.3370, Src Train Acc: 99.96, Trg Train Acc: 89.63, Src Test Acc: 95.33, Trg Test Acc: 92.40, Server Test Acc: 76.56, Office Test Acc: 70.30, Conf Test Acc: 76.22\n",
      "Epoch: 136, TotalL: 7.9819, CrossE: 0.0003, CondE: 0.0078, disc: 0.0000, domain: 1.3844, Src VAT: 0.0023, Trg VAT: 0.0078, Src MixUp: 0.1623, Trg MixUp: 0.3217, Src Train Acc: 100.00, Trg Train Acc: 89.67, Src Test Acc: 96.50, Trg Test Acc: 94.76, Server Test Acc: 80.80, Office Test Acc: 77.31, Conf Test Acc: 80.00\n",
      "Epoch: 137, TotalL: 7.9933, CrossE: 0.0003, CondE: 0.0072, disc: 0.0000, domain: 1.3862, Src VAT: 0.0022, Trg VAT: 0.0072, Src MixUp: 0.1747, Trg MixUp: 0.3173, Src Train Acc: 100.00, Trg Train Acc: 89.67, Src Test Acc: 97.67, Trg Test Acc: 91.96, Server Test Acc: 78.35, Office Test Acc: 79.64, Conf Test Acc: 76.00\n",
      "Epoch: 138, TotalL: 7.9484, CrossE: 0.0002, CondE: 0.0063, disc: 0.0000, domain: 1.3802, Src VAT: 0.0017, Trg VAT: 0.0063, Src MixUp: 0.1642, Trg MixUp: 0.3039, Src Train Acc: 100.00, Trg Train Acc: 89.69, Src Test Acc: 96.11, Trg Test Acc: 92.10, Server Test Acc: 75.00, Office Test Acc: 76.53, Conf Test Acc: 73.33\n",
      "Epoch: 139, TotalL: 7.9888, CrossE: 0.0004, CondE: 0.0084, disc: 0.0000, domain: 1.3857, Src VAT: 0.0029, Trg VAT: 0.0084, Src MixUp: 0.1692, Trg MixUp: 0.3177, Src Train Acc: 100.00, Trg Train Acc: 89.67, Src Test Acc: 97.67, Trg Test Acc: 95.55, Server Test Acc: 83.26, Office Test Acc: 82.31, Conf Test Acc: 79.78\n",
      "Epoch: 140, TotalL: 8.0365, CrossE: 0.0012, CondE: 0.0099, disc: 0.0000, domain: 1.3860, Src VAT: 0.0045, Trg VAT: 0.0099, Src MixUp: 0.1887, Trg MixUp: 0.3350, Src Train Acc: 100.00, Trg Train Acc: 89.69, Src Test Acc: 98.05, Trg Test Acc: 95.70, Server Test Acc: 81.03, Office Test Acc: 80.53, Conf Test Acc: 81.11\n",
      "Epoch: 141, TotalL: 7.9769, CrossE: 0.0009, CondE: 0.0074, disc: 0.0000, domain: 1.3846, Src VAT: 0.0023, Trg VAT: 0.0074, Src MixUp: 0.1728, Trg MixUp: 0.3127, Src Train Acc: 99.96, Trg Train Acc: 89.69, Src Test Acc: 97.67, Trg Test Acc: 93.86, Server Test Acc: 80.13, Office Test Acc: 73.64, Conf Test Acc: 80.44\n",
      "Epoch: 142, TotalL: 7.9821, CrossE: 0.0003, CondE: 0.0073, disc: 0.0000, domain: 1.3854, Src VAT: 0.0023, Trg VAT: 0.0073, Src MixUp: 0.1797, Trg MixUp: 0.3114, Src Train Acc: 100.00, Trg Train Acc: 89.71, Src Test Acc: 97.67, Trg Test Acc: 95.14, Server Test Acc: 80.13, Office Test Acc: 77.75, Conf Test Acc: 80.44\n",
      "Epoch: 143, TotalL: 7.9532, CrossE: 0.0003, CondE: 0.0063, disc: 0.0000, domain: 1.3829, Src VAT: 0.0023, Trg VAT: 0.0063, Src MixUp: 0.1666, Trg MixUp: 0.3140, Src Train Acc: 100.00, Trg Train Acc: 89.69, Src Test Acc: 96.89, Trg Test Acc: 94.06, Server Test Acc: 77.01, Office Test Acc: 72.19, Conf Test Acc: 78.22\n",
      "Epoch: 144, TotalL: 8.0168, CrossE: 0.0005, CondE: 0.0100, disc: 0.0000, domain: 1.3866, Src VAT: 0.0033, Trg VAT: 0.0100, Src MixUp: 0.1840, Trg MixUp: 0.3250, Src Train Acc: 100.00, Trg Train Acc: 89.63, Src Test Acc: 98.44, Trg Test Acc: 95.61, Server Test Acc: 82.14, Office Test Acc: 80.76, Conf Test Acc: 78.00\n",
      "Epoch: 145, TotalL: 7.9468, CrossE: 0.0002, CondE: 0.0061, disc: 0.0000, domain: 1.3857, Src VAT: 0.0021, Trg VAT: 0.0061, Src MixUp: 0.1662, Trg MixUp: 0.2933, Src Train Acc: 100.00, Trg Train Acc: 89.71, Src Test Acc: 97.28, Trg Test Acc: 95.06, Server Test Acc: 79.46, Office Test Acc: 78.31, Conf Test Acc: 78.89\n",
      "Epoch: 146, TotalL: 7.9626, CrossE: 0.0003, CondE: 0.0068, disc: 0.0000, domain: 1.3835, Src VAT: 0.0022, Trg VAT: 0.0068, Src MixUp: 0.1649, Trg MixUp: 0.3139, Src Train Acc: 100.00, Trg Train Acc: 89.71, Src Test Acc: 97.67, Trg Test Acc: 95.20, Server Test Acc: 83.48, Office Test Acc: 78.31, Conf Test Acc: 83.11\n",
      "Epoch: 147, TotalL: 7.9842, CrossE: 0.0003, CondE: 0.0073, disc: 0.0000, domain: 1.3855, Src VAT: 0.0024, Trg VAT: 0.0073, Src MixUp: 0.1785, Trg MixUp: 0.3154, Src Train Acc: 100.00, Trg Train Acc: 89.69, Src Test Acc: 97.28, Trg Test Acc: 93.48, Server Test Acc: 75.00, Office Test Acc: 78.09, Conf Test Acc: 74.89\n",
      "Epoch: 148, TotalL: 7.9666, CrossE: 0.0003, CondE: 0.0064, disc: 0.0000, domain: 1.3851, Src VAT: 0.0022, Trg VAT: 0.0064, Src MixUp: 0.1705, Trg MixUp: 0.3103, Src Train Acc: 100.00, Trg Train Acc: 89.69, Src Test Acc: 98.05, Trg Test Acc: 95.61, Server Test Acc: 82.81, Office Test Acc: 79.87, Conf Test Acc: 80.44\n",
      "Epoch: 149, TotalL: 7.9626, CrossE: 0.0003, CondE: 0.0070, disc: 0.0000, domain: 1.3855, Src VAT: 0.0022, Trg VAT: 0.0070, Src MixUp: 0.1611, Trg MixUp: 0.3089, Src Train Acc: 100.00, Trg Train Acc: 89.76, Src Test Acc: 96.11, Trg Test Acc: 93.33, Server Test Acc: 78.57, Office Test Acc: 76.97, Conf Test Acc: 77.33\n",
      "Epoch: 150, TotalL: 7.9853, CrossE: 0.0004, CondE: 0.0072, disc: 0.0000, domain: 1.3835, Src VAT: 0.0028, Trg VAT: 0.0072, Src MixUp: 0.1737, Trg MixUp: 0.3142, Src Train Acc: 100.00, Trg Train Acc: 89.67, Src Test Acc: 96.11, Trg Test Acc: 94.44, Server Test Acc: 83.48, Office Test Acc: 79.31, Conf Test Acc: 81.11\n",
      "Epoch: 151, TotalL: 7.9323, CrossE: 0.0002, CondE: 0.0054, disc: 0.0000, domain: 1.3839, Src VAT: 0.0018, Trg VAT: 0.0054, Src MixUp: 0.1619, Trg MixUp: 0.2937, Src Train Acc: 100.00, Trg Train Acc: 89.69, Src Test Acc: 96.50, Trg Test Acc: 95.29, Server Test Acc: 80.58, Office Test Acc: 78.98, Conf Test Acc: 77.56\n",
      "Epoch: 152, TotalL: 8.0758, CrossE: 0.0165, CondE: 0.0119, disc: 0.0000, domain: 1.3878, Src VAT: 0.0060, Trg VAT: 0.0119, Src MixUp: 0.1837, Trg MixUp: 0.3241, Src Train Acc: 99.74, Trg Train Acc: 89.52, Src Test Acc: 97.28, Trg Test Acc: 94.91, Server Test Acc: 79.69, Office Test Acc: 71.08, Conf Test Acc: 80.00\n",
      "Epoch: 153, TotalL: 7.9439, CrossE: 0.0002, CondE: 0.0062, disc: 0.0000, domain: 1.3831, Src VAT: 0.0018, Trg VAT: 0.0062, Src MixUp: 0.1564, Trg MixUp: 0.3011, Src Train Acc: 100.00, Trg Train Acc: 89.69, Src Test Acc: 96.50, Trg Test Acc: 93.71, Server Test Acc: 79.91, Office Test Acc: 76.20, Conf Test Acc: 79.78\n",
      "Epoch: 154, TotalL: 7.9268, CrossE: 0.0002, CondE: 0.0055, disc: 0.0000, domain: 1.3838, Src VAT: 0.0018, Trg VAT: 0.0055, Src MixUp: 0.1607, Trg MixUp: 0.2902, Src Train Acc: 100.00, Trg Train Acc: 89.67, Src Test Acc: 98.05, Trg Test Acc: 95.17, Server Test Acc: 79.69, Office Test Acc: 76.86, Conf Test Acc: 79.56\n",
      "Epoch: 155, TotalL: 7.9460, CrossE: 0.0003, CondE: 0.0050, disc: 0.0000, domain: 1.3841, Src VAT: 0.0021, Trg VAT: 0.0050, Src MixUp: 0.1682, Trg MixUp: 0.2943, Src Train Acc: 100.00, Trg Train Acc: 89.69, Src Test Acc: 98.44, Trg Test Acc: 95.26, Server Test Acc: 82.14, Office Test Acc: 79.64, Conf Test Acc: 80.22\n",
      "Epoch: 156, TotalL: 7.9261, CrossE: 0.0002, CondE: 0.0047, disc: 0.0000, domain: 1.3843, Src VAT: 0.0017, Trg VAT: 0.0047, Src MixUp: 0.1600, Trg MixUp: 0.2907, Src Train Acc: 100.00, Trg Train Acc: 89.69, Src Test Acc: 97.28, Trg Test Acc: 95.17, Server Test Acc: 77.68, Office Test Acc: 78.20, Conf Test Acc: 78.44\n",
      "Epoch: 157, TotalL: 7.9383, CrossE: 0.0004, CondE: 0.0055, disc: 0.0000, domain: 1.3862, Src VAT: 0.0023, Trg VAT: 0.0055, Src MixUp: 0.1653, Trg MixUp: 0.2899, Src Train Acc: 100.00, Trg Train Acc: 89.71, Src Test Acc: 96.89, Trg Test Acc: 94.94, Server Test Acc: 78.12, Office Test Acc: 79.09, Conf Test Acc: 79.11\n",
      "Epoch: 158, TotalL: 7.9181, CrossE: 0.0002, CondE: 0.0054, disc: 0.0000, domain: 1.3840, Src VAT: 0.0020, Trg VAT: 0.0054, Src MixUp: 0.1538, Trg MixUp: 0.2884, Src Train Acc: 100.00, Trg Train Acc: 89.67, Src Test Acc: 98.05, Trg Test Acc: 95.70, Server Test Acc: 82.81, Office Test Acc: 80.76, Conf Test Acc: 81.78\n",
      "Epoch: 159, TotalL: 7.9566, CrossE: 0.0002, CondE: 0.0064, disc: 0.0000, domain: 1.3861, Src VAT: 0.0020, Trg VAT: 0.0064, Src MixUp: 0.1648, Trg MixUp: 0.2996, Src Train Acc: 100.00, Trg Train Acc: 89.71, Src Test Acc: 95.72, Trg Test Acc: 91.69, Server Test Acc: 74.33, Office Test Acc: 76.97, Conf Test Acc: 74.67\n",
      "Epoch: 160, TotalL: 7.9278, CrossE: 0.0002, CondE: 0.0054, disc: 0.0000, domain: 1.3854, Src VAT: 0.0018, Trg VAT: 0.0054, Src MixUp: 0.1506, Trg MixUp: 0.2961, Src Train Acc: 100.00, Trg Train Acc: 89.69, Src Test Acc: 98.05, Trg Test Acc: 94.91, Server Test Acc: 81.03, Office Test Acc: 77.53, Conf Test Acc: 78.44\n",
      "Epoch: 161, TotalL: 7.9948, CrossE: 0.0007, CondE: 0.0088, disc: 0.0000, domain: 1.3849, Src VAT: 0.0036, Trg VAT: 0.0088, Src MixUp: 0.1791, Trg MixUp: 0.3098, Src Train Acc: 100.00, Trg Train Acc: 89.67, Src Test Acc: 98.44, Trg Test Acc: 95.38, Server Test Acc: 84.15, Office Test Acc: 78.20, Conf Test Acc: 84.00\n",
      "Epoch: 162, TotalL: 7.9572, CrossE: 0.0003, CondE: 0.0057, disc: 0.0000, domain: 1.3854, Src VAT: 0.0023, Trg VAT: 0.0057, Src MixUp: 0.1694, Trg MixUp: 0.3009, Src Train Acc: 100.00, Trg Train Acc: 89.69, Src Test Acc: 97.67, Trg Test Acc: 95.67, Server Test Acc: 83.93, Office Test Acc: 80.65, Conf Test Acc: 82.22\n",
      "Epoch: 163, TotalL: 7.9477, CrossE: 0.0002, CondE: 0.0055, disc: 0.0000, domain: 1.3833, Src VAT: 0.0019, Trg VAT: 0.0055, Src MixUp: 0.1733, Trg MixUp: 0.2905, Src Train Acc: 100.00, Trg Train Acc: 89.71, Src Test Acc: 97.67, Trg Test Acc: 95.26, Server Test Acc: 77.90, Office Test Acc: 79.87, Conf Test Acc: 78.22\n",
      "Epoch: 164, TotalL: 7.9625, CrossE: 0.0002, CondE: 0.0065, disc: 0.0000, domain: 1.3847, Src VAT: 0.0021, Trg VAT: 0.0065, Src MixUp: 0.1763, Trg MixUp: 0.2958, Src Train Acc: 100.00, Trg Train Acc: 89.65, Src Test Acc: 96.50, Trg Test Acc: 94.47, Server Test Acc: 80.36, Office Test Acc: 76.64, Conf Test Acc: 78.00\n",
      "Epoch: 165, TotalL: 7.9242, CrossE: 0.0002, CondE: 0.0053, disc: 0.0000, domain: 1.3856, Src VAT: 0.0019, Trg VAT: 0.0053, Src MixUp: 0.1589, Trg MixUp: 0.2800, Src Train Acc: 100.00, Trg Train Acc: 89.67, Src Test Acc: 97.67, Trg Test Acc: 94.36, Server Test Acc: 79.46, Office Test Acc: 78.09, Conf Test Acc: 79.78\n",
      "Epoch: 166, TotalL: 7.9617, CrossE: 0.0004, CondE: 0.0064, disc: 0.0000, domain: 1.3851, Src VAT: 0.0024, Trg VAT: 0.0064, Src MixUp: 0.1702, Trg MixUp: 0.2919, Src Train Acc: 100.00, Trg Train Acc: 89.67, Src Test Acc: 97.28, Trg Test Acc: 93.74, Server Test Acc: 78.12, Office Test Acc: 70.63, Conf Test Acc: 79.56\n",
      "Epoch: 167, TotalL: 7.9084, CrossE: 0.0001, CondE: 0.0047, disc: 0.0000, domain: 1.3855, Src VAT: 0.0014, Trg VAT: 0.0047, Src MixUp: 0.1514, Trg MixUp: 0.2738, Src Train Acc: 100.00, Trg Train Acc: 89.71, Src Test Acc: 98.44, Trg Test Acc: 95.03, Server Test Acc: 83.26, Office Test Acc: 75.64, Conf Test Acc: 81.78\n",
      "Epoch: 168, TotalL: 7.9192, CrossE: 0.0003, CondE: 0.0049, disc: 0.0000, domain: 1.3855, Src VAT: 0.0020, Trg VAT: 0.0049, Src MixUp: 0.1562, Trg MixUp: 0.2838, Src Train Acc: 100.00, Trg Train Acc: 89.71, Src Test Acc: 96.89, Trg Test Acc: 94.56, Server Test Acc: 84.82, Office Test Acc: 78.87, Conf Test Acc: 80.89\n",
      "Epoch: 169, TotalL: 7.9492, CrossE: 0.0003, CondE: 0.0061, disc: 0.0000, domain: 1.3847, Src VAT: 0.0021, Trg VAT: 0.0061, Src MixUp: 0.1678, Trg MixUp: 0.2919, Src Train Acc: 100.00, Trg Train Acc: 89.69, Src Test Acc: 97.28, Trg Test Acc: 94.79, Server Test Acc: 78.12, Office Test Acc: 80.53, Conf Test Acc: 78.89\n",
      "Epoch: 170, TotalL: 7.9236, CrossE: 0.0002, CondE: 0.0048, disc: 0.0000, domain: 1.3842, Src VAT: 0.0017, Trg VAT: 0.0048, Src MixUp: 0.1648, Trg MixUp: 0.2821, Src Train Acc: 100.00, Trg Train Acc: 89.69, Src Test Acc: 96.11, Trg Test Acc: 93.48, Server Test Acc: 78.12, Office Test Acc: 75.75, Conf Test Acc: 79.33\n",
      "Epoch: 171, TotalL: 7.9041, CrossE: 0.0002, CondE: 0.0045, disc: 0.0000, domain: 1.3842, Src VAT: 0.0019, Trg VAT: 0.0045, Src MixUp: 0.1551, Trg MixUp: 0.2744, Src Train Acc: 100.00, Trg Train Acc: 89.69, Src Test Acc: 95.72, Trg Test Acc: 93.83, Server Test Acc: 78.35, Office Test Acc: 77.64, Conf Test Acc: 76.44\n",
      "Epoch: 172, TotalL: 8.2384, CrossE: 0.0349, CondE: 0.0261, disc: 0.0000, domain: 1.3877, Src VAT: 0.0171, Trg VAT: 0.0261, Src MixUp: 0.2051, Trg MixUp: 0.3320, Src Train Acc: 99.00, Trg Train Acc: 88.56, Src Test Acc: 97.28, Trg Test Acc: 94.18, Server Test Acc: 79.46, Office Test Acc: 81.54, Conf Test Acc: 75.78\n",
      "Epoch: 173, TotalL: 7.9279, CrossE: 0.0003, CondE: 0.0051, disc: 0.0000, domain: 1.3834, Src VAT: 0.0017, Trg VAT: 0.0051, Src MixUp: 0.1626, Trg MixUp: 0.2800, Src Train Acc: 100.00, Trg Train Acc: 89.74, Src Test Acc: 96.11, Trg Test Acc: 95.61, Server Test Acc: 81.47, Office Test Acc: 82.31, Conf Test Acc: 78.44\n",
      "Epoch: 174, TotalL: 7.8914, CrossE: 0.0001, CondE: 0.0037, disc: 0.0000, domain: 1.3820, Src VAT: 0.0012, Trg VAT: 0.0037, Src MixUp: 0.1607, Trg MixUp: 0.2637, Src Train Acc: 100.00, Trg Train Acc: 89.69, Src Test Acc: 98.05, Trg Test Acc: 95.47, Server Test Acc: 81.03, Office Test Acc: 81.65, Conf Test Acc: 78.44\n",
      "Epoch: 175, TotalL: 7.8792, CrossE: 0.0001, CondE: 0.0036, disc: 0.0000, domain: 1.3834, Src VAT: 0.0013, Trg VAT: 0.0036, Src MixUp: 0.1536, Trg MixUp: 0.2634, Src Train Acc: 100.00, Trg Train Acc: 89.71, Src Test Acc: 98.44, Trg Test Acc: 96.14, Server Test Acc: 85.04, Office Test Acc: 82.20, Conf Test Acc: 83.56\n",
      "Epoch: 176, TotalL: 7.8858, CrossE: 0.0001, CondE: 0.0038, disc: 0.0000, domain: 1.3850, Src VAT: 0.0014, Trg VAT: 0.0038, Src MixUp: 0.1507, Trg MixUp: 0.2676, Src Train Acc: 100.00, Trg Train Acc: 89.69, Src Test Acc: 97.67, Trg Test Acc: 95.55, Server Test Acc: 83.93, Office Test Acc: 83.20, Conf Test Acc: 80.67\n",
      "Epoch: 177, TotalL: 7.9058, CrossE: 0.0002, CondE: 0.0042, disc: 0.0000, domain: 1.3851, Src VAT: 0.0017, Trg VAT: 0.0042, Src MixUp: 0.1620, Trg MixUp: 0.2732, Src Train Acc: 100.00, Trg Train Acc: 89.71, Src Test Acc: 97.28, Trg Test Acc: 94.94, Server Test Acc: 82.37, Office Test Acc: 76.97, Conf Test Acc: 79.33\n",
      "Epoch: 178, TotalL: 7.9159, CrossE: 0.0002, CondE: 0.0048, disc: 0.0000, domain: 1.3836, Src VAT: 0.0017, Trg VAT: 0.0048, Src MixUp: 0.1666, Trg MixUp: 0.2772, Src Train Acc: 100.00, Trg Train Acc: 89.69, Src Test Acc: 96.11, Trg Test Acc: 93.86, Server Test Acc: 77.46, Office Test Acc: 75.53, Conf Test Acc: 76.22\n",
      "Epoch: 179, TotalL: 7.8791, CrossE: 0.0001, CondE: 0.0041, disc: 0.0000, domain: 1.3840, Src VAT: 0.0014, Trg VAT: 0.0041, Src MixUp: 0.1441, Trg MixUp: 0.2686, Src Train Acc: 100.00, Trg Train Acc: 89.67, Src Test Acc: 97.28, Trg Test Acc: 95.53, Server Test Acc: 82.59, Office Test Acc: 80.65, Conf Test Acc: 79.56\n"
     ]
    }
   ],
   "source": [
    "train_template = 'Epoch: {:03d}, TotalL: {:.4f}, CrossE: {:.4f}, CondE: {:.4f}, disc: {:.4f}, domain: {:.4f}, Src VAT: {:.4f}, Trg VAT: {:.4f}, Src MixUp: {:.4f}, Trg MixUp: {:.4f}, Src Train Acc: {:.2f}, Trg Train Acc: {:.2f}, '\n",
    "test_template  = 'Src Test Acc: {:.2f}, Trg Test Acc: {:.2f}, Server Test Acc: {:.2f}, Office Test Acc: {:.2f}, Conf Test Acc: {:.2f}'\n",
    "\n",
    "generator      = ResNet50(num_classes, num_features, num_hidden, gen_activation)\n",
    "gen_optimizer  = tf.keras.optimizers.Adam(learning_rate = learning_rate, beta_1 = 0.5)\n",
    "center_loss    = CenterLoss(batch_size, num_classes, num_features, alpha)\n",
    "\n",
    "summary_writer = tf.contrib.summary.create_file_writer('../logs/{}'.format(log_data), flush_millis=10000)\n",
    "summary_writer.set_as_default()\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "def log_loss():\n",
    "  with tf.contrib.summary.always_record_summaries():\n",
    "    tf.contrib.summary.scalar(\"train_total_loss\", train_total_loss.result())\n",
    "    tf.contrib.summary.scalar(\"train_cross_entropy_loss\", train_cross_entropy_loss.result())\n",
    "    tf.contrib.summary.scalar(\"train_cond_entropy_loss\", train_cond_entropy_loss.result())\n",
    "    tf.contrib.summary.scalar(\"src_train_accuracy\", src_train_accuracy.result())\n",
    "    tf.contrib.summary.scalar(\"trg_train_accuracy\", trg_train_accuracy.result())\n",
    "    tf.contrib.summary.scalar(\"train_discriminator_loss\", train_discriminator_loss.result())\n",
    "    tf.contrib.summary.scalar(\"train_domain_loss\", train_domain_loss.result())\n",
    "    tf.contrib.summary.scalar(\"train_src_vat_loss\", train_src_vat_loss.result())\n",
    "    tf.contrib.summary.scalar(\"train_trg_vat_loss\", train_trg_vat_loss.result())\n",
    "    tf.contrib.summary.scalar(\"train_src_mixup_loss\", train_src_mixup_loss.result())\n",
    "    tf.contrib.summary.scalar(\"train_trg_mixup_loss\", train_trg_mixup_loss.result())\n",
    "    tf.contrib.summary.scalar(\"src_test_accuracy\", src_test_accuracy.result())\n",
    "    tf.contrib.summary.scalar(\"trg_test_accuracy\", trg_test_accuracy.result())\n",
    "    tf.contrib.summary.scalar(\"office_test_accuracy\", office_test_accuracy.result())\n",
    "    tf.contrib.summary.scalar(\"server_test_accuracy\", server_test_accuracy.result())\n",
    "    tf.contrib.summary.scalar(\"conf_test_accuracy\", conf_test_accuracy.result())\n",
    "\n",
    "def get_lambda(p, delta=10):\n",
    "  return ((2/(1 + np.exp(-delta*p))) - 1).astype(np.float32)\n",
    "\n",
    "for epoch in range(epochs):  \n",
    "  global_step.assign_add(1)  \n",
    "\n",
    "  for source_data, target_data, server_data, conf_data in zip(src_train_set, time_train_set, server_train_set, conf_train_set):\n",
    "    train_gen_step(source_data[0], source_data[1], server_data[0], server_data[1], conf_data[0], conf_data[1], target_data[0], target_data[1], get_lambda(epoch*2))\n",
    "\n",
    "  print(train_template.format(epoch+1,\n",
    "                              train_total_loss.result(),\n",
    "                              train_cross_entropy_loss.result(),\n",
    "                              train_cond_entropy_loss.result(),\n",
    "                              train_discriminator_loss.result(),\n",
    "                              train_domain_loss.result(),\n",
    "                              train_src_vat_loss.result(),\n",
    "                              train_trg_vat_loss.result(),\n",
    "                              train_src_mixup_loss.result(),\n",
    "                              train_trg_mixup_loss.result(),\n",
    "                              src_train_accuracy.result()*100,\n",
    "                              trg_train_accuracy.result()*100), end=\"\")\n",
    "\n",
    "  for data in trg_test_set:\n",
    "    trg_test_accuracy(test_step(data[0]), data[1])\n",
    "    \n",
    "  for data in src_test_set:\n",
    "    src_test_accuracy(test_step(data[0]), data[1])\n",
    "    \n",
    "  for data in office_test_set:\n",
    "    office_test_accuracy(test_step(data[0]), data[1])\n",
    "    \n",
    "  for data in server_test_set:\n",
    "    server_test_accuracy(test_step(data[0]), data[1])\n",
    "    \n",
    "  for data in conf_test_set:\n",
    "    conf_test_accuracy(test_step(data[0]), data[1])\n",
    "    \n",
    "  print(test_template.format(src_test_accuracy.result()*100,\n",
    "                             trg_test_accuracy.result()*100,\n",
    "                             server_test_accuracy.result()*100,\n",
    "                             office_test_accuracy.result()*100,\n",
    "                             conf_test_accuracy.result()*100))\n",
    "\n",
    "  log_loss()\n",
    "  \n",
    "  train_total_loss.reset_states()\n",
    "  train_cross_entropy_loss.reset_states()\n",
    "  train_cond_entropy_loss.reset_states()\n",
    "  src_train_accuracy.reset_states()\n",
    "  trg_train_accuracy.reset_states()\n",
    "  train_discriminator_loss.reset_states()\n",
    "  train_domain_loss.reset_states()\n",
    "  train_src_vat_loss.reset_states()\n",
    "  train_trg_vat_loss.reset_states()\n",
    "  train_src_mixup_loss.reset_states()\n",
    "  train_trg_mixup_loss.reset_states()\n",
    "  src_test_accuracy.reset_states()\n",
    "  trg_test_accuracy.reset_states()\n",
    "  server_test_accuracy.reset_states()\n",
    "  office_test_accuracy.reset_states()\n",
    "  conf_test_accuracy.reset_states()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
