{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "repo_path = os.getenv('MMWAVE_PATH')\n",
    "import sys\n",
    "sys.path.append(os.path.join(repo_path, 'models'))\n",
    "from utils import *\n",
    "from resnet_amca import ResNetAMCA, AM_logits\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import inspect\n",
    "import shutil\n",
    "import yaml\n",
    "import h5py\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images):\n",
    "    logits, embds = model(images, training=False)\n",
    "    return tf.nn.softmax(logits), embds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source_days = 1\n",
    "train_server_days = 0\n",
    "train_conference_days = 0\n",
    "\n",
    "checkpoint_path=\"/home/kjakkala/mmwave/logs/FinalExp/Source/epochs:1000-init_lr:0.001-num_features:128-model_filters:64-activation_fn:selu-batch_size:64-num_classes:10-train_source_days:{}-anneal:4-s:10-m:0.1-ca:0.001-notes:AMCABaseline/checkpoints\".format(train_source_days)\n",
    "#checkpoint_path=\"/home/kjakkala/mmwave/logs/FinalExp/SourceTargetLabeled/epochs:1000-init_lr:0.001-num_features:128-model_filters:64-activation_fn:selu-batch_size:64-num_classes:10-train_source_days:{}-train_server_days:{}-train_conference_days:{}-anneal:4-s:10-m:0.1-ca:0.001-notes:AMCABaseline/checkpoints\".format(train_source_days, train_server_days, train_conference_days)\n",
    "\n",
    "dataset_path=\"/home/kjakkala/mmwave/data\"\n",
    "train_source_unlabeled_days = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_trg_data(filename, src_classes, train_trg_days, test_all=False):\n",
    "    X_data_trg, y_data_trg, trg_classes = get_h5dataset(filename)\n",
    "\n",
    "    #split days of data to train and test\n",
    "    X_train_trg = X_data_trg[y_data_trg[:, 1] < train_trg_days]\n",
    "    y_train_trg = y_data_trg[y_data_trg[:, 1] < train_trg_days, 0]\n",
    "    y_train_trg_day = y_data_trg[y_data_trg[:, 1] < train_trg_days, 1]\n",
    "    y_train_trg = np.array([\n",
    "        src_classes.index(trg_classes[y_train_trg[i]])\n",
    "        for i in range(y_train_trg.shape[0])\n",
    "    ])\n",
    "\n",
    "    test_days = 0 if test_all else 3\n",
    "    X_test_trg = X_data_trg[y_data_trg[:, 1] >= test_days]\n",
    "    y_test_trg = y_data_trg[y_data_trg[:, 1] >= test_days, 0]\n",
    "    y_test_trg_day = y_data_trg[y_data_trg[:, 1] >= test_days, 1]\n",
    "    y_test_trg = np.array([\n",
    "        src_classes.index(trg_classes[y_test_trg[i]])\n",
    "        for i in range(y_test_trg.shape[0])\n",
    "    ])\n",
    "\n",
    "    if (X_train_trg.shape[0] != 0):\n",
    "        X_train_trg, trg_mean = mean_center(X_train_trg)\n",
    "        X_train_trg, trg_min, trg_ptp = normalize(X_train_trg)\n",
    "        y_train_trg = np.eye(len(src_classes))[y_train_trg]\n",
    "\n",
    "        X_test_trg, _ = mean_center(X_test_trg, trg_mean)\n",
    "        X_test_trg, _, _ = normalize(X_test_trg, trg_min, trg_ptp)\n",
    "        y_test_trg = np.eye(len(src_classes))[y_test_trg]\n",
    "    else:\n",
    "        X_test_trg, _ = mean_center(X_test_trg)\n",
    "        X_test_trg, _, _ = normalize(X_test_trg)\n",
    "        y_test_trg = np.eye(len(src_classes))[y_test_trg]\n",
    "\n",
    "    X_train_trg = X_train_trg.astype(np.float32)\n",
    "    y_train_trg = y_train_trg.astype(np.uint8)\n",
    "    X_test_trg = X_test_trg.astype(np.float32)\n",
    "    y_test_trg = y_test_trg.astype(np.uint8)\n",
    "\n",
    "    return X_train_trg, y_train_trg, y_train_trg_day, X_test_trg, y_test_trg, y_test_trg_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X_data, y_data, classes = get_h5dataset(\n",
    "    os.path.join(dataset_path, 'source_data.h5'))\n",
    "X_data, y_data = balance_dataset(X_data,\n",
    "                                 y_data,\n",
    "                                 num_days=10,\n",
    "                                 num_classes=len(classes),\n",
    "                                 max_samples_per_class=95)\n",
    "\n",
    "#split days of data to train and test\n",
    "X_src = X_data[y_data[:, 1] < train_source_days]\n",
    "y_src = y_data[y_data[:, 1] < train_source_days, 0]\n",
    "y_src_day = y_data[y_data[:, 1] < train_source_days, 1]\n",
    "y_src = np.eye(len(classes))[y_src]\n",
    "X_train_src, X_test_src, y_train_src, y_test_src, y_train_src_day, y_test_src_day = train_test_split(\n",
    "    X_src, y_src, y_src_day, stratify=y_src, test_size=0.10, random_state=42)\n",
    "\n",
    "X_trg = X_data[y_data[:, 1] >= train_source_days]\n",
    "y_trg = y_data[y_data[:, 1] >= train_source_days]\n",
    "X_train_trg = X_trg[y_trg[:, 1] < train_source_days +\n",
    "                    train_source_unlabeled_days]\n",
    "y_train_trg = y_trg[y_trg[:, 1] < train_source_days +\n",
    "                    train_source_unlabeled_days, 0]\n",
    "y_train_trg = np.eye(len(classes))[y_train_trg]\n",
    "\n",
    "X_test_trg = X_data[y_data[:, 1] >= train_source_days +\n",
    "                    train_source_unlabeled_days]\n",
    "y_test_trg = y_data[y_data[:, 1] >= train_source_days +\n",
    "                    train_source_unlabeled_days, 0]\n",
    "y_test_trg_day = y_data[y_data[:, 1] >= train_source_days +\n",
    "                    train_source_unlabeled_days, 1]\n",
    "y_test_trg = np.eye(len(classes))[y_test_trg]\n",
    "\n",
    "del X_src, y_src, X_trg, y_trg, X_data, y_data\n",
    "\n",
    "#mean center and normalize dataset\n",
    "X_train_src, src_mean = mean_center(X_train_src)\n",
    "X_train_src, src_min, src_ptp = normalize(X_train_src)\n",
    "\n",
    "X_test_src, _ = mean_center(X_test_src, src_mean)\n",
    "X_test_src, _, _ = normalize(X_test_src, src_min, src_ptp)\n",
    "\n",
    "if (X_train_trg.shape[0] != 0):\n",
    "    X_train_trg, trg_mean = mean_center(X_train_trg)\n",
    "    X_train_trg, trg_min, trg_ptp = normalize(X_train_trg)\n",
    "\n",
    "    X_test_trg, _ = mean_center(X_test_trg, trg_mean)\n",
    "    X_test_trg, _, _ = normalize(X_test_trg, trg_min, trg_ptp)\n",
    "else:\n",
    "    X_test_trg, _ = mean_center(X_test_trg, src_mean)\n",
    "    X_test_trg, _, _ = normalize(X_test_trg, src_min, src_ptp)\n",
    "\n",
    "X_train_src = X_train_src.astype(np.float32)\n",
    "y_train_src = y_train_src.astype(np.uint8)\n",
    "X_test_src = X_test_src.astype(np.float32)\n",
    "y_test_src = y_test_src.astype(np.uint8)\n",
    "X_train_trg = X_train_trg.astype(np.float32)\n",
    "y_train_trg = y_train_trg.astype(np.uint8)\n",
    "X_test_trg = X_test_trg.astype(np.float32)\n",
    "y_test_trg = y_test_trg.astype(np.uint8)\n",
    "\n",
    "X_train_conf, y_train_conf, y_train_conf_day, X_test_conf, y_test_conf, y_test_conf_day = get_trg_data(\n",
    "    os.path.join(dataset_path, 'target_conf_data.h5'), classes,\n",
    "    train_conference_days, test_all=True)\n",
    "X_train_server, y_train_server, y_train_server_day, X_test_server, y_test_server, y_test_server_day = get_trg_data(\n",
    "    os.path.join(dataset_path, 'target_server_data.h5'), classes,\n",
    "    train_server_days, test_all=True)\n",
    "_, _, _, X_data_office, y_data_office, y_data_office_day = get_trg_data(os.path.join(\n",
    "    dataset_path, 'target_office_data.h5'),\n",
    "                                                  classes,\n",
    "                                                  0,\n",
    "                                                  test_all=True)\n",
    "\n",
    "print(\"Final shapes: \")\n",
    "print(\" Train Src:   \", X_train_src.shape, y_train_src.shape, \"\\n\",\n",
    "      \"Test Src:    \", X_test_src.shape, y_test_src.shape, \"\\n\",\n",
    "      \"Train Trg:   \", X_train_trg.shape, y_train_trg.shape, \"\\n\",\n",
    "      \"Test Trg:    \", X_test_trg.shape, y_test_trg.shape)\n",
    "print(\" Train Conf:  \", X_train_conf.shape, y_train_conf.shape, \"\\n\",\n",
    "      \"Test Conf:   \", X_test_conf.shape, y_test_conf.shape, \"\\n\",\n",
    "      \"Train Server:\", X_train_server.shape, y_train_server.shape, \"\\n\",\n",
    "      \"Test Server: \", X_test_server.shape, y_test_server.shape, \"\\n\",\n",
    "      \"Test office: \", X_data_office.shape, y_data_office.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model = ResNetAMCA(10,\n",
    "                   128,\n",
    "                   num_filters=64,\n",
    "                   activation='selu',\n",
    "                   ca_decay=1e-3)\n",
    "\n",
    "\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt,\n",
    "                                          checkpoint_path,\n",
    "                                          max_to_keep=5)\n",
    "ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "if not ckpt_manager.latest_checkpoint:\n",
    "  print(\"No checkpoint !!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train')\n",
    "\n",
    "train_embds = []\n",
    "train_data = []\n",
    "for label in range(10):\n",
    "  tmp = []\n",
    "\n",
    "  for image in X_train_src[np.argmax(y_train_src, axis=-1)==label]:\n",
    "    _, embd = test_step(tf.expand_dims(image, axis=0)) \n",
    "    tmp.extend(embd)\n",
    "    train_data.extend(embd)\n",
    "  \n",
    "  '''\n",
    "  for image in X_train_server[np.argmax(y_train_server, axis=-1)==label]:\n",
    "    _, embd = test_step(tf.expand_dims(image, axis=0)) \n",
    "    tmp.extend(embd)\n",
    "\n",
    "  for image in X_train_conf[np.argmax(y_train_conf, axis=-1)==label]:\n",
    "    _, embd = test_step(tf.expand_dims(image, axis=0)) \n",
    "    tmp.extend(embd)\n",
    "    \n",
    "  '''\n",
    "\n",
    "  train_embds.append(np.mean(tmp, axis=0))\n",
    "train_embds = np.array(train_embds)\n",
    "print(train_embds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout = open(checkpoint_path.replace(\"checkpoints\", \"accuracies\"), 'w')\n",
    "\n",
    "acc = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "print('\\nServer')\n",
    "server_embds = [[] for i in range(5)]\n",
    "server_data = []\n",
    "for day in range(5):\n",
    "  acc.reset_states()\n",
    "  for label in range(10):\n",
    "    tmp = []\n",
    "    for image in X_test_server[np.logical_and(y_test_server_day==day, np.argmax(y_test_server, axis=-1)==label)]:\n",
    "      pred, embd = test_step(tf.expand_dims(image, axis=0)) \n",
    "      tmp.append(embd)\n",
    "      server_data.extend(embd)\n",
    "      acc(pred, np.eye(10)[label])\n",
    "    server_embds[day].append(np.mean(tmp, axis=0).squeeze())\n",
    "  print(float(acc.result()))\n",
    "server_embds = np.array(server_embds)\n",
    "\n",
    "print()\n",
    "for day in range(5):\n",
    "  tmp = []\n",
    "  for label in range(10):\n",
    "    tmp.append(np.linalg.norm(server_embds[day][label]-train_embds[label]))\n",
    "  print(np.sum(tmp))\n",
    "  \n",
    "  \n",
    "print('\\nConf')\n",
    "conf_embds = [[] for i in range(5)]\n",
    "conf_data = []\n",
    "for day in range(5):\n",
    "  acc.reset_states()\n",
    "  for label in range(10):\n",
    "    tmp = []\n",
    "    for image in X_test_conf[np.logical_and(y_test_conf_day==day, np.argmax(y_test_conf, axis=-1)==label)]:\n",
    "      pred, embd = test_step(tf.expand_dims(image, axis=0)) \n",
    "      tmp.append(embd)\n",
    "      conf_data.extend(embd)\n",
    "      acc(pred, np.eye(10)[label])\n",
    "    conf_embds[day].append(np.mean(tmp, axis=0).squeeze())\n",
    "  print(float(acc.result()))\n",
    "conf_embds = np.array(conf_embds)\n",
    "\n",
    "print()\n",
    "for day in range(5):\n",
    "  tmp = []\n",
    "  for label in range(10):\n",
    "    tmp.append(np.linalg.norm(conf_embds[day][label]-train_embds[label]))\n",
    "  print(np.sum(tmp))\n",
    "  \n",
    "  \n",
    "print('\\nOffice')\n",
    "office_embds = [[] for i in range(5)]\n",
    "office_data = []\n",
    "for day in range(5):\n",
    "  acc.reset_states()\n",
    "  for label in range(10):\n",
    "    tmp = []\n",
    "    for image in X_data_office[np.logical_and(y_data_office_day==day, np.argmax(y_data_office, axis=-1)==label)]:\n",
    "      pred, embd = test_step(tf.expand_dims(image, axis=0)) \n",
    "      tmp.append(embd)\n",
    "      office_data.extend(embd)\n",
    "      acc(pred, np.eye(10)[label])\n",
    "    office_embds[day].append(np.mean(tmp, axis=0).squeeze())\n",
    "  print(float(acc.result()))\n",
    "office_embds = np.array(office_embds)\n",
    "\n",
    "print()\n",
    "for day in range(5):\n",
    "  tmp = []\n",
    "  for label in range(10):\n",
    "    tmp.append(np.linalg.norm(office_embds[day][label]-train_embds[label]))\n",
    "  print(np.sum(tmp))\n",
    "  \n",
    "\n",
    "\n",
    "print('\\nSource')\n",
    "source_embds = [[] for i in range(10)]\n",
    "source_data = []\n",
    "for day in range(train_source_days):\n",
    "  acc.reset_states()\n",
    "  for label in range(10):\n",
    "    tmp = []\n",
    "    for image in X_test_src[np.logical_and(y_test_src_day==day, np.argmax(y_test_src, axis=-1)==label)]:\n",
    "      pred, embd = test_step(tf.expand_dims(image, axis=0)) \n",
    "      tmp.append(embd)\n",
    "      source_data.extend(embd)\n",
    "      acc(pred, np.eye(10)[label])\n",
    "    source_embds[day].append(np.mean(tmp, axis=0).squeeze())\n",
    "  print(float(acc.result()))\n",
    "for day in range(train_source_days, 10):\n",
    "  acc.reset_states()\n",
    "  for label in range(10):\n",
    "    tmp = []\n",
    "    for image in X_test_trg[np.logical_and(y_test_trg_day==day, np.argmax(y_test_trg, axis=-1)==label)]:\n",
    "      pred, embd = test_step(tf.expand_dims(image, axis=0)) \n",
    "      tmp.append(embd)\n",
    "      source_data.extend(embd)\n",
    "      acc(pred, np.eye(10)[label])\n",
    "    source_embds[day].append(np.mean(tmp, axis=0).squeeze())\n",
    "  print(float(acc.result()))\n",
    "source_embds = np.array(source_embds)\n",
    "\n",
    "print()\n",
    "for day in range(10):\n",
    "  tmp = []\n",
    "  for label in range(10):\n",
    "    tmp.append(np.linalg.norm(source_embds[day][label]-train_embds[label]))\n",
    "  print(np.sum(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded = TSNE(n_components=2).fit_transform(np.concatenate([train_data, server_data, conf_data, office_data, source_data], axis=0))\n",
    "np.save(checkpoint_path.replace(\"checkpoints\", \"t-SNE\"), X_embedded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
