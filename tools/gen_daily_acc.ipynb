{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "repo_path = os.getenv('MMWAVE_PATH')\n",
    "import sys\n",
    "sys.path.append(os.path.join(repo_path, 'models'))\n",
    "from utils import *\n",
    "from resnet_amca import ResNetAMCA, AM_logits\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import inspect\n",
    "import shutil\n",
    "import yaml\n",
    "import h5py\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images):\n",
    "    logits, embds = model(images, training=False)\n",
    "    return tf.nn.softmax(logits), embds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source_days = 1\n",
    "train_server_days = 1\n",
    "train_conference_days = 0\n",
    "\n",
    "checkpoint_path=\"/home/kjakkala/mmwave/logs/FinalExp/SourceOnly/epochs:1000-init_lr:0.001-num_features:128-model_filters:64-activation_fn:selu-batch_size:64-num_classes:10-train_source_days:{}-anneal:4-s:10-m:0.1-ca:0.001-notes:AMCABaseline/checkpoints\".format(train_source_days)\n",
    "checkpoint_path=\"/home/kjakkala/mmwave/logs/FinalExp/SourceTargetLabeled/epochs:1000-init_lr:0.001-num_features:128-model_filters:64-activation_fn:selu-batch_size:64-num_classes:10-train_source_days:{}-train_server_days:{}-train_conference_days:{}-anneal:4-s:10-m:0.1-ca:0.001-notes:AMCABaseline/checkpoints\".format(train_source_days, train_server_days, train_conference_days)\n",
    "\n",
    "dataset_path=\"/home/kjakkala/mmwave/data\"\n",
    "train_source_unlabeled_days = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shapes: \n",
      " Train Src:    (855, 256, 256, 1) (855, 10) \n",
      " Test Src:     (95, 256, 256, 1) (95, 10) \n",
      " Train Trg:    (0, 256, 256, 1) (0, 10) \n",
      " Test Trg:     (8550, 256, 256, 1) (8550, 10)\n",
      " Train Conf:   (0, 256, 256, 1) (0,) \n",
      " Test Conf:    (2500, 256, 256, 1) (2500, 10) \n",
      " Train Server: (497, 256, 256, 1) (497, 10) \n",
      " Test Server:  (2496, 256, 256, 1) (2496, 10) \n",
      " Test office:  (2498, 256, 256, 1) (2498, 10)\n"
     ]
    }
   ],
   "source": [
    "X_data, y_data, classes = get_h5dataset(\n",
    "    os.path.join(dataset_path, 'source_data.h5'))\n",
    "X_data, y_data = balance_dataset(X_data,\n",
    "                                 y_data,\n",
    "                                 num_days=10,\n",
    "                                 num_classes=len(classes),\n",
    "                                 max_samples_per_class=95)\n",
    "\n",
    "#split days of data to train and test\n",
    "X_src = X_data[y_data[:, 1] < train_source_days]\n",
    "y_src = y_data[y_data[:, 1] < train_source_days, 0]\n",
    "y_src_day = y_data[y_data[:, 1] < train_source_days, 1]\n",
    "y_src = np.eye(len(classes))[y_src]\n",
    "X_train_src, X_test_src, y_train_src, y_test_src, y_train_src_day, y_test_src_day = train_test_split(\n",
    "    X_src, y_src, y_src_day, stratify=y_src, test_size=0.10, random_state=42)\n",
    "\n",
    "X_trg = X_data[y_data[:, 1] >= train_source_days]\n",
    "y_trg = y_data[y_data[:, 1] >= train_source_days]\n",
    "X_train_trg = X_trg[y_trg[:, 1] < train_source_days +\n",
    "                    train_source_unlabeled_days]\n",
    "y_train_trg = y_trg[y_trg[:, 1] < train_source_days +\n",
    "                    train_source_unlabeled_days, 0]\n",
    "y_train_trg = np.eye(len(classes))[y_train_trg]\n",
    "\n",
    "X_test_trg = X_data[y_data[:, 1] >= train_source_days +\n",
    "                    train_source_unlabeled_days]\n",
    "y_test_trg = y_data[y_data[:, 1] >= train_source_days +\n",
    "                    train_source_unlabeled_days, 0]\n",
    "y_test_trg_day = y_data[y_data[:, 1] >= train_source_days +\n",
    "                    train_source_unlabeled_days, 1]\n",
    "y_test_trg = np.eye(len(classes))[y_test_trg]\n",
    "\n",
    "del X_src, y_src, X_trg, y_trg, X_data, y_data\n",
    "\n",
    "#mean center and normalize dataset\n",
    "X_train_src, src_mean = mean_center(X_train_src)\n",
    "X_train_src, src_min, src_ptp = normalize(X_train_src)\n",
    "\n",
    "X_test_src, _ = mean_center(X_test_src, src_mean)\n",
    "X_test_src, _, _ = normalize(X_test_src, src_min, src_ptp)\n",
    "\n",
    "if (X_train_trg.shape[0] != 0):\n",
    "    X_train_trg, trg_mean = mean_center(X_train_trg)\n",
    "    X_train_trg, trg_min, trg_ptp = normalize(X_train_trg)\n",
    "\n",
    "    X_test_trg, _ = mean_center(X_test_trg, trg_mean)\n",
    "    X_test_trg, _, _ = normalize(X_test_trg, trg_min, trg_ptp)\n",
    "else:\n",
    "    X_test_trg, _ = mean_center(X_test_trg, src_mean)\n",
    "    X_test_trg, _, _ = normalize(X_test_trg, src_min, src_ptp)\n",
    "\n",
    "X_train_src = X_train_src.astype(np.float32)\n",
    "y_train_src = y_train_src.astype(np.uint8)\n",
    "X_test_src = X_test_src.astype(np.float32)\n",
    "y_test_src = y_test_src.astype(np.uint8)\n",
    "X_train_trg = X_train_trg.astype(np.float32)\n",
    "y_train_trg = y_train_trg.astype(np.uint8)\n",
    "X_test_trg = X_test_trg.astype(np.float32)\n",
    "y_test_trg = y_test_trg.astype(np.uint8)\n",
    "\n",
    "X_train_conf, y_train_conf, y_train_conf_day, X_test_conf, y_test_conf, y_test_conf_day = get_trg_data(\n",
    "    os.path.join(dataset_path, 'target_conf_data.h5'), classes,\n",
    "    train_conference_days, test_all=True)\n",
    "X_train_server, y_train_server, y_train_server_day, X_test_server, y_test_server, y_test_server_day = get_trg_data(\n",
    "    os.path.join(dataset_path, 'target_server_data.h5'), classes,\n",
    "    train_server_days, test_all=True)\n",
    "_, _, _, X_data_office, y_data_office, y_data_office_day = get_trg_data(os.path.join(\n",
    "    dataset_path, 'target_office_data.h5'),\n",
    "                                                  classes,\n",
    "                                                  0,\n",
    "                                                  test_all=True)\n",
    "\n",
    "print(\"Final shapes: \")\n",
    "print(\" Train Src:   \", X_train_src.shape, y_train_src.shape, \"\\n\",\n",
    "      \"Test Src:    \", X_test_src.shape, y_test_src.shape, \"\\n\",\n",
    "      \"Train Trg:   \", X_train_trg.shape, y_train_trg.shape, \"\\n\",\n",
    "      \"Test Trg:    \", X_test_trg.shape, y_test_trg.shape)\n",
    "print(\" Train Conf:  \", X_train_conf.shape, y_train_conf.shape, \"\\n\",\n",
    "      \"Test Conf:   \", X_test_conf.shape, y_test_conf.shape, \"\\n\",\n",
    "      \"Train Server:\", X_train_server.shape, y_train_server.shape, \"\\n\",\n",
    "      \"Test Server: \", X_test_server.shape, y_test_server.shape, \"\\n\",\n",
    "      \"Test office: \", X_data_office.shape, y_data_office.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNetAMCA(10,\n",
    "                   128,\n",
    "                   num_filters=64,\n",
    "                   activation='selu',\n",
    "                   ca_decay=1e-3)\n",
    "\n",
    "\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt,\n",
    "                                          checkpoint_path,\n",
    "                                          max_to_keep=5)\n",
    "ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "if not ckpt_manager.latest_checkpoint:\n",
    "  print(\"No checkpoint !!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "(10, 128)\n"
     ]
    }
   ],
   "source": [
    "print('Train')\n",
    "train_embds = []\n",
    "for label in range(10):\n",
    "  tmp = []\n",
    "  for image in X_train_src[np.argmax(y_train_src, axis=-1)==label]:\n",
    "    _, embd = test_step(tf.expand_dims(image, axis=0)) \n",
    "    tmp.extend(embd)\n",
    "  train_embds.append(np.mean(tmp, axis=0))\n",
    "train_embds = np.array(train_embds)\n",
    "print(train_embds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Server\n",
      "1.0\n",
      "0.8360000252723694\n",
      "0.8019999861717224\n",
      "0.7955911755561829\n",
      "0.7200000286102295\n",
      "\n",
      "27.83879\n",
      "106.94913\n",
      "119.0163\n",
      "122.80188\n",
      "138.39645\n",
      "\n",
      "Conf\n",
      "0.7699999809265137\n",
      "0.8100000023841858\n",
      "0.8539999723434448\n",
      "0.8240000009536743\n",
      "0.800000011920929\n",
      "\n",
      "111.31773\n",
      "111.068306\n",
      "91.06996\n",
      "88.95405\n",
      "105.15255\n",
      "\n",
      "Office\n",
      "0.6079999804496765\n",
      "0.5379999876022339\n",
      "0.509018063545227\n",
      "0.5170340538024902\n",
      "0.5379999876022339\n",
      "\n",
      "143.05931\n",
      "155.00194\n",
      "154.5889\n",
      "154.45506\n",
      "159.3272\n",
      "\n",
      "Source\n",
      "0.9789473414421082\n",
      "0.9147368669509888\n",
      "0.9347368478775024\n",
      "0.9200000166893005\n",
      "0.9242105484008789\n",
      "0.8031578660011292\n",
      "0.906315803527832\n",
      "0.8873684406280518\n",
      "0.8799999952316284\n",
      "0.785263180732727\n",
      "\n",
      "29.52549\n",
      "85.894905\n",
      "67.401054\n",
      "73.963844\n",
      "83.56709\n",
      "102.75411\n",
      "83.97243\n",
      "92.03045\n",
      "107.91532\n",
      "117.08028\n"
     ]
    }
   ],
   "source": [
    "acc = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "print('\\nServer')\n",
    "server_embds = [[] for i in range(5)]\n",
    "for day in range(5):\n",
    "  acc.reset_states()\n",
    "  for label in range(10):\n",
    "    tmp = []\n",
    "    for image in X_test_server[np.logical_and(y_test_server_day==day, np.argmax(y_test_server, axis=-1)==label)]:\n",
    "      pred, embd = test_step(tf.expand_dims(image, axis=0)) \n",
    "      tmp.append(embd)\n",
    "      acc(pred, np.eye(10)[label])\n",
    "    server_embds[day].append(np.mean(tmp, axis=0).squeeze())\n",
    "  print(float(acc.result()))\n",
    "server_embds = np.array(server_embds)\n",
    "\n",
    "print()\n",
    "for day in range(5):\n",
    "  tmp = []\n",
    "  for label in range(10):\n",
    "    tmp.append(np.linalg.norm(server_embds[day][label]-train_embds[label]))\n",
    "  print(np.sum(tmp))\n",
    "  \n",
    "  \n",
    "print('\\nConf')\n",
    "conf_embds = [[] for i in range(5)]\n",
    "for day in range(5):\n",
    "  acc.reset_states()\n",
    "  for label in range(10):\n",
    "    tmp = []\n",
    "    for image in X_test_conf[np.logical_and(y_test_conf_day==day, np.argmax(y_test_conf, axis=-1)==label)]:\n",
    "      pred, embd = test_step(tf.expand_dims(image, axis=0)) \n",
    "      tmp.append(embd)\n",
    "      acc(pred, np.eye(10)[label])\n",
    "    conf_embds[day].append(np.mean(tmp, axis=0).squeeze())\n",
    "  print(float(acc.result()))\n",
    "conf_embds = np.array(conf_embds)\n",
    "\n",
    "print()\n",
    "for day in range(5):\n",
    "  tmp = []\n",
    "  for label in range(10):\n",
    "    tmp.append(np.linalg.norm(conf_embds[day][label]-train_embds[label]))\n",
    "  print(np.sum(tmp))\n",
    "  \n",
    "  \n",
    "print('\\nOffice')\n",
    "office_embds = [[] for i in range(5)]\n",
    "for day in range(5):\n",
    "  acc.reset_states()\n",
    "  for label in range(10):\n",
    "    tmp = []\n",
    "    for image in X_data_office[np.logical_and(y_data_office_day==day, np.argmax(y_data_office, axis=-1)==label)]:\n",
    "      pred, embd = test_step(tf.expand_dims(image, axis=0)) \n",
    "      tmp.append(embd)\n",
    "      acc(pred, np.eye(10)[label])\n",
    "    office_embds[day].append(np.mean(tmp, axis=0).squeeze())\n",
    "  print(float(acc.result()))\n",
    "office_embds = np.array(office_embds)\n",
    "\n",
    "print()\n",
    "for day in range(5):\n",
    "  tmp = []\n",
    "  for label in range(10):\n",
    "    tmp.append(np.linalg.norm(office_embds[day][label]-train_embds[label]))\n",
    "  print(np.sum(tmp))\n",
    "  \n",
    "\n",
    "\n",
    "print('\\nSource')\n",
    "source_embds = [[] for i in range(10)]\n",
    "for day in range(train_source_days):\n",
    "  acc.reset_states()\n",
    "  for label in range(10):\n",
    "    tmp = []\n",
    "    for image in X_test_src[np.logical_and(y_test_src_day==day, np.argmax(y_test_src, axis=-1)==label)]:\n",
    "      pred, embd = test_step(tf.expand_dims(image, axis=0)) \n",
    "      tmp.append(embd)\n",
    "      acc(pred, np.eye(10)[label])\n",
    "    source_embds[day].append(np.mean(tmp, axis=0).squeeze())\n",
    "  print(float(acc.result()))\n",
    "for day in range(train_source_days, 10):\n",
    "  acc.reset_states()\n",
    "  for label in range(10):\n",
    "    tmp = []\n",
    "    for image in X_test_trg[np.logical_and(y_test_trg_day==day, np.argmax(y_test_trg, axis=-1)==label)]:\n",
    "      pred, embd = test_step(tf.expand_dims(image, axis=0)) \n",
    "      tmp.append(embd)\n",
    "      acc(pred, np.eye(10)[label])\n",
    "    source_embds[day].append(np.mean(tmp, axis=0).squeeze())\n",
    "  print(float(acc.result()))\n",
    "source_embds = np.array(source_embds)\n",
    "\n",
    "print()\n",
    "for day in range(10):\n",
    "  tmp = []\n",
    "  for label in range(10):\n",
    "    tmp.append(np.linalg.norm(source_embds[day][label]-train_embds[label]))\n",
    "  print(np.sum(tmp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
